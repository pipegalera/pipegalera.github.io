<!doctype html><html class="dark light" lang=en><head><meta charset=UTF-8><meta content="IE=edge" http-equiv=X-UA-Compatible><meta content="width=device-width,initial-scale=1.0" name=viewport><meta content=https://pipegalera.github.io name=base><title>
            
                Fastai - Deep Learning for Coders, by Jeremy Howard
            
        </title><meta content="Fastai - Deep Learning for Coders, by Jeremy Howard" property=og:title><meta content="My personal notes of the Fastai book/course." property=og:description><meta content="My personal notes of the Fastai book/course." name=description><link href=https://cdn.jsdelivr.net/npm/jetbrains-mono@1.0.6/css/jetbrains-mono.min.css rel=stylesheet><link href=https://cdn.jsdelivr.net/npm/@fontsource/space-grotesk@4.5.8/index.min.css rel=stylesheet><script src=https://pipegalera.github.io/js/codeblock.js></script><script src=https://pipegalera.github.io/js/toc.js></script><script src=https://pipegalera.github.io/js/note.js></script><script>MathJax = {
              tex: {
                inlineMath: [['$', '$'], ['\\(', '\\)']]
              }
            };</script><script async id=MathJax-script src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js></script><link href=https://pipegalera.github.io/atom.xml rel=alternate title=~/.pipe_galera type=application/atom+xml><link href=https://pipegalera.github.io/theme/light.css rel=stylesheet><link href=https://pipegalera.github.io/theme/dark.css id=darkModeStyle rel=stylesheet><script src=https://pipegalera.github.io/js/themetoggle.js></script><script>setTheme(getSavedTheme());</script><link href=https://pipegalera.github.io/main.css media=screen rel=stylesheet><script src="https://pipegalera.github.io/js/searchElasticlunr.min.js?h=3626c0ef99daa745b31e" defer></script><body><div class=content><header><div class=main><a href=https://pipegalera.github.io>~/.pipe_galera</a><div class=socials><a class=social href=https://www.linkedin.com/in/pipegalera/ rel=me> <img alt=linkedin src=https://pipegalera.github.io/icons/social/linkedin.svg> </a><a class=social href=https://github.com/pipegalera/ rel=me> <img alt=github src=https://pipegalera.github.io/icons/social/github.svg> </a></div></div><nav><a href=https://pipegalera.github.io/posts style=margin-left:.25em>/posts</a><a href=https://pipegalera.github.io/mostly_books style=margin-left:.25em>/mostly_books</a><a href=https://pipegalera.github.io/tags style=margin-left:.25em>/tags</a><button title="$SHORTCUT to open search" class=search-button id=search-button><img alt=Search class=search-icon src=https://pipegalera.github.io/icons/search.svg></button><div class="search-modal js" aria-labelledby=modalTitle id=searchModal role=dialog><div id=modal-content><h1 class=page-header id=modalTitle>Search</h1><div id=searchBar><input aria-controls=results-container aria-expanded=false autocomplete=off id=searchInput placeholder=Search... role=combobox spellcheck=false><button title="Clear search" class=clear-button id=clear-search><svg viewbox="0 -960 960 960" xmlns=http://www.w3.org/2000/svg><path d="m256-200-56-56 224-224-224-224 56-56 224 224 224-224 56 56-224 224 224 224-56 56-224-224-224 224Z"/></svg></button></div><div id=results-container><div id=results-info><span id=zero_results style=display:none>No results</span><span id=one_result style=display:none>1 result</span><span id=many_results style=display:none>$NUMBER results</span></div><div id=results role=listbox></div></div></div></div><a onclick="toggleTheme(); event.preventDefault();" href=# id=dark-mode-toggle> <img alt=Light id=sun-icon src=https://pipegalera.github.io/icons/sun.svg style=filter:invert()> <img alt=Dark id=moon-icon src=https://pipegalera.github.io/icons/moon.svg> </a><script>updateItemToggleTheme()</script></nav></header><main><article><div class=title><div class=page-header>Fastai - Deep Learning for Coders, by Jeremy Howard<span class=primary-color style=font-size:1.6em>.</span></div><div class=meta>Posted on <time>2022-01-01</time> :: 16421 Words <span class=tags-label>:: Tags:</span><span class=tags> <a class=post-tag href=https://pipegalera.github.io/tags/books/>books</a> , <a class=post-tag href=https://pipegalera.github.io/tags/machine-learning/>machine learning</a> , <a class=post-tag href=https://pipegalera.github.io/tags/deep-learning/>deep learning</a> , <a class=post-tag href=https://pipegalera.github.io/tags/python/>python</a> </span></div></div><div class=toc-container><h1 class=toc-title>Table of Contents</h1><ul class=toc-list><li><a href=https://pipegalera.github.io/mostly_books/book-fastai/#chapters-1-to-4-introduction>Chapters 1 to 4 - Introduction</a> <ul><li><a href=https://pipegalera.github.io/mostly_books/book-fastai/#1-1-install-fastai-api>1.1 Install fastai API</a><li><a href=https://pipegalera.github.io/mostly_books/book-fastai/#1-2-machine-learning-intro>1.2 Machine Learning Intro</a><li><a href=https://pipegalera.github.io/mostly_books/book-fastai/#1-3-weights>1.3 Weights</a><li><a href=https://pipegalera.github.io/mostly_books/book-fastai/#1-4-terminology>1.4 Terminology</a><li><a href=https://pipegalera.github.io/mostly_books/book-fastai/#1-5-p-values-principles>1.5 P-values principles</a><li><a href=https://pipegalera.github.io/mostly_books/book-fastai/#1-6-starting-a-machine-learning-project-defining-the-problem>1.6 Starting a Machine Learning Project: Defining the problem</a></ul><li><a href=https://pipegalera.github.io/mostly_books/book-fastai/#chapter-5-image-classification>Chapter 5 - Image Classification</a> <ul><li><a href=https://pipegalera.github.io/mostly_books/book-fastai/#5-1-oxford-iiit-pet-dataset>5.1 Oxford-IIIT Pet Dataset</a><li><a href=https://pipegalera.github.io/mostly_books/book-fastai/#5-2-datablocks>5.2 DataBlocks</a><li><a href=https://pipegalera.github.io/mostly_books/book-fastai/#5-3-other-resizing-methods>5.3 Other resizing methods</a><li><a href=https://pipegalera.github.io/mostly_books/book-fastai/#5-4-creating-a-baseline-model>5.4 Creating a baseline model</a><li><a href=https://pipegalera.github.io/mostly_books/book-fastai/#5-5-model-interpretation>5.5 Model interpretation</a><li><a href=https://pipegalera.github.io/mostly_books/book-fastai/#5-6-exporting-and-importing-a-model>5.6 Exporting and importing a model</a><li><a href=https://pipegalera.github.io/mostly_books/book-fastai/#5-7-testing-the-model-outside-the-fastai-environment>5.7 Testing the model outside the fastai environment</a><li><a href=https://pipegalera.github.io/mostly_books/book-fastai/#5-8-improving-our-model>5.8 Improving Our Model</a></li><ul><li><a href=https://pipegalera.github.io/mostly_books/book-fastai/#5-8-1-learning-rate-finder>5.8.1 Learning rate finder</a><li><a href=https://pipegalera.github.io/mostly_books/book-fastai/#5-8-2-transfer-learning-and-freezing>5.8.2 Transfer Learning and Freezing</a><li><a href=https://pipegalera.github.io/mostly_books/book-fastai/#5-8-3-discriminative-learning-rates>5.8.3 Discriminative learning rates</a><li><a href=https://pipegalera.github.io/mostly_books/book-fastai/#5-8-4-selecting-the-number-of-epochs>5.8.4 Selecting the Number of Epochs</a></ul><li><a href=https://pipegalera.github.io/mostly_books/book-fastai/#5-9-deeper-architectures>5.9 Deeper Architectures</a><li><a href=https://pipegalera.github.io/mostly_books/book-fastai/#5-10-final-model-results-comparison>5.10 Final model results comparison</a></ul><li><a href=https://pipegalera.github.io/mostly_books/book-fastai/#chapter-6-other-computer-vision-problems>Chapter 6 - Other Computer Vision Problems</a> <ul><li><a href=https://pipegalera.github.io/mostly_books/book-fastai/#6-1-multi-label-classification>6.1 Multi-label classification</a><li><a href=https://pipegalera.github.io/mostly_books/book-fastai/#6-2-regression>6.2 Regression</a></ul><li><a href=https://pipegalera.github.io/mostly_books/book-fastai/#chapter-7-training-a-state-of-the-art-model>Chapter 7 - Training a State-of-the-Art Model</a> <ul><li><a href=https://pipegalera.github.io/mostly_books/book-fastai/#7-1-imagenette-dataset>7.1 Imagenette Dataset</a><li><a href=https://pipegalera.github.io/mostly_books/book-fastai/#7-2-normalization>7.2 Normalization</a><li><a href=https://pipegalera.github.io/mostly_books/book-fastai/#7-3-progressive-resizing>7.3 Progressive Resizing</a><li><a href=https://pipegalera.github.io/mostly_books/book-fastai/#7-4-test-time-augmentation>7.4 Test Time augmentation</a><li><a href=https://pipegalera.github.io/mostly_books/book-fastai/#7-5-mixup>7.5 Mixup</a><li><a href=https://pipegalera.github.io/mostly_books/book-fastai/#7-6-label-smoothing>7.6 Label Smoothing</a></ul><li><a href=https://pipegalera.github.io/mostly_books/book-fastai/#chapter-9-tabular-modeling-deep-dive>Chapter 9 - Tabular Modeling Deep Dive</a> <ul><li><a href=https://pipegalera.github.io/mostly_books/book-fastai/#9-1-beyond-deep-learning>9.1 Beyond Deep Learning</a><li><a href=https://pipegalera.github.io/mostly_books/book-fastai/#9-2-the-dataset>9.2 The Dataset</a><li><a href=https://pipegalera.github.io/mostly_books/book-fastai/#9-3-categorical-embeddings>9.3 Categorical Embeddings</a><li><a href=https://pipegalera.github.io/mostly_books/book-fastai/#9-4-feature-engineering-dates>9.4 Feature Engineering: Dates</a><li><a href=https://pipegalera.github.io/mostly_books/book-fastai/#9-5-using-tabularpandas-and-tabularproc>9.5 Using TabularPandas and TabularProc</a><li><a href=https://pipegalera.github.io/mostly_books/book-fastai/#9-7-decision-trees-avoiding-overfitting>9.7 Decision Trees: Avoiding Overfitting</a><li><a href=https://pipegalera.github.io/mostly_books/book-fastai/#9-8-random-forests>9.8 Random Forests</a><li><a href=https://pipegalera.github.io/mostly_books/book-fastai/#9-10-out-of-bag-error-and-prediction>9.10 Out-of-Bag Error and Prediction</a><li><a href=https://pipegalera.github.io/mostly_books/book-fastai/#9-11-model-simplification-and-improvements>9.11 Model Simplification and Improvements</a></li><ul><li><a href=https://pipegalera.github.io/mostly_books/book-fastai/#9-11-1-tree-variance-for-prediction-confidence>9.11.1 Tree Variance for Prediction Confidence</a><li><a href=https://pipegalera.github.io/mostly_books/book-fastai/#9-11-2-feature-importance>9.11.2 Feature Importance</a><li><a href=https://pipegalera.github.io/mostly_books/book-fastai/#9-11-3-removing-low-importance-variables>9.11.3 Removing Low-Importance Variables</a><li><a href=https://pipegalera.github.io/mostly_books/book-fastai/#9-11-4-removing-redundant-features>9.11.4 Removing Redundant Features</a><li><a href=https://pipegalera.github.io/mostly_books/book-fastai/#9-11-5-partial-dependence>9.11.5 Partial Dependence</a><li><a href=https://pipegalera.github.io/mostly_books/book-fastai/#9-11-6-data-leakage>9.11.6 Data Leakage</a></ul><li><a href=https://pipegalera.github.io/mostly_books/book-fastai/#9-12-tree-models-and-extrapolation>9.12 Tree-models and Extrapolation</a><li><a href=https://pipegalera.github.io/mostly_books/book-fastai/#9-13-finding-out-of-domain-data>9.13 Finding Out-of-Domain Data</a><li><a href=https://pipegalera.github.io/mostly_books/book-fastai/#9-14-neural-networks-for-tabular-data>9.14 Neural Networks for tabular data</a><li><a href=https://pipegalera.github.io/mostly_books/book-fastai/#9-15-ensembling>9.15 Ensembling</a><li><a href=https://pipegalera.github.io/mostly_books/book-fastai/#9-16-boosting>9.16 Boosting</a><li><a href=https://pipegalera.github.io/mostly_books/book-fastai/#9-17-tabular-models-conclusion>9.17 Tabular models conclusion</a></ul></ul></div><section class=body><p>My personal notes of the Fastbook/Fastai course <a href=https://fastai.github.io/fastbook2e/>Practical Deep Learning for Coders</a><p><img alt="book cover" src=https://m.media-amazon.com/images/I/516YvsJCS9L._SY445_SX342_.jpg><h2 id=chapters-1-to-4-introduction><a aria-label="Anchor link for: chapters-1-to-4-introduction" class=zola-anchor href=#chapters-1-to-4-introduction>Chapters 1 to 4 - Introduction</a></h2><p>Fastbook is a book is focused on the practical side of deep learning. It starts with the big picture, such as definitions and general applications of deep learning, and progressively digs beneath the surface into concrete examples.<p>The book is based on <em>fastai</em> API, an API on top of Pytorch that makes it easier to use state-of-the-art methods in deep learning. It doesn't need you to understand models such as Convolutional Neural Networks and how they work, but it definitely have helped me following the book.<p>The fastbook package includes fastai and several easy-access datasets to test the models.<h3 id=1-1-install-fastai-api><a aria-label="Anchor link for: 1-1-install-fastai-api" class=zola-anchor href=#1-1-install-fastai-api>1.1 Install fastai API</a></h3><p><strong>Installing fastai in Segamaker Studio Lab:</strong><ol><li>Initiate a Terminal and create a conda environment:</ol><pre class=language-bash data-lang=bash style=color:#839496;background-color:#002b36><code class=language-bash data-lang=bash><span style=color:#b58900>conda</span><span> create</span><span style=color:#268bd2> -n</span><span> fastai python=3.8
</span><span style=color:#b58900>conda</span><span> activate fastai
</span></code></pre><ol start=2><li>Install Pytorch and Fastai:</ol><pre class=language-bash data-lang=bash style=color:#839496;background-color:#002b36><code class=language-bash data-lang=bash><span style=color:#586e75># Pytorch
</span><span style=color:#b58900>conda</span><span> install pytorch torchvision torchaudio
</span><span style=color:#586e75># Fastai
</span><span style=color:#b58900>conda</span><span> install</span><span style=color:#268bd2> -c</span><span> fastchan fastai
</span></code></pre><ol start=3><li>Import fastai:</ol><pre class=language-python data-lang=python style=color:#839496;background-color:#002b36><code class=language-python data-lang=python><span style=color:#cb4b16>import </span><span>fastbook
</span><span>fastbook.</span><span style=color:#b58900>setup_book</span><span style=color:#657b83>()
</span><span style=color:#cb4b16>from </span><span>fastai.vision.all </span><span style=color:#cb4b16>import </span><span style=color:#b58900>*
</span><span style=color:#cb4b16>from </span><span>fastai.vision </span><span style=color:#cb4b16>import </span><span style=color:#b58900>*
</span></code></pre><p><strong>Installing fastai locally</strong><p>Please notice that unless you have a really powerful GPU (e.g. Nvidia 3080+) you won't get the same training times than training the models in Google Colab or Amazon Segamaker.<p>The instructions are very similar, you only have to take care of the CUDA Toolkit first.<ol><li><p><a href="https://developer.nvidia.com/cuda-11.3.0-download-archive?target_os=Windows&target_arch=x86_64&target_version=10">Install CUDA Toolkit 11.3</a> . Follow the link and install.</p><li><p>Create a new clean Python environment using <a href=https://docs.conda.io/en/latest/miniconda.html>miniconda</a> :</p></ol><pre class=language-bash data-lang=bash style=color:#839496;background-color:#002b36><code class=language-bash data-lang=bash><span style=color:#b58900>conda</span><span> create</span><span style=color:#268bd2> -n</span><span> fastai python=3.8
</span><span style=color:#b58900>conda</span><span> activate fastai
</span></code></pre><ol start=3><li>Install Pytorch and Fastai:</ol><pre class=language-bash data-lang=bash style=color:#839496;background-color:#002b36><code class=language-bash data-lang=bash><span style=color:#586e75># Pytorch
</span><span style=color:#b58900>conda</span><span> install pytorch torchvision torchaudio cudatoolkit=11.3</span><span style=color:#268bd2> -c</span><span> pytorch
</span><span style=color:#586e75># Fastai
</span><span style=color:#b58900>conda</span><span> install</span><span style=color:#268bd2> -c</span><span> fastchan fastai
</span></code></pre><ol start=4><li>Test Pytorch and Fastai:</ol><p>If Pytorch was successfully installed you should see you GPU name by running:<pre class=language-python data-lang=python style=color:#839496;background-color:#002b36><code class=language-python data-lang=python><span style=color:#cb4b16>import </span><span>torch
</span><span>x </span><span style=color:#657b83>= </span><span>torch.cuda.</span><span style=color:#b58900>get_device_name</span><span style=color:#657b83>(</span><span style=color:#6c71c4>0</span><span style=color:#657b83>) </span><span style=color:#859900>if </span><span>torch.cuda.</span><span style=color:#b58900>is_available</span><span style=color:#657b83>() </span><span style=color:#859900>else </span><span style=color:#b58900>None
</span><span style=color:#859900>print</span><span style=color:#657b83>(</span><span>x</span><span style=color:#657b83>)
</span></code></pre><p>If Fastai was successfully installed you should load fastai without any error:<pre class=language-python data-lang=python style=color:#839496;background-color:#002b36><code class=language-python data-lang=python><span style=color:#cb4b16>import </span><span>fastbook
</span><span>fastbook.</span><span style=color:#b58900>setup_book</span><span style=color:#657b83>()
</span><span style=color:#cb4b16>from </span><span>fastai.vision.all </span><span style=color:#cb4b16>import </span><span style=color:#b58900>*
</span><span style=color:#cb4b16>from </span><span>fastai.vision </span><span style=color:#cb4b16>import </span><span style=color:#b58900>*
</span></code></pre><h3 id=1-2-machine-learning-intro><a aria-label="Anchor link for: 1-2-machine-learning-intro" class=zola-anchor href=#1-2-machine-learning-intro>1.2 Machine Learning Intro</a></h3><p>Machine Learning: The training of programs developed by allowing a computer to learn from its experience, rather than through manually coding the individual steps.<p>Deep Learning is a branch of Machine Learning focus in Neural Networks. Visually, this is how they work:<p><img alt src=https://pipegalera.github.io/mostly_books/book-fastai/./images/2.png><p>Neural Networks, in theory, can solve any problem to any level of accuracy based on the parametrization of the weights - <em>Universal approximation theorem</em>.<h3 id=1-3-weights><a aria-label="Anchor link for: 1-3-weights" class=zola-anchor href=#1-3-weights>1.3 Weights</a></h3><p>The key for the parametrization to be correct is updating the weight. The weights are "responsible" of finding the right solution to the problem at hand. For example, weighting correctly the pixels in a picture to solve the question "Is a Dog or a Cat picture?".<p>The weight updating is made by Stochastic gradient descent (SGD).<h3 id=1-4-terminology><a aria-label="Anchor link for: 1-4-terminology" class=zola-anchor href=#1-4-terminology>1.4 Terminology</a></h3><p>The terminology has changed. Here is the modern deep learning terminology for all the pieces we have discussed:<ul><li><p>The functional form of the <em>model</em> is called its <strong>architecture</strong> (but be carefulâ€”sometimes people use <em>model</em> as a synonym of <em>architecture</em>, so this can get confusing).</p><li><p>The <em>weights</em> are called <strong>parameters</strong>.</p><li><p>The <strong>predictions</strong> are calculated from the <em>independent variable</em>, which is the <em>data</em> not including the <em>labels</em>.</p><li><p>The <em>results</em> of the model are called <em>predictions</em>.</p><li><p>The measure of <em>performance</em> is called the <strong>loss</strong>. This measure of performance is only relevant <strong>for the computer</strong> to see if the model is doing better or worse in order <strong>to update the parameters</strong>.</p><li><p>The loss depends not only on the predictions, but also the correct <em>labels</em> (also known as <em>targets</em> or the <em>dependent variable</em>); e.g., "dog" or "cat."</p><li><p><strong>Metric</strong> is a function that measures quality of the model prediction <strong>for you</strong>. For example, the % of true labels predicted accurately. It can be the case that the loss change but identify the same number of true labels.</p></ul><p>Clarification: In the course they use "regression" not as a linear regression but as any prediction model in which the result is a continuous variable.<p>After making these changes, our diagram looks like:<p><img alt src=https://pipegalera.github.io/mostly_books/book-fastai/./images/3.png><p>More important terminology:<ul><li>Data Ethics: Positive feedback loop</ul><p>Positive feedback loop is the effect of a small increase in the values of one part of a system that increases other values in the remaining system. Given that the definition is kinda technical, let's use the case of a predictive policing model.<p>Let's say that a predictive policing model is created based on where arrests have been made in the past. In practice, this is not actually predicting crime, but rather predicting arrests, and is therefore partially simply reflecting biases in existing policing processes. Law enforcement officers then might use that model to decide where to focus their police activity, resulting in creased arrests in those areas.<p>These additional arrests would then feed back to re-training future versions of the model. The more the model is used, the more biased the data becomes, making the model even more biased, and so forth.<p>This is an example of a Positive feedback loop, where the system is this predictive policing model and the values are arrests.<p><strong>You cannot avoid positive feedback loop, use human interaction to notice the weird stuff that your algorithm might create.</strong><ul><li>Proxy bias</ul><p>Taking the previous example - If the proxy for the variable that you are interested (arrests as proxied for crime) is bias, the variable that you are predicting too.<ul><li>Transfer learning</ul><p>Using a pretrained model for a task different to what it was originally trained for. It is key to use models with less data. Basically, instead of the model starting with random weights, it is already trained by someone else and parametrized.<ul><li>Fine tuning</ul><p>A transfer learning technique where the parameters of a pretrained model are updated by training for additional epochs using a different task to that used for pretaining.<p>An epoch is how many times the model looks at the data.<p>A more extended dictionary:<p><img alt src=https://pipegalera.github.io/mostly_books/book-fastai/./images/4.png><h3 id=1-5-p-values-principles><a aria-label="Anchor link for: 1-5-p-values-principles" class=zola-anchor href=#1-5-p-values-principles>1.5 P-values principles</a></h3><p>The practical importance of a model is not given by the p-values but by the results and implications. <strong>It only says that the confidence of the event happening by chance.</strong><ol><li><p>P-values can indicate how incompatible the data are with a specified statistical model.</p><li><p>P-values do not measure the probability that the studied hypothesis is true, or the probability that the data were produced by random chance alone.</p><li><p>Scientific conclusions and business or policy decisions should not be based only on whether a P-value passes a specific threshold.</p><li><p>Proper inference requires full reporting and transparency.</p><li><p>A P-value, or statistical significance, does not measure the size of an effect or the importance of a result.</p></ol><p>The threshold of statistical significance that is commonly used is a P-value of 0.05. This is conventional and arbitrary.<ol start=6><li>By itself, a P-value does not provide a good measure of evidence regarding a model or hypothesis.</ol><h3 id=1-6-starting-a-machine-learning-project-defining-the-problem><a aria-label="Anchor link for: 1-6-starting-a-machine-learning-project-defining-the-problem" class=zola-anchor href=#1-6-starting-a-machine-learning-project-defining-the-problem>1.6 Starting a Machine Learning Project: Defining the problem</a></h3><p>First, define the problem that you want to solve and the levers or variables that you can pull to change the outcome. <strong>What its the point of predicting an outcome if you cannot do anything about it?</strong><h2 id=chapter-5-image-classification><a aria-label="Anchor link for: chapter-5-image-classification" class=zola-anchor href=#chapter-5-image-classification>Chapter 5 - Image Classification</a></h2><p>This chapter focused on building an image classification model.<h3 id=5-1-oxford-iiit-pet-dataset><a aria-label="Anchor link for: 5-1-oxford-iiit-pet-dataset" class=zola-anchor href=#5-1-oxford-iiit-pet-dataset>5.1 Oxford-IIIT Pet Dataset</a></h3><p>We will use a images dataset with 37 pet breeds classes and roughly 200 images for each class. The images have large variations in scale, pose, and lighting (here the <a href=https://www.robots.ox.ac.uk/~vgg/data/pets/>original source</a>).<pre class=language-python data-lang=python style=color:#839496;background-color:#002b36><code class=language-python data-lang=python><span style=color:#586e75># Downloading the Oxford-IIIT Pet Dataset
</span><span>path </span><span style=color:#657b83>= </span><span style=color:#b58900>untar_data</span><span style=color:#657b83>(</span><span>URLs.</span><span style=color:#268bd2>PETS</span><span style=color:#657b83>)
</span></code></pre><p>We can use the <code>ls</code> method from fastai to see what is in our dataset and folders<pre class=language-python data-lang=python style=color:#839496;background-color:#002b36><code class=language-python data-lang=python><span>Path.</span><span style=color:#268bd2>BASE_PATH </span><span style=color:#657b83>= </span><span>path
</span><span style=color:#859900>print</span><span style=color:#657b83>(</span><span>path.</span><span style=color:#b58900>ls</span><span style=color:#657b83>())
</span><span style=color:#657b83>(</span><span>path</span><span style=color:#657b83>/</span><span>"</span><span style=color:#2aa198>images</span><span>"</span><span style=color:#657b83>)</span><span>.</span><span style=color:#b58900>ls</span><span style=color:#657b83>()
</span><span>
</span><span>
</span><span>    </span><span style=color:#657b83>[</span><span style=color:#b58900>Path</span><span style=color:#657b83>(</span><span>'</span><span style=color:#2aa198>annotations</span><span>'</span><span style=color:#657b83>)</span><span>, </span><span style=color:#b58900>Path</span><span style=color:#657b83>(</span><span>'</span><span style=color:#2aa198>images</span><span>'</span><span style=color:#657b83>)]
</span><span>
</span><span>    </span><span style=color:#657b83>(</span><span style=color:#586e75>#7393) [Path('images/newfoundland_31.jpg'),Path('images/Ragdoll_79.jpg'),Path('images/yorkshire_terrier_31.jpg'),Path('images/havanese_172.jpg'),Path('images/newfoundland_61.jpg'),Path('images/Abyssinian_175.jpg'),Path('images/leonberger_164.jpg'),Path('images/saint_bernard_86.jpg'),Path('images/boxer_108.jpg'),Path('images/scottish_terrier_195.jpg')...]
</span></code></pre><h3 id=5-2-datablocks><a aria-label="Anchor link for: 5-2-datablocks" class=zola-anchor href=#5-2-datablocks>5.2 DataBlocks</a></h3><p>Fastai uses DataBlocks to load the data. Here we load the images of the folder into this <code>DataBlock</code>. Most of the arguments of the functions are quite intuitive to guess, but they are explained below in any case.<ul><li><p><code>DataBlock</code> is the envelope of the structure of the data. Here you tell fastai API how you organized the data.</p><li><p><code>blocks</code> is how you tell fastai what inputs are images (<code>ImageBlock</code>) and what are the targets for the categories (<code>CategoryBlock</code>).</p><li><p><code>get_items</code> is how you tell fastai to assemble our items inside the <code>DataBlock</code>.</p><li><p><code>splitter</code> is used to divide the images in training and validation set randomly.</p><li><p><code>get_y</code> is used to create target values. The images are not labeled, they are just 7393 jpgs. We extract the target label (y) from the name of the file using regex expressions <code>RegexLabeller</code>.</p></ul><pre class=language-python data-lang=python style=color:#839496;background-color:#002b36><code class=language-python data-lang=python><span>pets </span><span style=color:#657b83>= </span><span style=color:#b58900>DataBlock</span><span style=color:#657b83>(</span><span style=color:#268bd2>blocks </span><span style=color:#657b83>= (</span><span>ImageBlock, CategoryBlock</span><span style=color:#657b83>)</span><span>,
</span><span>                 </span><span style=color:#268bd2>get_items</span><span style=color:#657b83>=</span><span>get_image_files,
</span><span>                 </span><span style=color:#268bd2>splitter</span><span style=color:#657b83>=</span><span style=color:#b58900>RandomSplitter</span><span style=color:#657b83>(</span><span style=color:#268bd2>seed</span><span style=color:#657b83>=</span><span style=color:#6c71c4>42</span><span style=color:#657b83>)</span><span>,
</span><span>                 </span><span style=color:#268bd2>get_y</span><span style=color:#657b83>=</span><span style=color:#b58900>using_attr</span><span style=color:#657b83>(</span><span style=color:#b58900>RegexLabeller</span><span style=color:#657b83>(</span><span style=color:#268bd2>r</span><span>'</span><span style=color:#2aa198>(</span><span style=color:#cb4b16>.</span><span style=color:#859900>+</span><span style=color:#2aa198>)_</span><span style=color:#cb4b16>\d</span><span style=color:#859900>+</span><span style=color:#cb4b16>.</span><span style=color:#2aa198>jpg</span><span style=color:#859900>$</span><span>'</span><span style=color:#657b83>)</span><span>, '</span><span style=color:#2aa198>name</span><span>'</span><span style=color:#657b83>)</span><span>,
</span><span>                 </span><span style=color:#268bd2>item_tfms</span><span style=color:#657b83>=</span><span style=color:#b58900>Resize</span><span style=color:#657b83>(</span><span style=color:#6c71c4>460</span><span style=color:#657b83>)</span><span>,
</span><span>                 </span><span style=color:#268bd2>batch_tfms</span><span style=color:#657b83>=</span><span style=color:#b58900>aug_transforms</span><span style=color:#657b83>(</span><span style=color:#268bd2>size</span><span style=color:#657b83>=</span><span style=color:#6c71c4>224</span><span>, </span><span style=color:#268bd2>min_scale</span><span style=color:#657b83>=</span><span style=color:#6c71c4>0.75</span><span style=color:#657b83>))
</span><span>
</span><span style=color:#586e75># Tell DataBlock where the "source" is
</span><span>dls </span><span style=color:#657b83>= </span><span>pets.</span><span style=color:#b58900>dataloaders</span><span style=color:#657b83>(</span><span>path</span><span style=color:#657b83>/</span><span>"</span><span style=color:#2aa198>images</span><span>"</span><span style=color:#657b83>)
</span></code></pre><p>We can take the first image and print the path using <code>.ls()</code> method as well.<pre class=language-python data-lang=python style=color:#839496;background-color:#002b36><code class=language-python data-lang=python><span>fname </span><span style=color:#657b83>= (</span><span>path</span><span style=color:#657b83>/</span><span>"</span><span style=color:#2aa198>images</span><span>"</span><span style=color:#657b83>)</span><span>.</span><span style=color:#b58900>ls</span><span style=color:#657b83>()</span><span style=color:#268bd2>[</span><span style=color:#6c71c4>0</span><span style=color:#268bd2>]
</span><span>fname
</span><span>
</span><span>
</span><span>    </span><span style=color:#657b83>/</span><span>root</span><span style=color:#657b83>/</span><span>.fastai</span><span style=color:#657b83>/</span><span>data</span><span style=color:#657b83>/</span><span>oxford</span><span style=color:#657b83>-</span><span>iiit</span><span style=color:#657b83>-</span><span>pet</span><span style=color:#657b83>/</span><span>images</span><span style=color:#657b83>/</span><span>newfoundland_31.jpg
</span></code></pre><p>Using regex we can extract the target from the jpg name<pre class=language-python data-lang=python style=color:#839496;background-color:#002b36><code class=language-python data-lang=python><span>re.</span><span style=color:#b58900>findall</span><span style=color:#657b83>(</span><span style=color:#268bd2>r</span><span>'</span><span style=color:#2aa198>(</span><span style=color:#cb4b16>.</span><span style=color:#859900>+</span><span style=color:#2aa198>)_</span><span style=color:#cb4b16>\d</span><span style=color:#859900>+</span><span style=color:#cb4b16>.</span><span style=color:#2aa198>jpg</span><span style=color:#859900>$</span><span>', fname.name</span><span style=color:#657b83>)
</span><span>
</span><span>          </span><span style=color:#657b83>[</span><span>'</span><span style=color:#2aa198>newfoundland</span><span>'</span><span style=color:#657b83>]
</span></code></pre><p>The last 2 methods are about data augmentation strategy, what fastai call <em>presizing</em>.<p><strong>Presizing</strong> is a particular way to do image augmentation that is designed to speed up computation and improve model accuracy.<ul><li><p><code>item_tfms</code> resize so all the images have the same dimension (In this case 460x460). It is needed so they can collate into tensors to be passed to the GPU. By default, it crops the image (not squish like when you set the background of your computer screen). On the training set, the crop area is chosen randomly. On the validation set, the center square of the image is always chosen.</p><li><p><code>batch_tfms</code> randomly random crops and augment parts of the images. It's only done once, in one batch. On the validation set, it only resizes to the final size needed for the model. On the training set, it first random crops and performs any augmentations, and then it resizes.</p><li><p><code>aug_transforms</code> function can be used to create a list of images flipped, rotated, zoomed, wrapped, or with changed lighting. It helps the training process and avoids overfitting. <code>min_scale</code> determines how much of the image to select at minimum each time (More <a href=https://docs.fast.ai/vision.augment.html#aug_transforms>here</a>)</p></ul><p><img alt src=https://raw.githubusercontent.com/fastai/fastbook/780b76bef3127ce5b64f8230fce60e915a7e0735/images/att_00060.png><h3 id=5-3-other-resizing-methods><a aria-label="Anchor link for: 5-3-other-resizing-methods" class=zola-anchor href=#5-3-other-resizing-methods>5.3 Other resizing methods</a></h3><p>With <code>show_batch</code> we can print a batch of images of the training set.<pre class=language-python data-lang=python style=color:#839496;background-color:#002b36><code class=language-python data-lang=python><span style=color:#586e75># Show some images
</span><span>dls.</span><span style=color:#b58900>show_batch</span><span style=color:#657b83>(</span><span style=color:#268bd2>max_n</span><span style=color:#657b83>=</span><span style=color:#6c71c4>6</span><span style=color:#657b83>)
</span></code></pre><p><img alt src=https://pipegalera.github.io/mostly_books/book-fastai/./images/Fastbook_Chapter_5_Image_Classification_12_0.png><p>We can squish the images, or add padding to the sides or crop it by copying the model with <code>.new</code> method and modifying the part of the model that you want to change.<p>Here we squish the images:<pre class=language-python data-lang=python style=color:#839496;background-color:#002b36><code class=language-python data-lang=python><span>pets </span><span style=color:#657b83>= </span><span>pets.</span><span style=color:#b58900>new</span><span style=color:#657b83>(</span><span style=color:#268bd2>item_tfms</span><span style=color:#657b83>= </span><span style=color:#b58900>Resize</span><span style=color:#657b83>(</span><span style=color:#6c71c4>256</span><span>, ResizeMethod.Squish</span><span style=color:#657b83>))
</span><span>dls </span><span style=color:#657b83>= </span><span>pets.</span><span style=color:#b58900>dataloaders</span><span style=color:#657b83>(</span><span>path</span><span style=color:#657b83>/</span><span>"</span><span style=color:#2aa198>images</span><span>"</span><span style=color:#657b83>)
</span><span>dls.</span><span style=color:#b58900>show_batch</span><span style=color:#657b83>(</span><span style=color:#268bd2>max_n</span><span style=color:#657b83>=</span><span style=color:#6c71c4>6</span><span style=color:#657b83>)
</span></code></pre><p><img alt src=https://pipegalera.github.io/mostly_books/book-fastai/./images/Fastbook_Chapter_5_Image_Classification_14_0.png><p>Here we add padding to the images:<pre class=language-python data-lang=python style=color:#839496;background-color:#002b36><code class=language-python data-lang=python><span>pets </span><span style=color:#657b83>= </span><span>pets.</span><span style=color:#b58900>new</span><span style=color:#657b83>(</span><span style=color:#268bd2>item_tfms</span><span style=color:#657b83>= </span><span style=color:#b58900>Resize</span><span style=color:#657b83>(</span><span style=color:#6c71c4>256</span><span>, ResizeMethod.Pad, </span><span style=color:#268bd2>pad_mode</span><span style=color:#657b83>=</span><span>'</span><span style=color:#2aa198>zeros</span><span>'</span><span style=color:#657b83>))
</span><span>dls </span><span style=color:#657b83>= </span><span>pets.</span><span style=color:#b58900>dataloaders</span><span style=color:#657b83>(</span><span>path</span><span style=color:#657b83>/</span><span>"</span><span style=color:#2aa198>images</span><span>"</span><span style=color:#657b83>)
</span><span>dls.</span><span style=color:#b58900>show_batch</span><span style=color:#657b83>(</span><span style=color:#268bd2>max_n</span><span style=color:#657b83>=</span><span style=color:#6c71c4>6</span><span style=color:#657b83>)
</span></code></pre><p><img alt src=https://pipegalera.github.io/mostly_books/book-fastai/./images/Fastbook_Chapter_5_Image_Classification_15_0.png><p><strong>Remember that by cropping the images we removed some of the features that allow us to perform recognition.</strong><p>Instead, what we normally do in practice is to randomly select part of the image and crop it. On each epoch (which is one complete pass through all of our images in the dataset) we randomly select a different crop of each image. We can use <code>RandomResizedCrop</code> for that.<p>This means that our model can learn to focus on, and recognize, different features in our images at different epochs. It also reflects how images work in the real world as different photos of the same thing may be framed in slightly different ways.<pre class=language-python data-lang=python style=color:#839496;background-color:#002b36><code class=language-python data-lang=python><span>pets </span><span style=color:#657b83>= </span><span>pets.</span><span style=color:#b58900>new</span><span style=color:#657b83>(</span><span style=color:#268bd2>item_tfms</span><span style=color:#657b83>= </span><span style=color:#b58900>RandomResizedCrop</span><span style=color:#657b83>(</span><span style=color:#6c71c4>128</span><span>, </span><span style=color:#268bd2>min_scale</span><span style=color:#657b83>=</span><span style=color:#6c71c4>0.3</span><span style=color:#657b83>))
</span><span>dls </span><span style=color:#657b83>= </span><span>pets.</span><span style=color:#b58900>dataloaders</span><span style=color:#657b83>(</span><span>path</span><span style=color:#657b83>/</span><span>"</span><span style=color:#2aa198>images</span><span>"</span><span style=color:#657b83>)
</span><span style=color:#586e75># Unique=True to have the same image repeated with different versions of this RandomResizedCrop transform
</span><span>dls.</span><span style=color:#b58900>show_batch</span><span style=color:#657b83>(</span><span style=color:#268bd2>max_n</span><span style=color:#657b83>=</span><span style=color:#6c71c4>6</span><span>, </span><span style=color:#268bd2>unique</span><span style=color:#657b83>=</span><span style=color:#b58900>True</span><span style=color:#657b83>)
</span></code></pre><p><img alt src=https://pipegalera.github.io/mostly_books/book-fastai/./images/Fastbook_Chapter_5_Image_Classification_17_0.png><p>We can alwasy use <code>new</code> method to get back to the first resizing method chosen (<code>aug_transforms</code>):<pre class=language-python data-lang=python style=color:#839496;background-color:#002b36><code class=language-python data-lang=python><span>pets </span><span style=color:#657b83>= </span><span>pets.</span><span style=color:#b58900>new</span><span style=color:#657b83>(</span><span style=color:#268bd2>item_tfms</span><span style=color:#657b83>=</span><span style=color:#b58900>Resize</span><span style=color:#657b83>(</span><span style=color:#6c71c4>460</span><span style=color:#657b83>)</span><span>, </span><span style=color:#268bd2>batch_tfms</span><span style=color:#657b83>=</span><span style=color:#b58900>aug_transforms</span><span style=color:#657b83>(</span><span style=color:#268bd2>size</span><span style=color:#657b83>=</span><span style=color:#6c71c4>224</span><span>, </span><span style=color:#268bd2>min_scale</span><span style=color:#657b83>=</span><span style=color:#6c71c4>0.75</span><span style=color:#657b83>))
</span><span>dls </span><span style=color:#657b83>= </span><span>pets.</span><span style=color:#b58900>dataloaders</span><span style=color:#657b83>(</span><span>path</span><span style=color:#657b83>/</span><span>"</span><span style=color:#2aa198>images</span><span>"</span><span style=color:#657b83>)
</span><span>dls.</span><span style=color:#b58900>show_batch</span><span style=color:#657b83>(</span><span style=color:#268bd2>max_n</span><span style=color:#657b83>=</span><span style=color:#6c71c4>6</span><span>, </span><span style=color:#268bd2>unique </span><span style=color:#657b83>= </span><span style=color:#b58900>True</span><span style=color:#657b83>)
</span></code></pre><p><img alt src=https://pipegalera.github.io/mostly_books/book-fastai/./images/Fastbook_Chapter_5_Image_Classification_19_0.png><h3 id=5-4-creating-a-baseline-model><a aria-label="Anchor link for: 5-4-creating-a-baseline-model" class=zola-anchor href=#5-4-creating-a-baseline-model>5.4 Creating a baseline model</a></h3><p>We can see the shape of the data by printing one batch. Here we printed the labels <code>y</code>. There are 64 listed numbers printed as the batch size is 64. The range of the numbers goes from 0 to 36 as it represents the labels for the 37 pet breeds.<pre class=language-python data-lang=python style=color:#839496;background-color:#002b36><code class=language-python data-lang=python><span>x, y </span><span style=color:#657b83>= </span><span>dls.</span><span style=color:#b58900>one_batch</span><span style=color:#657b83>()
</span><span>y
</span><span>
</span><span>    </span><span style=color:#b58900>TensorCategory</span><span style=color:#657b83>([ </span><span style=color:#6c71c4>9</span><span>,  </span><span style=color:#6c71c4>1</span><span>,  </span><span style=color:#6c71c4>2</span><span>, </span><span style=color:#6c71c4>22</span><span>, </span><span style=color:#6c71c4>14</span><span>, </span><span style=color:#6c71c4>35</span><span>, </span><span style=color:#6c71c4>27</span><span>, </span><span style=color:#6c71c4>28</span><span>, </span><span style=color:#6c71c4>17</span><span>, </span><span style=color:#6c71c4>31</span><span>,  </span><span style=color:#6c71c4>0</span><span>,  </span><span style=color:#6c71c4>9</span><span>, </span><span style=color:#6c71c4>13</span><span>, </span><span style=color:#6c71c4>12</span><span>,  </span><span style=color:#6c71c4>0</span><span>, </span><span style=color:#6c71c4>12</span><span>, </span><span style=color:#6c71c4>15</span><span>, </span><span style=color:#6c71c4>36</span><span>,  </span><span style=color:#6c71c4>2</span><span>,
</span><span>    </span><span style=color:#6c71c4>13</span><span>,  </span><span style=color:#6c71c4>9</span><span>,  </span><span style=color:#6c71c4>1</span><span>, </span><span style=color:#6c71c4>14</span><span>, </span><span style=color:#6c71c4>11</span><span>, </span><span style=color:#6c71c4>33</span><span>, </span><span style=color:#6c71c4>29</span><span>,  </span><span style=color:#6c71c4>7</span><span>, </span><span style=color:#6c71c4>27</span><span>, </span><span style=color:#6c71c4>13</span><span>, </span><span style=color:#6c71c4>10</span><span>,  </span><span style=color:#6c71c4>4</span><span>, </span><span style=color:#6c71c4>30</span><span>, </span><span style=color:#6c71c4>5</span><span>, </span><span style=color:#6c71c4>24</span><span>, </span><span style=color:#6c71c4>20</span><span>, </span><span style=color:#6c71c4>32</span><span>, </span><span style=color:#6c71c4>14</span><span>,  </span><span style=color:#6c71c4>8</span><span>, </span><span style=color:#6c71c4>18</span><span>, </span><span style=color:#6c71c4>35</span><span>, </span><span style=color:#6c71c4>15</span><span>,
</span><span>    </span><span style=color:#6c71c4>23</span><span>, </span><span style=color:#6c71c4>11</span><span>, </span><span style=color:#6c71c4>24</span><span>, </span><span style=color:#6c71c4>21</span><span>, </span><span style=color:#6c71c4>22</span><span>,  </span><span style=color:#6c71c4>9</span><span>, </span><span style=color:#6c71c4>18</span><span>, </span><span style=color:#6c71c4>9</span><span>, </span><span style=color:#6c71c4>17</span><span>, </span><span style=color:#6c71c4>12</span><span>, </span><span style=color:#6c71c4>15</span><span>, </span><span style=color:#6c71c4>14</span><span>, </span><span style=color:#6c71c4>17</span><span>, </span><span style=color:#6c71c4>36</span><span>, </span><span style=color:#6c71c4>18</span><span>, </span><span style=color:#6c71c4>18</span><span>, </span><span style=color:#6c71c4>33</span><span>, </span><span style=color:#6c71c4>21</span><span>,  </span><span style=color:#6c71c4>0</span><span>, </span><span style=color:#6c71c4>10</span><span>, </span><span style=color:#6c71c4>17</span><span>, </span><span style=color:#6c71c4>12</span><span>,  </span><span style=color:#6c71c4>7</span><span style=color:#657b83>]
</span><span>    , </span><span style=color:#268bd2>device</span><span style=color:#657b83>=</span><span>'</span><span style=color:#2aa198>cuda:0</span><span>'</span><span style=color:#657b83>)
</span></code></pre><p>Training a powerful baseline model requires 2 lines of code:<pre class=language-python data-lang=python style=color:#839496;background-color:#002b36><code class=language-python data-lang=python><span>learn </span><span style=color:#657b83>= </span><span style=color:#b58900>cnn_learner</span><span style=color:#657b83>(</span><span>dls, resnet34, </span><span style=color:#268bd2>metrics</span><span style=color:#657b83>= </span><span>error_rate</span><span style=color:#657b83>)
</span><span>learn.</span><span style=color:#b58900>fine_tune</span><span style=color:#657b83>(</span><span style=color:#6c71c4>2</span><span style=color:#657b83>)
</span></code></pre><ul><li><code>dls</code> is our data.<li><code>restnet34</code> is a certain pre-trained CNN architecture.<li>The <code>metric</code> requested is <code>error_rate</code>.<li>By default, fast ai chooses the loss function that best fit our kind of data. With image data and a categorical outcome, fastai will default to using <code>cross-entropy loss</code>.<li><code>fine_tune(2)</code> indicates the number of epochs with the default model configuration.</ul><p>This is the magic and simplicity of fastai. Once you have the data correctly loaded, the modeling with pre-trained models cannot be easier. Fastai automatically download the pre-trained architecture, choses an appropriate loss function and prints the metric results:<table style=center><thead><tr><th>epoch<th>train_loss<th>valid_loss<th>error_rate<th>time<tbody><tr><td>0<td>1.532038<td>0.331124<td>0.112991<td>01:07</table><table border=0 class=dataframe><thead><tr style=text-align:center;overflow-x:auto><th>epoch<th>train_loss<th>valid_loss<th>error_rate<th>time<tbody><tr><td>0<td>0.514930<td>0.295484<td>0.094046<td>01:12<tr><td>1<td>0.330700<td>0.223524<td>0.071042<td>01:12</table><p>The second column show the cross-entropy loss in the training and validation set. The fourth column show less than 1% of error classifying the images.<p>It even includes handy shortcuts like <code>show_results</code> to print the real and predicted labels for a quick check test of labels and predictions:<pre class=language-python data-lang=python style=color:#839496;background-color:#002b36><code class=language-python data-lang=python><span>learn.</span><span style=color:#b58900>show_results</span><span style=color:#657b83>()
</span></code></pre><p><img alt src=https://pipegalera.github.io/mostly_books/book-fastai/./images/Fastbook_Chapter_5_Image_Classification_26_1.png><h3 id=5-5-model-interpretation><a aria-label="Anchor link for: 5-5-model-interpretation" class=zola-anchor href=#5-5-model-interpretation>5.5 Model interpretation</a></h3><p>After building a model, you don't want to know only how many targets got right. You might want to know which targets are harder to predict or which images got wrong to train it better. fastai includes a <code>ClassificationInterpretation</code> class from which you can call <code>plot_confusion_matrix</code>, <code>most_confused</code> or <code>plot_top_losses</code> methods to extract this information easily.<pre class=language-python data-lang=python style=color:#839496;background-color:#002b36><code class=language-python data-lang=python><span>interp </span><span style=color:#657b83>= </span><span>ClassificationInterpretation.</span><span style=color:#b58900>from_learner</span><span style=color:#657b83>(</span><span>learn</span><span style=color:#657b83>)
</span><span>interp.</span><span style=color:#b58900>plot_confusion_matrix</span><span style=color:#657b83>(</span><span style=color:#268bd2>figsize </span><span style=color:#657b83>= (</span><span style=color:#6c71c4>12</span><span>,</span><span style=color:#6c71c4>12</span><span style=color:#657b83>)</span><span>, </span><span style=color:#268bd2>dpi</span><span style=color:#657b83>=</span><span style=color:#6c71c4>60</span><span style=color:#657b83>)
</span></code></pre><p><img alt src=https://pipegalera.github.io/mostly_books/book-fastai/./images/Fastbook_Chapter_5_Image_Classification_28_1.png><p>We can see which are the labels that the model more struggles to differentiate:<pre class=language-python data-lang=python style=color:#839496;background-color:#002b36><code class=language-python data-lang=python><span>interp.</span><span style=color:#b58900>most_confused</span><span style=color:#657b83>(</span><span style=color:#268bd2>min_val </span><span style=color:#657b83>= </span><span style=color:#6c71c4>4</span><span style=color:#657b83>)
</span><span>
</span><span>    </span><span style=color:#657b83>[(</span><span>'</span><span style=color:#2aa198>american_pit_bull_terrier</span><span>', '</span><span style=color:#2aa198>american_bulldog</span><span>', </span><span style=color:#6c71c4>6</span><span style=color:#657b83>)</span><span>,
</span><span>     </span><span style=color:#657b83>(</span><span>'</span><span style=color:#2aa198>British_Shorthair</span><span>', '</span><span style=color:#2aa198>Russian_Blue</span><span>', </span><span style=color:#6c71c4>5</span><span style=color:#657b83>)</span><span>,
</span><span>     </span><span style=color:#657b83>(</span><span>'</span><span style=color:#2aa198>Ragdoll</span><span>', '</span><span style=color:#2aa198>Birman</span><span>', </span><span style=color:#6c71c4>5</span><span style=color:#657b83>)</span><span>,
</span><span>     </span><span style=color:#657b83>(</span><span>'</span><span style=color:#2aa198>Siamese</span><span>', '</span><span style=color:#2aa198>Birman</span><span>', </span><span style=color:#6c71c4>4</span><span style=color:#657b83>)</span><span>,
</span><span>     </span><span style=color:#657b83>(</span><span>'</span><span style=color:#2aa198>american_pit_bull_terrier</span><span>', '</span><span style=color:#2aa198>staffordshire_bull_terrier</span><span>', </span><span style=color:#6c71c4>4</span><span style=color:#657b83>)</span><span>,
</span><span>     </span><span style=color:#657b83>(</span><span>'</span><span style=color:#2aa198>chihuahua</span><span>', '</span><span style=color:#2aa198>miniature_pinscher</span><span>', </span><span style=color:#6c71c4>4</span><span style=color:#657b83>)</span><span>,
</span><span>     </span><span style=color:#657b83>(</span><span>'</span><span style=color:#2aa198>staffordshire_bull_terrier</span><span>', '</span><span style=color:#2aa198>american_pit_bull_terrier</span><span>', </span><span style=color:#6c71c4>4</span><span style=color:#657b83>)]
</span></code></pre><p>And the the most "wrong" predictions:<pre class=language-python data-lang=python style=color:#839496;background-color:#002b36><code class=language-python data-lang=python><span>interp.</span><span style=color:#b58900>plot_top_losses</span><span style=color:#657b83>(</span><span style=color:#6c71c4>5</span><span>, </span><span style=color:#268bd2>nrows </span><span style=color:#657b83>= </span><span style=color:#6c71c4>5</span><span style=color:#657b83>)
</span></code></pre><p><img alt src=https://pipegalera.github.io/mostly_books/book-fastai/./images/Fastbook_Chapter_5_Image_Classification_31_0.png><h3 id=5-6-exporting-and-importing-a-model><a aria-label="Anchor link for: 5-6-exporting-and-importing-a-model" class=zola-anchor href=#5-6-exporting-and-importing-a-model>5.6 Exporting and importing a model</a></h3><p>Models with multiple layers, epochs, and parameters can take hours to train. Instead of starting over every time you run the notebook, the model can be saved and loaded again.<p><strong>Saving/Exporting a model</strong>:<pre class=language-python data-lang=python style=color:#839496;background-color:#002b36><code class=language-python data-lang=python><span>learn.</span><span style=color:#b58900>export</span><span style=color:#657b83>(</span><span>os.path.</span><span style=color:#b58900>abspath</span><span style=color:#657b83>(</span><span>'</span><span style=color:#2aa198>./my_export.pkl</span><span>'</span><span style=color:#657b83>))
</span></code></pre><p>To check that the model is saved, you can either navigate the folder and see the <code>.pkl</code>, or also you can call the <code>path.ls()</code> method and see the file printed.<p><strong>Loading/Importing a model</strong>:<pre class=language-python data-lang=python style=color:#839496;background-color:#002b36><code class=language-python data-lang=python><span>learn_inf </span><span style=color:#657b83>= </span><span style=color:#b58900>load_learner</span><span style=color:#657b83>(</span><span>'</span><span style=color:#2aa198>my_export.pkl</span><span>'</span><span style=color:#657b83>)
</span></code></pre><h3 id=5-7-testing-the-model-outside-the-fastai-environment><a aria-label="Anchor link for: 5-7-testing-the-model-outside-the-fastai-environment" class=zola-anchor href=#5-7-testing-the-model-outside-the-fastai-environment>5.7 Testing the model outside the fastai environment</a></h3><p>To see if the model would work outside the dataloader environment, I googled "Bengal cat" in google images and drag a random image into the Google Colab folder. I consider the image as tricky, as it contains a human holding a Bengal cat:</p><img alt="Random image finded in the internet" height=400 src=./images/test_image.jpg width=300><p>I simply called the <code>predict</code> method of the model trained before to see if it is as easy at it looks to use fastai.<pre class=language-python data-lang=python style=color:#839496;background-color:#002b36><code class=language-python data-lang=python><span>learn_inf.</span><span style=color:#b58900>predict</span><span style=color:#657b83>(</span><span>'</span><span style=color:#2aa198>test_image.jpg</span><span>'</span><span style=color:#657b83>)
</span></code></pre><pre style=color:#839496;background-color:#002b36><code><span>('Bengal',
</span><span> tensor(1),
</span><span> tensor([9.6365e-07, 9.9558e-01, 5.0118e-09, 2.5665e-08, 5.0663e-08, 4.2385e-03, 1.6677e-04, 1.0780e-08, 3.7194e-08, 1.1227e-07, 7.4500e-09, 3.3078e-06, 4.6680e-08, 8.1986e-07, 1.0533e-07, 8.3078e-08,
</span><span>         9.4154e-08, 2.7704e-08, 2.7787e-07, 2.6699e-06, 2.5465e-06, 7.7660e-09, 8.5412e-09, 1.5087e-07, 3.9640e-08, 3.1239e-08, 9.4404e-07, 3.2094e-08, 5.2541e-08, 7.1558e-09, 4.6352e-09, 1.7388e-08,
</span><span>         6.1503e-08, 6.6123e-08, 7.2059e-09, 9.4673e-08, 5.6627e-07]))
</span></code></pre><p>Surprisingly, it got the label of the image right. Loading the training data was less than 10 lines of code and the model itself is 1 line. It could handle random animal images and classify them regardless of the input image size, image format, or anything else.<h3 id=5-8-improving-our-model><a aria-label="Anchor link for: 5-8-improving-our-model" class=zola-anchor href=#5-8-improving-our-model>5.8 Improving Our Model</a></h3><p>The one-line-of-code model is great, but we might want to tweak the model and compare the results to increase the accuracy. We will explore 4 techniques or tools that can improve the model:<ol><li>Learning rate finder<li>Transfer Learning<li>Discriminative Learning rates<li>Selecting the right number of epochs</ol><h4 id=5-8-1-learning-rate-finder><a aria-label="Anchor link for: 5-8-1-learning-rate-finder" class=zola-anchor href=#5-8-1-learning-rate-finder>5.8.1 Learning rate finder</a></h4><p>The general idea of a <em>learning rate finder</em> is to start with a very very small learning rates, watch the loss function, and iterating with bigger and bigger learning rates.<p>We start with some number so small that we would never expect it to be too big to handle, like .00000007. We use that for one mini-batch, track the loss, and double the learning rate. We keep doing it until the loss gets worse. Once it started to get worse and worse, we should select a learning rate a bit lower than that point.<p>fastai method <code>lr_find()</code> does all this loop for us:<pre class=language-python data-lang=python style=color:#839496;background-color:#002b36><code class=language-python data-lang=python><span>learn </span><span style=color:#657b83>= </span><span style=color:#b58900>cnn_learner</span><span style=color:#657b83>(</span><span>dls, resnet34, </span><span style=color:#268bd2>metrics </span><span style=color:#657b83>= </span><span>error_rate</span><span style=color:#657b83>)
</span><span>learn.</span><span style=color:#b58900>lr_find</span><span style=color:#657b83>()
</span></code></pre><pre style=color:#839496;background-color:#002b36><code><span>SuggestedLRs(valley=tensor(0.0025))
</span></code></pre><p><img alt src=https://pipegalera.github.io/mostly_books/book-fastai/./images/Fastbook_Chapter_5_Image_Classification_40_2.png><pre class=language-python data-lang=python style=color:#839496;background-color:#002b36><code class=language-python data-lang=python><span style=color:#586e75># Let's call it the "leslie_smith_lr" in honor to the author of the orignal paper
</span><span>leslie_smith_lr </span><span style=color:#657b83>= </span><span style=color:#6c71c4>0.0025
</span><span>learn </span><span style=color:#657b83>= </span><span style=color:#b58900>cnn_learner</span><span style=color:#657b83>(</span><span>dls, resnet34, </span><span style=color:#268bd2>metrics </span><span style=color:#657b83>= </span><span>error_rate</span><span style=color:#657b83>)
</span><span>learn.</span><span style=color:#b58900>fine_tune</span><span style=color:#657b83>(</span><span style=color:#6c71c4>2</span><span>, </span><span style=color:#268bd2>base_lr </span><span style=color:#657b83>= </span><span>leslie_smith_lr</span><span style=color:#657b83>)
</span></code></pre><table border=0 class=dataframe><thead><tr style=text-align:center><th>epoch<th>train_loss<th>valid_loss<th>error_rate<th>time<tbody><tr><td>0<td>1.261431<td>0.310061<td>0.102842<td>01:10</table><table border=0 class=dataframe><thead><tr style=text-align:center><th>epoch<th>train_loss<th>valid_loss<th>error_rate<th>time<tbody><tr><td>0<td>0.547525<td>0.373586<td>0.115020<td>01:14<tr><td>1<td>0.348811<td>0.226233<td>0.068336<td>01:14</table><p>Compared with the baseline model we reduced slightly the error_rate. In the next tables, I will keep track of the improvements and the comparison of the methods.<h4 id=5-8-2-transfer-learning-and-freezing><a aria-label="Anchor link for: 5-8-2-transfer-learning-and-freezing" class=zola-anchor href=#5-8-2-transfer-learning-and-freezing>5.8.2 Transfer Learning and Freezing</a></h4><p><strong>Transfer learning</strong><p>The last layer in a CNN is the classification task. This pet breed classification task is a layer with 37 neurons with a softmax function that gives the probability of the image for each of the 37 classes.<p>But how can we use all this hard-consuming weighting parametrization in another image classification task?<p>We can take the model, ditch the last layer and substitute it for our new classification task. That's transfer learning - using the knowledge learned from a task and re-using it for another different.<p>In practical terms,we take the parameters/weights of the model and we substitute the last layer for the new task without starting the weighting from scratch. It saves time and also produces better results. <code>restnet34</code> is an example of this, as it is a pre-trained model with its custom parametrization.<p><strong>Freezing</strong><p>Transfer learning can be applied by a technique called freezing. By freezing you tell the model not to touch certain layers. They are "frozen".<p><em>Why you would want to freeze layers?</em><p>To focus on the layer that matters. As I said, <code>restnet34</code> is already trained beforehand. We can tell the model to focus more on the last layer, our classification task, and keep the former ones untouched. Freeze and unfreeze effectively allow you to decide which specific layers of your model you want to train at a given time.<p>Freezing is especially handy when you want to focus not only on the weighting but also on some parameters like the learning rate.<p>To allow transfer learning we can use <code>fit_one_cycle</code> method, instead of <code>fine_tune</code>. Here we load the model with our data and train it for 3 epochs:<pre class=language-python data-lang=python style=color:#839496;background-color:#002b36><code class=language-python data-lang=python><span>learn </span><span style=color:#657b83>= </span><span style=color:#b58900>cnn_learner</span><span style=color:#657b83>(</span><span>dls, resnet34, </span><span style=color:#268bd2>metrics </span><span style=color:#657b83>= </span><span>error_rate</span><span style=color:#657b83>)
</span><span>learn.</span><span style=color:#b58900>fit_one_cycle</span><span style=color:#657b83>(</span><span style=color:#6c71c4>3</span><span>, leslie_smith_lr</span><span style=color:#657b83>)
</span></code></pre><table border=0 class=dataframe><thead><tr style=text-align:center><th>epoch<th>train_loss<th>valid_loss<th>error_rate<th>time<tbody><tr><td>0<td>1.220214<td>0.328361<td>0.103518<td>01:13<tr><td>1<td>0.559653<td>0.242575<td>0.080514<td>01:11<tr><td>2<td>0.340312<td>0.220747<td>0.069689<td>01:11</table><p>Consider this model parametrization "froze". Using <code>unfreeze()</code> method allows the model to start over from the already weighting from <code>fit_one_cyle</code>, so it doesn't start from random weighting but the "frozen" parameters from the 3 first epochs of <code>fit_one_cyle</code>.<pre class=language-python data-lang=python style=color:#839496;background-color:#002b36><code class=language-python data-lang=python><span>learn.</span><span style=color:#b58900>unfreeze</span><span style=color:#657b83>()
</span></code></pre><p>It is is easier for the model to start from a pre-trained weighting than with random weighting. To illustrate this point let's try to search for an optimal learning rate again:<pre class=language-python data-lang=python style=color:#839496;background-color:#002b36><code class=language-python data-lang=python><span>learn.</span><span style=color:#b58900>lr_find</span><span style=color:#657b83>()
</span></code></pre><pre style=color:#839496;background-color:#002b36><code><span>SuggestedLRs(valley=4.365158383734524e-05)
</span></code></pre><p><img alt src=https://pipegalera.github.io/mostly_books/book-fastai/./images/Fastbook_Chapter_5_Image_Classification_49_2.png><p>In this graph, the Loss axis is way smaller than the previous one. The model is already trained beforehand and therefore trying mini-batches of different learning rates and iterating is easier.<p>To apply "transfer learning" we train the model with another 6 epochs that will start from the previous parametrization. We use the new learning rate as well.<pre class=language-python data-lang=python style=color:#839496;background-color:#002b36><code class=language-python data-lang=python><span>leslie_smith_lr_2 </span><span style=color:#657b83>= </span><span style=color:#6c71c4>4.365158383734524e-05
</span><span>learn.</span><span style=color:#b58900>fit_one_cycle</span><span style=color:#657b83>(</span><span style=color:#6c71c4>6</span><span>, leslie_smith_lr_2</span><span style=color:#657b83>)
</span></code></pre><p>Instead of printing the epoch results, from here on I'll show the results of the last epoch and the comparison with the other models:<table border=0 class=dataframe><thead><tr style=text-align:center><th>Model<th>Train Loss<th>Validation Loss<th>Error rate<tbody><tr><td>ResNet-34 Baseline (2 epochs)<td>0.330700<td>0.223524<td>0.071042<tr><td>ResNet-34 with Learning rate finder (2 epochs)<td>0.348811<td>0.226233<td>0.068336<tr><td><b>ResNet-34 with Transfer Learning (6 epochs)</b><td><b>0.534172</b><td><b>0.261891</b><td><b>0.083897</b></table><h4 id=5-8-3-discriminative-learning-rates><a aria-label="Anchor link for: 5-8-3-discriminative-learning-rates" class=zola-anchor href=#5-8-3-discriminative-learning-rates>5.8.3 Discriminative learning rates</a></h4><p>Like many good ideas in deep learning, the idea of <strong><em>Discriminative learning rates</em></strong> is extremely simple: use a lower learning rate for the early layers of the neural network, and a higher learning rate for the later layers<p>The first layer learns very simple foundations, like image edges and gradient detectors; these are likely to be just as useful for nearly any task. The later layers learn much more complex concepts, like the concept of â€œeyeâ€ and â€œsunset,â€ which might not be useful in your task at all - maybe youâ€™re classifying car models, for instance. So it makes sense to let the later layers fine-tune more quickly than earlier layers.<p>By default, fastai <code>cnn_learner</code> uses discriminative learning rates.<p>Letâ€™s use this approach to replicate the previous training, but this time using Discriminative learning rates using a slice range in the learning rate parameter: <code>lr_max=slice(4e-6,4e-4)</code>.<ul><li><p>The first value (<code>4e-6</code>) is the learning rate in the earliest layer of the neural network.</p><li><p>The second value (<code>4e-4</code>) is the learning rate of the final layer.</p><li><p>The layers in between will have learning rates that scale up equidistantly throughout that range - from the first until they reach the second value.</p></ul><pre class=language-python data-lang=python style=color:#839496;background-color:#002b36><code class=language-python data-lang=python><span style=color:#586e75># Model
</span><span>learn </span><span style=color:#657b83>= </span><span style=color:#b58900>cnn_learner</span><span style=color:#657b83>(</span><span>dls, resnet34, </span><span style=color:#268bd2>metrics </span><span style=color:#657b83>= </span><span>error_rate</span><span style=color:#657b83>)
</span><span style=color:#586e75># Pre-train the model
</span><span>learn.</span><span style=color:#b58900>fit_one_cycle</span><span style=color:#657b83>(</span><span style=color:#6c71c4>3</span><span>, leslie_smith_lr</span><span style=color:#657b83>)
</span><span>learn.</span><span style=color:#b58900>unfreeze</span><span style=color:#657b83>()
</span><span style=color:#586e75># Train the model with a learning rate range
</span><span>learn.</span><span style=color:#b58900>fit_one_cycle</span><span style=color:#657b83>(</span><span style=color:#6c71c4>12</span><span>, </span><span style=color:#268bd2>lr_max</span><span style=color:#657b83>=</span><span style=color:#859900>slice</span><span style=color:#657b83>(</span><span style=color:#6c71c4>4e-6</span><span>,</span><span style=color:#6c71c4>4e-4</span><span style=color:#657b83>))
</span></code></pre><table border=0 class=dataframe><thead><tr style=text-align:center><th>Model<th>Train Loss<th>Validation Loss<th>Error rate<tbody><tr><td>ResNet-34 Baseline (2 epochs)<td>0.330700<td>0.223524<td>0.071042<tr><td>ResNet-34 with Learning rate Finder (2 epochs)<td>0.348811<td>0.226233<td>0.068336<tr><td>ResNet-34 with Transfer Learning (6 epochs)<td>0.534172<td>0.261891<td>0.083897<tr><td><b>ResNet-34 with Discriminative learning rates (12 epochs)</b><td><b>0.049675</b><td><b>0.181254</b><td><b>0.048714</b></table><h4 id=5-8-4-selecting-the-number-of-epochs><a aria-label="Anchor link for: 5-8-4-selecting-the-number-of-epochs" class=zola-anchor href=#5-8-4-selecting-the-number-of-epochs>5.8.4 Selecting the Number of Epochs</a></h4><p>The more epochs, the more time and tries the model has to learn the trained data. Your first approach to training should be to simply pick a specific number of epochs that you are happy to wait for, and look at the training and validation loss plots.<p>Using <code>.plot_loss()</code> you can see if the validation loss keeps getting better with more epochs. If not, it is a waste of time to use more than the necessary epochs.<p>For some machine learning problems is worth keep training the model for a day to earn 1% more accuracy, such as programming competitions, but in most cases choosing the right model or better parametrization is going to be more important than squishing the last marginal accuracy point with 300 more epochs.<pre class=language-python data-lang=python style=color:#839496;background-color:#002b36><code class=language-python data-lang=python><span>learn.recorder.</span><span style=color:#b58900>plot_loss</span><span style=color:#657b83>()
</span></code></pre><p><img alt src=https://pipegalera.github.io/mostly_books/book-fastai/./images/Fastbook_Chapter_5_Image_Classification_60_0.png><h3 id=5-9-deeper-architectures><a aria-label="Anchor link for: 5-9-deeper-architectures" class=zola-anchor href=#5-9-deeper-architectures>5.9 Deeper Architectures</a></h3><p>In general, a model with more parameters can describe your data more accurately. A larger version of a ResNet will always be able to give us a better training loss, but it can suffer more from overfitting, basically because it has more parameters to suffer from overfitting.<p>Another downside of deeper architectures is that they take quite a bit longer to train. One technique that can speed things up a lot is <strong>mixed-precision training</strong>. This refers to using less-precise numbers (half-precision floating point, also called fp16) where possible during training.<p>Instead of using <code>.fit_one_cycle()</code> and then <code>unfreeze()</code> methods we tell fastai how many epochs to freeze with <code>freeze_epochs</code> since we are not changing the learning rates from one step to the other like in Discriminative learning rates.<pre class=language-python data-lang=python style=color:#839496;background-color:#002b36><code class=language-python data-lang=python><span style=color:#cb4b16>from </span><span>fastai.callback.fp16 </span><span style=color:#cb4b16>import </span><span style=color:#b58900>*
</span><span>learn </span><span style=color:#657b83>= </span><span style=color:#b58900>cnn_learner</span><span style=color:#657b83>(</span><span>dls, resnet50, </span><span style=color:#268bd2>metrics</span><span style=color:#657b83>=</span><span>error_rate</span><span style=color:#657b83>)</span><span>.</span><span style=color:#b58900>to_fp16</span><span style=color:#657b83>()
</span><span>learn.</span><span style=color:#b58900>fine_tune</span><span style=color:#657b83>(</span><span style=color:#6c71c4>6</span><span>, </span><span style=color:#268bd2>freeze_epochs</span><span style=color:#657b83>=</span><span style=color:#6c71c4>3</span><span style=color:#657b83>)
</span></code></pre><table border=0 class=dataframe><thead><tr style=text-align:center><th>epoch<th>train_loss<th>valid_loss<th>error_rate<th>time<tbody><tr><td>0<td>1.260760<td>0.327534<td>0.095399<td>01:07<tr><td>1<td>0.595598<td>0.297897<td>0.089310<td>01:07<tr><td>2<td>0.431712<td>0.256303<td>0.089986<td>01:07</table><table border=0 class=dataframe><thead><tr style=text-align:center><th>epoch<th>train_loss<th>valid_loss<th>error_rate<th>time<tbody><tr><td>0<td>0.286988<td>0.246470<td>0.079161<td>01:09<tr><td>1<td>0.323408<td>0.258964<td>0.091340<td>01:08<tr><td>2<td>0.262799<td>0.315306<td>0.083221<td>01:09<tr><td>3<td>0.167648<td>0.242762<td>0.073072<td>01:09<tr><td>4<td>0.090543<td>0.180670<td>0.056834<td>01:09<tr><td>5<td>0.060775<td>0.174947<td>0.050068<td>01:09</table><h3 id=5-10-final-model-results-comparison><a aria-label="Anchor link for: 5-10-final-model-results-comparison" class=zola-anchor href=#5-10-final-model-results-comparison>5.10 Final model results comparison</a></h3><p>Based on the validation loss and the error rate, a deeper and more complex architecture(RestNet50) and the model with discriminative learning rates hold the best results.<table border=0 class=dataframe><thead><tr style=text-align:center><th>Model<th>Train Loss<th>Validation Loss<th>Error rate<tbody><tr><td>ResNet-34 Baseline (2 epochs)<td>0.330700<td>0.223524<td>0.071042<tr><td>ResNet-34 with Learning rate Finder (2 epochs)<td>0.348811<td>0.226233<td>0.068336<tr><td>ResNet-34 with Transfer Learning (6 epochs)<td>0.534172<td>0.261891<td>0.083897<tr><td>ResNet-34 with Discriminative learning rates (12 epochs)<td>0.049675<td>0.181254<td><b>0.048714</b><tr><td>Mixed-Precision ResNet-50 (6 epochs)<td>0.060775<td><b>0.174947</b><td>0.050068</table><p>In any case, these techniques should be tried and evaluated for every image classification problem, as the results depend on the specific data. This is just an example of the applications and could easily improve any initial model baseline.<h2 id=chapter-6-other-computer-vision-problems><a aria-label="Anchor link for: chapter-6-other-computer-vision-problems" class=zola-anchor href=#chapter-6-other-computer-vision-problems>Chapter 6 - Other Computer Vision Problems</a></h2><ul><li>Multi-label classification<li>Regression.</ul><p>I will use Google Colab to run the code, as in Chapter 5 notes.<pre class=language-python data-lang=python style=color:#839496;background-color:#002b36><code class=language-python data-lang=python><span>!pip install </span><span style=color:#657b83>-</span><span>Uqq fastbook
</span><span>
</span><span>     </span><span style=color:#657b83>|</span><span>â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ</span><span style=color:#657b83>|</span><span> 727kB </span><span style=color:#6c71c4>29.0</span><span>MB</span><span style=color:#657b83>/</span><span>s
</span><span>     </span><span style=color:#657b83>|</span><span>â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ</span><span style=color:#657b83>| </span><span style=color:#6c71c4>1.2</span><span>MB </span><span style=color:#6c71c4>45.6</span><span>MB</span><span style=color:#657b83>/</span><span>s
</span><span>     </span><span style=color:#657b83>|</span><span>â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ</span><span style=color:#657b83>|</span><span> 194kB </span><span style=color:#6c71c4>47.3</span><span>MB</span><span style=color:#657b83>/</span><span>s
</span><span>     </span><span style=color:#657b83>|</span><span>â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ</span><span style=color:#657b83>|</span><span> 51kB </span><span style=color:#6c71c4>7.9</span><span>MB</span><span style=color:#657b83>/</span><span>s
</span><span>     </span><span style=color:#657b83>|</span><span>â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ</span><span style=color:#657b83>|</span><span> 61kB </span><span style=color:#6c71c4>9.2</span><span>MB</span><span style=color:#657b83>/</span><span>s
</span><span>     </span><span style=color:#657b83>|</span><span>â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ</span><span style=color:#657b83>|</span><span> 61kB </span><span style=color:#6c71c4>9.0</span><span>MB</span><span style=color:#657b83>/</span><span>s
</span><span>
</span></code></pre><pre class=language-python data-lang=python style=color:#839496;background-color:#002b36><code class=language-python data-lang=python><span style=color:#cb4b16>import </span><span>fastbook
</span><span>fastbook.</span><span style=color:#b58900>setup_book</span><span style=color:#657b83>()
</span><span style=color:#cb4b16>from </span><span>fastai.vision.all </span><span style=color:#cb4b16>import </span><span style=color:#b58900>*
</span><span>
</span><span>    Mounted at </span><span style=color:#657b83>/</span><span>content</span><span style=color:#657b83>/</span><span>gdrive
</span></code></pre><h3 id=6-1-multi-label-classification><a aria-label="Anchor link for: 6-1-multi-label-classification" class=zola-anchor href=#6-1-multi-label-classification>6.1 Multi-label classification</a></h3><p><strong>Multi-label classification</strong> is when you want to predict more than one label per image (or sometimes none at all). In practice, it is probably more common to have some images with zero matches or more than one match, we should probably expect in practice that multi-label classifiers are more widely applicable than single-label classifiers.<p><strong>PASCAL Visual Object Classes Challenge 2007 Dataset</strong><pre class=language-python data-lang=python style=color:#839496;background-color:#002b36><code class=language-python data-lang=python><span>path </span><span style=color:#657b83>= </span><span style=color:#b58900>untar_data</span><span style=color:#657b83>(</span><span>URLs.</span><span style=color:#268bd2>PASCAL_2007</span><span style=color:#657b83>)
</span></code></pre><pre class=language-python data-lang=python style=color:#839496;background-color:#002b36><code class=language-python data-lang=python><span>df </span><span style=color:#657b83>= </span><span>pd.</span><span style=color:#b58900>read_csv</span><span style=color:#657b83>(</span><span>path</span><span style=color:#657b83>/</span><span>'</span><span style=color:#2aa198>train.csv</span><span>'</span><span style=color:#657b83>)
</span><span>df.</span><span style=color:#b58900>head</span><span style=color:#657b83>()
</span></code></pre><table><thead><tr><th>fname<th>labels<th>is_valid<tbody><tr><td>000005.jpg<td>chair<td>True<tr><td>000007.jpg<td>car<td>True<tr><td>000009.jpg<td>horse person<td>True<tr><td>000012.jpg<td>car<td>False<tr><td>000016.jpg<td>bicycle<td>True</table><p><strong>Building the DataBlock</strong><p>The data is not preprocessed, so we will need to shape it correctly to use Fastai.<ol><li>Get the input path and the target variable</ol><p>The original dataset is a collection that returns a tuple of your independent and dependent variable for a single item. To use the <code>DataLoader</code> of Fastai we will need to format and preprocess the data. In a <code>DataLoader</code>, each mini-batch contains a batch of independent variables and a batch of dependent variables.<p>We can see the current shape of the data by calling <code>DataBlock.datasets</code> to create a Datasets object from the source.<pre class=language-python data-lang=python style=color:#839496;background-color:#002b36><code class=language-python data-lang=python><span>dblock </span><span style=color:#657b83>= </span><span style=color:#b58900>DataBlock</span><span style=color:#657b83>()
</span><span>dsets </span><span style=color:#657b83>= </span><span>dblock.</span><span style=color:#b58900>datasets</span><span style=color:#657b83>(</span><span>df</span><span style=color:#657b83>)
</span></code></pre><pre class=language-python data-lang=python style=color:#839496;background-color:#002b36><code class=language-python data-lang=python><span>dsets.train</span><span style=color:#268bd2>[</span><span style=color:#6c71c4>0</span><span style=color:#268bd2>]
</span></code></pre><pre style=color:#839496;background-color:#002b36><code><span>(fname       002815.jpg
</span><span> labels          person
</span><span> is_valid          True
</span><span> Name: 1414, dtype: object,
</span><span>
</span><span> fname       002815.jpg
</span><span> labels          person
</span><span> is_valid          True
</span><span> Name: 1414, dtype: object)
</span></code></pre><pre class=language-python data-lang=python style=color:#839496;background-color:#002b36><code class=language-python data-lang=python><span>dsets.valid</span><span style=color:#268bd2>[</span><span style=color:#6c71c4>1</span><span style=color:#268bd2>]
</span></code></pre><pre style=color:#839496;background-color:#002b36><code><span>(fname             000892.jpg
</span><span> labels      person motorbike
</span><span> is_valid               False
</span><span> Name: 443, dtype: object,
</span><span>
</span><span> fname             000892.jpg
</span><span> labels      person motorbike
</span><span> is_valid               False
</span><span> Name: 443, dtype: object)
</span></code></pre><p>The data is in the wrong format. Instead of a path to the images and the corresponding label, it simply returns a row of the DataFrame, twice. This is because by default, the <strong><code>DataBlock</code> assumes we have two things: input and target</strong>. Here we don't have a path or the target specified, so it returns the input twice.<p>We are going to need to grab the appropriate fields from the DataFrame, which we can do by passing <code>get_x</code> and <code>get_y</code> functions.<ul><li><code>get_x</code>: to create a function that points out the path of the files (in the <em>fname</em> column).</ul><pre class=language-python data-lang=python style=color:#839496;background-color:#002b36><code class=language-python data-lang=python><span style=color:#859900>def </span><span style=color:#b58900>get_images_name</span><span style=color:#657b83>(</span><span style=color:#268bd2>r</span><span style=color:#657b83>):
</span><span>  </span><span style=color:#859900>return </span><span>path</span><span style=color:#657b83>/</span><span>'</span><span style=color:#2aa198>train</span><span>'</span><span style=color:#657b83>/</span><span>r</span><span style=color:#268bd2>[</span><span>'</span><span style=color:#2aa198>fname</span><span>'</span><span style=color:#268bd2>]
</span></code></pre><ul><li><code>get_y</code>: to create a function that takes the targets from the labels column and splits on the space character as there are several labels.</ul><pre class=language-python data-lang=python style=color:#839496;background-color:#002b36><code class=language-python data-lang=python><span style=color:#859900>def </span><span style=color:#b58900>get_target_name</span><span style=color:#657b83>(</span><span style=color:#268bd2>r</span><span style=color:#657b83>):
</span><span>  </span><span style=color:#859900>return </span><span>r</span><span style=color:#268bd2>[</span><span>'</span><span style=color:#2aa198>labels</span><span>'</span><span style=color:#268bd2>]</span><span>.</span><span style=color:#b58900>split</span><span style=color:#657b83>(</span><span>' '</span><span style=color:#657b83>)
</span></code></pre><p>We will try <code>DataBlock.datasets</code> again, now with the data formatted using the functions:<pre class=language-python data-lang=python style=color:#839496;background-color:#002b36><code class=language-python data-lang=python><span style=color:#586e75># We add the data format to the DataBlock
</span><span>dblock </span><span style=color:#657b83>= </span><span style=color:#b58900>DataBlock</span><span style=color:#657b83>(</span><span style=color:#268bd2>get_x </span><span style=color:#657b83>= </span><span>get_images_name,
</span><span>                   </span><span style=color:#268bd2>get_y </span><span style=color:#657b83>= </span><span>get_target_name</span><span style=color:#657b83>)
</span><span style=color:#586e75># We update de dataset feeded to the DataBlock
</span><span>dsets </span><span style=color:#657b83>= </span><span>dblock.</span><span style=color:#b58900>datasets</span><span style=color:#657b83>(</span><span>df</span><span style=color:#657b83>)
</span></code></pre><pre class=language-python data-lang=python style=color:#839496;background-color:#002b36><code class=language-python data-lang=python><span>dsets.train</span><span style=color:#268bd2>[</span><span style=color:#6c71c4>34</span><span style=color:#268bd2>]
</span><span>
</span><span>    </span><span style=color:#657b83>(</span><span style=color:#b58900>Path</span><span style=color:#657b83>(</span><span>'</span><span style=color:#2aa198>/root/.fastai/data/pascal_2007/train/002359.jpg</span><span>'</span><span style=color:#657b83>)</span><span>,
</span><span>    </span><span style=color:#657b83>[</span><span>'</span><span style=color:#2aa198>dog</span><span>'</span><span style=color:#657b83>])
</span></code></pre><p>Now it returns correctly the datablock format: input (the <em>jpg</em>), and the target (the image label).<ol start=2><li>Transform the data into tensors</ol><p>We can use the parameter <code>ImageBlock</code> to transform these inputs and targets into tensors. It is a good practice to specify the <code>MultiCategoryBlock</code> method so fastai knows that is a multiclassification type of problem.<p>In any case, fastai would know that is this type of problem because of the multiple labeling.<pre class=language-python data-lang=python style=color:#839496;background-color:#002b36><code class=language-python data-lang=python><span>dblock </span><span style=color:#657b83>= </span><span style=color:#b58900>DataBlock</span><span style=color:#657b83>(</span><span style=color:#268bd2>blocks </span><span style=color:#657b83>=(</span><span>ImageBlock, MultiCategoryBlock</span><span style=color:#657b83>)</span><span>,
</span><span>                   </span><span style=color:#268bd2>get_x </span><span style=color:#657b83>= </span><span>get_images_name,
</span><span>                   </span><span style=color:#268bd2>get_y </span><span style=color:#657b83>= </span><span>get_target_name</span><span style=color:#657b83>)
</span><span>
</span><span>dsets </span><span style=color:#657b83>= </span><span>dblock.</span><span style=color:#b58900>datasets</span><span style=color:#657b83>(</span><span>df</span><span style=color:#657b83>)
</span></code></pre><pre class=language-python data-lang=python style=color:#839496;background-color:#002b36><code class=language-python data-lang=python><span>dsets.train</span><span style=color:#268bd2>[</span><span style=color:#6c71c4>0</span><span style=color:#268bd2>]
</span><span>
</span><span>    </span><span style=color:#657b83>(</span><span>PILImage mode=</span><span style=color:#268bd2>RGB </span><span>size=500x336,
</span><span>     </span><span style=color:#b58900>TensorMultiCategory</span><span style=color:#657b83>([</span><span style=color:#6c71c4>0.</span><span>, </span><span style=color:#6c71c4>0.</span><span>, </span><span style=color:#6c71c4>0.</span><span>, </span><span style=color:#6c71c4>0.</span><span>, </span><span style=color:#6c71c4>0.</span><span>, </span><span style=color:#6c71c4>0.</span><span>, </span><span style=color:#6c71c4>1.</span><span>,
</span><span>                          </span><span style=color:#6c71c4>0.</span><span>, </span><span style=color:#6c71c4>0.</span><span>, </span><span style=color:#6c71c4>0.</span><span>, </span><span style=color:#6c71c4>0.</span><span>, </span><span style=color:#6c71c4>0.</span><span>, </span><span style=color:#6c71c4>0.</span><span>, </span><span style=color:#6c71c4>1.</span><span>,
</span><span>                          </span><span style=color:#6c71c4>1.</span><span>, </span><span style=color:#6c71c4>0.</span><span>, </span><span style=color:#6c71c4>0.</span><span>, </span><span style=color:#6c71c4>0.</span><span>, </span><span style=color:#6c71c4>0.</span><span>, </span><span style=color:#6c71c4>0.</span><span style=color:#657b83>]))
</span></code></pre><p>By adding <code>ImageBlock</code>, each element is transformed into a tensor with a 1 representing the label of the image. The categories are <strong>hot-encoded</strong>. A vector of 0s and 1s in each location is represented in the data, to encode a list of integers. There are 20 categories, so the length of this list of 0s and 1 equals 20.<p>The reason we can't just use a list of category indices is that each list would be a different length. For example, an image with 2 labels would have 2 elements in a list and a length of 2. An image with 1 label would be a list of length 1. Pytorch/fastai require tensors where targets have to have the same length and that's why we use hot-encoding.<ol start=3><li>Create a training and validation data split</ol><p>For now, the dataset is not divided correctly into train and validation dataset. If we take a look at the dataset, it contains a column called <code>is_valid</code> that we have been ignoring. This column is a boolean that signals that the data belongs to the train set or the validation set.<pre class=language-python data-lang=python style=color:#839496;background-color:#002b36><code class=language-python data-lang=python><span>df.</span><span style=color:#b58900>head</span><span style=color:#657b83>()
</span></code></pre><table><thead><tr><th>fname<th>labels<th>is_valid<tbody><tr><td>000005.jpg<td>chair<td>True<tr><td>000007.jpg<td>car<td>True<tr><td>000009.jpg<td>horse person<td>True<tr><td>000012.jpg<td>car<td>False<tr><td>000016.jpg<td>bicycle<td>True</table><p><code>DataBlock</code> has been using a random split of the data by default. However, we can create a simple splitter function that takes the values in which <code>is_valid</code> is <code>False</code> and stored them in a variable called <code>train</code>, and if <code>True</code> stored them in a variable called <code>valid</code>.<pre class=language-python data-lang=python style=color:#839496;background-color:#002b36><code class=language-python data-lang=python><span style=color:#859900>def </span><span style=color:#b58900>splitter</span><span style=color:#657b83>(</span><span style=color:#268bd2>df</span><span style=color:#657b83>):
</span><span>  train </span><span style=color:#657b83>= </span><span>df.index</span><span style=color:#268bd2>[</span><span style=color:#657b83>~</span><span>df</span><span style=color:#268bd2>[</span><span>'</span><span style=color:#2aa198>is_valid</span><span>'</span><span style=color:#268bd2>]]</span><span>.</span><span style=color:#b58900>tolist</span><span style=color:#657b83>()
</span><span>  valid </span><span style=color:#657b83>= </span><span>df.index</span><span style=color:#268bd2>[</span><span>df</span><span style=color:#268bd2>[</span><span>'</span><span style=color:#2aa198>is_valid</span><span>'</span><span style=color:#268bd2>]]</span><span>.</span><span style=color:#b58900>tolist</span><span style=color:#657b83>()
</span><span>  </span><span style=color:#859900>return </span><span>train,valid
</span></code></pre><p>This function separates train and validation datasets to make the split. As long as it returns these 2 elements (train and validation), the <code>splitter</code> method of <code>DataBlock</code> can take it.<pre class=language-python data-lang=python style=color:#839496;background-color:#002b36><code class=language-python data-lang=python><span>dblock </span><span style=color:#657b83>= </span><span style=color:#b58900>DataBlock</span><span style=color:#657b83>(</span><span style=color:#268bd2>blocks</span><span style=color:#657b83>=(</span><span>ImageBlock, MultiCategoryBlock</span><span style=color:#657b83>)</span><span>,
</span><span>                   </span><span style=color:#268bd2>splitter </span><span style=color:#657b83>= </span><span>splitter,
</span><span>                   </span><span style=color:#268bd2>get_x </span><span style=color:#657b83>= </span><span>get_images_name,
</span><span>                   </span><span style=color:#268bd2>get_y </span><span style=color:#657b83>= </span><span>get_target_name</span><span style=color:#657b83>)
</span><span>dsets </span><span style=color:#657b83>= </span><span>dblock.</span><span style=color:#b58900>datasets</span><span style=color:#657b83>(</span><span>df</span><span style=color:#657b83>)
</span></code></pre><pre class=language-python data-lang=python style=color:#839496;background-color:#002b36><code class=language-python data-lang=python><span>dsets.train</span><span style=color:#268bd2>[</span><span style=color:#6c71c4>0</span><span style=color:#268bd2>]
</span><span>
</span><span>    </span><span style=color:#657b83>(</span><span>PILImage mode=</span><span style=color:#268bd2>RGB </span><span>size=500x333,
</span><span>     </span><span style=color:#b58900>TensorMultiCategory</span><span style=color:#657b83>([</span><span style=color:#6c71c4>0.</span><span>, </span><span style=color:#6c71c4>0.</span><span>, </span><span style=color:#6c71c4>0.</span><span>, </span><span style=color:#6c71c4>0.</span><span>, </span><span style=color:#6c71c4>0.</span><span>, </span><span style=color:#6c71c4>0.</span><span>, </span><span style=color:#6c71c4>1.</span><span>,
</span><span>                          </span><span style=color:#6c71c4>0.</span><span>, </span><span style=color:#6c71c4>0.</span><span>, </span><span style=color:#6c71c4>0.</span><span>, </span><span style=color:#6c71c4>0.</span><span>, </span><span style=color:#6c71c4>0.</span><span>, </span><span style=color:#6c71c4>0.</span><span>, </span><span style=color:#6c71c4>0.</span><span>,
</span><span>                          </span><span style=color:#6c71c4>0.</span><span>, </span><span style=color:#6c71c4>0.</span><span>, </span><span style=color:#6c71c4>0.</span><span>, </span><span style=color:#6c71c4>0.</span><span>, </span><span style=color:#6c71c4>0.</span><span>, </span><span style=color:#6c71c4>0.</span><span style=color:#657b83>]))
</span></code></pre><p>Now, the split of train and validation has the correct labeling.<ol start=4><li>Input resizing</ol><p>Lastly, for the <code>DataBlock</code> to be converted into a <code>DataLoader</code> it needs that every item is of the same size. To do this, we can use <code>RandomResizedCrop</code>.<p>To prove that, we can try the previous <code>DataBlock</code> without resizing:<pre class=language-python data-lang=python style=color:#839496;background-color:#002b36><code class=language-python data-lang=python><span>dls </span><span style=color:#657b83>= </span><span>dblock.</span><span style=color:#b58900>dataloaders</span><span style=color:#657b83>(</span><span>df</span><span style=color:#657b83>)
</span><span>dls.</span><span style=color:#b58900>show_batch</span><span style=color:#657b83>(</span><span style=color:#268bd2>nrows</span><span style=color:#657b83>=</span><span style=color:#6c71c4>1</span><span>, </span><span style=color:#268bd2>ncols</span><span style=color:#657b83>=</span><span style=color:#6c71c4>3</span><span style=color:#657b83>)
</span><span>
</span><span>    </span><span style=color:#657b83>---------------------------------------------------------------------------
</span><span>
</span><span>    </span><span style=color:#b58900>RuntimeError                              Traceback </span><span style=color:#657b83>(</span><span>most recent call last</span><span style=color:#657b83>)
</span><span>
</span><span>    </span><span style=color:#657b83><</span><span>ipython</span><span style=color:#657b83>-</span><span style=color:#859900>input</span><span style=color:#657b83>-</span><span style=color:#6c71c4>127</span><span style=color:#657b83>-</span><span>98aca4c77278</span><span style=color:#657b83>> </span><span style=color:#859900>in </span><span style=color:#657b83><</span><span>module</span><span style=color:#657b83>>()
</span><span>          </span><span style=color:#6c71c4>1 </span><span>dls </span><span style=color:#657b83>= </span><span>dblock.</span><span style=color:#b58900>dataloaders</span><span style=color:#657b83>(</span><span>df</span><span style=color:#657b83>)
</span><span>    </span><span style=color:#657b83>----> </span><span style=color:#6c71c4>2 </span><span>dls.</span><span style=color:#b58900>show_batch</span><span style=color:#657b83>(</span><span style=color:#268bd2>nrows</span><span style=color:#657b83>=</span><span style=color:#6c71c4>1</span><span>, </span><span style=color:#268bd2>ncols</span><span style=color:#657b83>=</span><span style=color:#6c71c4>3</span><span style=color:#657b83>)
</span><span>
</span><span>
</span><span>    </span><span style=color:#657b83>/</span><span style=color:#b58900>...</span><span style=color:#657b83>/</span><span>core.py </span><span style=color:#859900>in </span><span style=color:#b58900>show_batch</span><span style=color:#657b83>(</span><span style=color:#d33682>self</span><span>, b, max_n, ctxs, show, unique, </span><span style=color:#859900>**</span><span>kwargs</span><span style=color:#657b83>)
</span><span>         </span><span style=color:#6c71c4>98             </span><span>old_get_idxs </span><span style=color:#657b83>= </span><span style=color:#d33682>self</span><span>.get_idxs
</span><span>         </span><span style=color:#6c71c4>99             </span><span style=color:#d33682>self</span><span>.get_idxs </span><span style=color:#657b83>= </span><span style=color:#859900>lambda</span><span style=color:#657b83>: </span><span>Inf.zeros
</span><span>    </span><span style=color:#657b83>--> </span><span style=color:#6c71c4>100         </span><span style=color:#859900>if </span><span>b </span><span style=color:#859900>is </span><span style=color:#b58900>None</span><span style=color:#657b83>: </span><span>b </span><span style=color:#657b83>= </span><span style=color:#d33682>self</span><span>.</span><span style=color:#b58900>one_batch</span><span style=color:#657b83>()
</span><span>        </span><span style=color:#6c71c4>101         </span><span style=color:#859900>if not </span><span>show</span><span style=color:#657b83>: </span><span style=color:#859900>return </span><span style=color:#d33682>self</span><span>.</span><span style=color:#b58900>_pre_show_batch</span><span style=color:#657b83>(</span><span>b, </span><span style=color:#268bd2>max_n</span><span style=color:#657b83>=</span><span>max_n</span><span style=color:#657b83>)
</span><span>        </span><span style=color:#6c71c4>102         </span><span style=color:#b58900>show_batch</span><span style=color:#657b83>(*</span><span style=color:#d33682>self</span><span>.</span><span style=color:#b58900>_pre_show_batch</span><span style=color:#657b83>(</span><span>b, </span><span style=color:#268bd2>max_n</span><span style=color:#657b83>=</span><span>max_n</span><span style=color:#657b83>)</span><span>, </span><span style=color:#268bd2>ctxs</span><span style=color:#657b83>=</span><span>ctxs, </span><span style=color:#268bd2>max_n</span><span style=color:#657b83>=</span><span>max_n, </span><span style=color:#859900>**</span><span>kwargs</span><span style=color:#657b83>)
</span><span>
</span><span>
</span><span style=color:#657b83>[</span><span style=color:#b58900>...</span><span style=color:#657b83>]
</span><span>
</span><span>    </span><span style=color:#b58900>RuntimeError</span><span>: stack expects each tensor to be equal size,
</span><span>    but got </span><span style=color:#268bd2>[</span><span style=color:#6c71c4>3</span><span>, </span><span style=color:#6c71c4>500</span><span>, </span><span style=color:#6c71c4>441</span><span style=color:#268bd2>] </span><span>at entry </span><span style=color:#6c71c4>0 </span><span style=color:#859900>and </span><span style=color:#657b83>[</span><span style=color:#6c71c4>3</span><span>, </span><span style=color:#6c71c4>333</span><span>, </span><span style=color:#6c71c4>500</span><span style=color:#657b83>] </span><span>at entry </span><span style=color:#6c71c4>1
</span></code></pre><p>By including resizing, the <code>DataBlock</code> is correctly loaded and transformed into a <code>DataLoader</code>:<pre class=language-python data-lang=python style=color:#839496;background-color:#002b36><code class=language-python data-lang=python><span>dblock </span><span style=color:#657b83>= </span><span style=color:#b58900>DataBlock</span><span style=color:#657b83>(</span><span style=color:#268bd2>blocks</span><span style=color:#657b83>=(</span><span>ImageBlock, MultiCategoryBlock</span><span style=color:#657b83>)</span><span>,
</span><span>                   </span><span style=color:#268bd2>splitter </span><span style=color:#657b83>= </span><span>splitter,
</span><span>                   </span><span style=color:#268bd2>get_x </span><span style=color:#657b83>= </span><span>get_images_name,
</span><span>                   </span><span style=color:#268bd2>get_y </span><span style=color:#657b83>= </span><span>get_target_name,
</span><span>                   </span><span style=color:#268bd2>item_tfms </span><span style=color:#657b83>= </span><span style=color:#b58900>RandomResizedCrop</span><span style=color:#657b83>(</span><span style=color:#6c71c4>128</span><span>, </span><span style=color:#268bd2>min_scale</span><span style=color:#657b83>=</span><span style=color:#6c71c4>0.35</span><span style=color:#657b83>))
</span><span>dls </span><span style=color:#657b83>= </span><span>dblock.</span><span style=color:#b58900>dataloaders</span><span style=color:#657b83>(</span><span>df</span><span style=color:#657b83>)
</span><span>
</span><span>dls.</span><span style=color:#b58900>show_batch</span><span style=color:#657b83>(</span><span style=color:#268bd2>nrows</span><span style=color:#657b83>=</span><span style=color:#6c71c4>1</span><span>, </span><span style=color:#268bd2>ncols</span><span style=color:#657b83>=</span><span style=color:#6c71c4>3</span><span style=color:#657b83>)
</span></code></pre><p><img alt src=https://pipegalera.github.io/mostly_books/book-fastai/./images/output_40_0.png><p>Fastai includes a method called <code>summary</code> to check if anything goes wrong when you create your dataset. Besides the previous printing of the batch, we can call it to see errors, if any.<pre class=language-python data-lang=python style=color:#839496;background-color:#002b36><code class=language-python data-lang=python><span>dblock.summary
</span><span>
</span><span>    </span><span style=color:#657b83><</span><span>bound method DataBlock.summary of
</span><span>    </span><span style=color:#657b83><</span><span>fastai.data.block.DataBlock </span><span style=color:#859900>object </span><span>at </span><span style=color:#6c71c4>0x7f01e42df2d0</span><span style=color:#657b83>>>
</span></code></pre><p><strong>Binary Cross Entropy and Categorical Cross Entropy</strong><p>Now that we have our <code>DataLoaders</code> object we can move to define the loss function that we will use: <strong><em>Binary Cross Entropy</em></strong> (BCE).<p>BCE is a kind of loss function for <strong>multiple-labels</strong> classification problem. It is slightly different from <strong><em>Categorical Cross Entropy</em></strong>, the default loss function of <strong>single-label</strong> classification problem.<ul><li><p>In <strong>Categorical Cross Entropy</strong>, all the nodes of the final layer of the neural network go through a <code>softmax</code> transformation function that takes the most positive as the label predicted. The biggest positive value is transformed to 1 and the rest of the label values to 0.</p><li><p>In <strong>Binary Cross Entropy</strong>, all the nodes of the final layer pass through a <code>sigmoid</code> function that transforms all the positive values above a threshold to 1, and the rest to 0. Several values can be above the threshold, as multiple labels could be present in the image.</p></ul><p>The <em>"Binary"</em> comes from having a prediction <strong>for every category</strong>. Every label is either 0 or 1, depending on if the label is present in the image.<p class=mark>Why do we use sigmoid instead of softmax in multi-labeling?<p>Well, the image <strong>in single-label classification cannot be 2 things at the same time</strong>. An image is either labeled as "dog" or "cat", but cannot be both. Makes sense to use softmax and use the maximum value for the most probable predicted label - That would be a 1, and the rest 0s.<p>The problem in multi-labeling is different. In <strong>multicalss classification an image can contain several labels that are independent</strong>. For example a dog, a cat, and a person in the same photo. Therefore, the probability of the label "dog" should not depend on the probability of the label "person".<p><strong>Sigmoid transformation in practice</strong><p>To illustrate how sigmoid and the BCE loss function works we will build a simple model using the data that we formated before.<p>We will use Restnet18 and pass a small batch to explore the outputs.<pre class=language-python data-lang=python style=color:#839496;background-color:#002b36><code class=language-python data-lang=python><span style=color:#586e75># Model
</span><span>learn </span><span style=color:#657b83>= </span><span style=color:#b58900>cnn_learner</span><span style=color:#657b83>(</span><span>dls, resnet18</span><span style=color:#657b83>)
</span><span>
</span><span style=color:#586e75># Making sure that both the model and the data are processed in the GPU
</span><span>learn.model </span><span style=color:#657b83>= </span><span>learn.model.</span><span style=color:#b58900>cuda</span><span style=color:#657b83>()
</span><span>learn.dls.</span><span style=color:#b58900>to</span><span style=color:#657b83>(</span><span>'</span><span style=color:#2aa198>cuda</span><span>'</span><span style=color:#657b83>)
</span><span>
</span><span style=color:#586e75># Passing one batch
</span><span>X,y </span><span style=color:#657b83>= </span><span>dls.train.</span><span style=color:#b58900>one_batch</span><span style=color:#657b83>()
</span><span>
</span><span style=color:#586e75># Exploring the outputs of the last layer of the model
</span><span>outputs </span><span style=color:#657b83>= </span><span>learn.</span><span style=color:#b58900>model</span><span style=color:#657b83>(</span><span>X</span><span style=color:#657b83>)
</span><span style=color:#859900>print</span><span style=color:#657b83>(</span><span>outputs.shape</span><span style=color:#657b83>)
</span><span style=color:#859900>print</span><span style=color:#657b83>(</span><span>outputs</span><span style=color:#268bd2>[</span><span style=color:#6c71c4>0</span><span style=color:#268bd2>]</span><span style=color:#657b83>)
</span><span>
</span><span>
</span><span>    torch.</span><span style=color:#b58900>Size</span><span style=color:#657b83>([</span><span style=color:#6c71c4>64</span><span>, </span><span style=color:#6c71c4>20</span><span style=color:#657b83>])
</span><span>    </span><span style=color:#b58900>tensor</span><span style=color:#657b83>([ </span><span style=color:#6c71c4>0.0786</span><span>,  </span><span style=color:#6c71c4>0.6746</span><span>, </span><span style=color:#657b83>-</span><span style=color:#6c71c4>1.7760</span><span>,  </span><span style=color:#6c71c4>2.8992</span><span>,  </span><span style=color:#6c71c4>0.9360</span><span>, </span><span style=color:#657b83>-</span><span style=color:#6c71c4>0.1045</span><span>, </span><span style=color:#657b83>-</span><span style=color:#6c71c4>2.5859</span><span>,
</span><span>            </span><span style=color:#657b83>-</span><span style=color:#6c71c4>0.3760</span><span>, </span><span style=color:#657b83>-</span><span style=color:#6c71c4>0.6101</span><span>, </span><span style=color:#657b83>-</span><span style=color:#6c71c4>0.6136</span><span>,  </span><span style=color:#6c71c4>3.0267</span><span>, </span><span style=color:#657b83>-</span><span style=color:#6c71c4>0.5890</span><span>, </span><span style=color:#657b83>-</span><span style=color:#6c71c4>0.2249</span><span>, </span><span style=color:#657b83>-</span><span style=color:#6c71c4>0.5697</span><span>,
</span><span>            </span><span style=color:#657b83>-</span><span style=color:#6c71c4>1.4767</span><span>,  </span><span style=color:#6c71c4>0.2276</span><span>,  </span><span style=color:#6c71c4>0.2324</span><span>, </span><span style=color:#657b83>-</span><span style=color:#6c71c4>2.0516</span><span>,  </span><span style=color:#6c71c4>0.7298</span><span>, </span><span style=color:#657b83>-</span><span style=color:#6c71c4>1.1993</span><span style=color:#657b83>]</span><span>,
</span><span>            </span><span style=color:#268bd2>device</span><span style=color:#657b83>=</span><span>'</span><span style=color:#2aa198>cuda:0</span><span>', </span><span style=color:#268bd2>grad_fn</span><span style=color:#657b83>=<</span><span>SelectBackward</span><span style=color:#657b83>>)
</span></code></pre><p class=mark>What are these tensor values?<p>These are values corresponding to the nodes of the last layer. Note that these values haven't gone yet through the transformation function (sigmoid/softmax/others) that gets you the final label prediction. <strong>After</strong> the transformation function, these outputs will be either 0s (not that label) or 1s (label identified).<p class=mark>What represents the "64" and "20" in torch.Size([64, 20])?<p>64 Refers to the number of images in the batch. Every batch is made of 64 images. Trying to select the 65th image (<code>outputs[64]</code>) will show an out-of-range error because a batch contains only 64 images.<pre class=language-python data-lang=python style=color:#839496;background-color:#002b36><code class=language-python data-lang=python><span>outputs</span><span style=color:#268bd2>[</span><span style=color:#6c71c4>64</span><span style=color:#268bd2>]
</span><span>
</span><span>
</span><span>    </span><span style=color:#657b83>---------------------------------------------------------------------------
</span><span>
</span><span>    </span><span style=color:#b58900>IndexError                                Traceback </span><span style=color:#657b83>(</span><span>most recent call last</span><span style=color:#657b83>)
</span><span>
</span><span>    </span><span style=color:#657b83><</span><span>ipython</span><span style=color:#657b83>-</span><span style=color:#859900>input</span><span style=color:#657b83>-</span><span style=color:#6c71c4>134</span><span style=color:#657b83>-</span><span>2751f6a48786</span><span style=color:#657b83>> </span><span style=color:#859900>in </span><span style=color:#657b83><</span><span>module</span><span style=color:#657b83>>()
</span><span>    </span><span style=color:#657b83>----> </span><span style=color:#6c71c4>1 </span><span>outputs</span><span style=color:#268bd2>[</span><span style=color:#6c71c4>64</span><span style=color:#268bd2>]
</span><span>
</span><span>
</span><span>    </span><span style=color:#b58900>IndexError</span><span>: index </span><span style=color:#6c71c4>64 </span><span style=color:#859900>is </span><span>out of bounds </span><span style=color:#859900>for </span><span>dimension 0 </span><span style=color:#839496;background-color:#6e2e32>with</span><span> size 64
</span></code></pre><p>The "20" are the number of categories or labels. It represents the last layer in the neural network. It has 20 nodes corresponding to the 20 different categories/labels.<p>Now that we know the output of the model, we can apply to them a sigmoid transformation and the Binary Cross Entropy loss. We will take the first image of the batch <code>output[0]</code> and can call the <code>sigmoid()</code> method on it to see the difference in the results:<pre class=language-python data-lang=python style=color:#839496;background-color:#002b36><code class=language-python data-lang=python><span style=color:#859900>print</span><span style=color:#657b83>(</span><span>outputs</span><span style=color:#268bd2>[</span><span style=color:#6c71c4>0</span><span style=color:#268bd2>]</span><span style=color:#657b83>)
</span><span>
</span><span>    </span><span style=color:#b58900>tensor</span><span style=color:#657b83>([ </span><span style=color:#6c71c4>0.0786</span><span>,  </span><span style=color:#6c71c4>0.6746</span><span>, </span><span style=color:#657b83>-</span><span style=color:#6c71c4>1.7760</span><span>,  </span><span style=color:#6c71c4>2.8992</span><span>,  </span><span style=color:#6c71c4>0.9360</span><span>,
</span><span>            </span><span style=color:#657b83>-</span><span style=color:#6c71c4>0.1045</span><span>, </span><span style=color:#657b83>-</span><span style=color:#6c71c4>2.5859</span><span>, </span><span style=color:#657b83>-</span><span style=color:#6c71c4>0.3760</span><span>, </span><span style=color:#657b83>-</span><span style=color:#6c71c4>0.6101</span><span>, </span><span style=color:#657b83>-</span><span style=color:#6c71c4>0.6136</span><span>,
</span><span>             </span><span style=color:#6c71c4>3.0267</span><span>, </span><span style=color:#657b83>-</span><span style=color:#6c71c4>0.5890</span><span>, </span><span style=color:#657b83>-</span><span style=color:#6c71c4>0.2249</span><span>, </span><span style=color:#657b83>-</span><span style=color:#6c71c4>0.5697</span><span>, </span><span style=color:#657b83>-</span><span style=color:#6c71c4>1.4767</span><span>,
</span><span>             </span><span style=color:#6c71c4>0.2276</span><span>,  </span><span style=color:#6c71c4>0.2324</span><span>, </span><span style=color:#657b83>-</span><span style=color:#6c71c4>2.0516</span><span>,  </span><span style=color:#6c71c4>0.7298</span><span>, </span><span style=color:#657b83>-</span><span style=color:#6c71c4>1.1993</span><span style=color:#657b83>]</span><span>,
</span><span>           </span><span style=color:#268bd2>device</span><span style=color:#657b83>=</span><span>'</span><span style=color:#2aa198>cuda:0</span><span>', </span><span style=color:#268bd2>grad_fn</span><span style=color:#657b83>=<</span><span>SelectBackward</span><span style=color:#657b83>>)
</span><span>
</span><span style=color:#859900>print</span><span style=color:#657b83>(</span><span>outputs.</span><span style=color:#b58900>sigmoid</span><span style=color:#657b83>()</span><span style=color:#268bd2>[</span><span style=color:#6c71c4>0</span><span style=color:#268bd2>]</span><span style=color:#657b83>)
</span><span>
</span><span>    </span><span style=color:#b58900>tensor</span><span style=color:#657b83>([</span><span style=color:#6c71c4>0.5196</span><span>, </span><span style=color:#6c71c4>0.6625</span><span>, </span><span style=color:#6c71c4>0.1448</span><span>, </span><span style=color:#6c71c4>0.9478</span><span>, </span><span style=color:#6c71c4>0.7183</span><span>,
</span><span>            </span><span style=color:#6c71c4>0.4739</span><span>, </span><span style=color:#6c71c4>0.0700</span><span>, </span><span style=color:#6c71c4>0.4071</span><span>, </span><span style=color:#6c71c4>0.3520</span><span>, </span><span style=color:#6c71c4>0.3512</span><span>,
</span><span>            </span><span style=color:#6c71c4>0.9538</span><span>, </span><span style=color:#6c71c4>0.3569</span><span>, </span><span style=color:#6c71c4>0.4440</span><span>, </span><span style=color:#6c71c4>0.3613</span><span>, </span><span style=color:#6c71c4>0.1859</span><span>,
</span><span>            </span><span style=color:#6c71c4>0.5566</span><span>, </span><span style=color:#6c71c4>0.5578</span><span>, </span><span style=color:#6c71c4>0.1139</span><span>, </span><span style=color:#6c71c4>0.6748</span><span>, </span><span style=color:#6c71c4>0.2316</span><span style=color:#657b83>]</span><span>,
</span><span>           </span><span style=color:#268bd2>device</span><span style=color:#657b83>=</span><span>'</span><span style=color:#2aa198>cuda:0</span><span>', </span><span style=color:#268bd2>grad_fn</span><span style=color:#657b83>=<</span><span>SelectBackward</span><span style=color:#657b83>>)
</span></code></pre><p>Notice that the sigmoid function transforms all the predictions of the model (outputs) into a <strong>range 0 to 1</strong>. This is very useful for Binary Cross Entropy loss as it requires every label to be either a 1 or a 0.<p>Remember that each of the 20 values of the <code>tensor</code> represents a label, and the number resulting from this transformation represents the probability of this label.<p class=mark>How do we select which predictions are 1s and which ones 0s?<p>The easiest solution is <strong>setting a threshold</strong>, a value, positive enough that we consider that the label is predicted. All the values more than this threshold are transformed to 1, or labels predicted.<p>For example, let's take the last outputs in <code>outputs.sigmoid()[0]</code> above and set a threshold of 0.7. The label associated with the node with the value <code>0.9478</code> and <code>0.7183</code> are the predicted labels, for the 18 other labels are not activated as they are below the threshold.<p>Here we have shown the transformation for the first image - index 0 (<code>[0]</code>). In practice, we apply sigmoid for every batch of the model and select the values for Binary Cross Entropy into the same step as we see next.<p><strong>Sigmoid Threshold Optimiazion</strong><p>The default threshold used for the Sigmoid transformation is 0.5. However, it can be other values as we saw in the last section setting 0.7. There is <strong>no way to see if the default value is a good threshold before you try with several</strong> thresholds.<p>To test this, we will build the model with different thresholds and give them some epochs to see if the accuracy changes.<pre class=language-python data-lang=python style=color:#839496;background-color:#002b36><code class=language-python data-lang=python><span style=color:#586e75># Deeper Model with more batches
</span><span>learn </span><span style=color:#657b83>= </span><span style=color:#b58900>cnn_learner</span><span style=color:#657b83>(</span><span>dls, resnet50,
</span><span>                    </span><span style=color:#268bd2>metrics </span><span style=color:#657b83>= </span><span style=color:#b58900>partial</span><span style=color:#657b83>(</span><span>accuracy_multi, </span><span style=color:#268bd2>thresh </span><span style=color:#657b83>= </span><span style=color:#6c71c4>0.2</span><span style=color:#657b83>))
</span><span>
</span><span style=color:#586e75># Optimize the learning rate
</span><span>lr_suggested </span><span style=color:#657b83>= </span><span>learn.</span><span style=color:#b58900>lr_find</span><span style=color:#657b83>()</span><span style=color:#268bd2>[</span><span style=color:#6c71c4>0</span><span style=color:#268bd2>]
</span><span>
</span><span style=color:#586e75># Freeze the first 5 epochs and run 5 epochs
</span><span>learn.</span><span style=color:#b58900>fine_tune</span><span style=color:#657b83>(</span><span style=color:#6c71c4>5</span><span>, </span><span style=color:#268bd2>base_lr </span><span style=color:#657b83>= </span><span>lr_suggested, </span><span style=color:#268bd2>freeze_epochs</span><span style=color:#657b83>= </span><span style=color:#6c71c4>5</span><span style=color:#657b83>)
</span></code></pre><table><thead><tr><th>epoch<th>train_loss<th>valid_loss<th>accuracy_multi<th>time<tbody><tr><td>0<td>0.988882<td>0.733648<td>0.200498<td>00:40<tr><td>1<td>0.897558<td>0.651835<td>0.226036<td>00:40<tr><td>2<td>0.797924<td>0.555892<td>0.264064<td>00:40<tr><td>3<td>0.654679<td>0.331369<td>0.504701<td>00:40<tr><td>4<td>0.454360<td>0.168649<td>0.888008<td>00:41</table><table border=0 class=dataframe><thead><tr style=text-align:left><th>epoch<th>train_loss<th>valid_loss<th>accuracy_multi<th>time<tbody><tr><td>0<td>0.192024<td>0.137152<td>0.931693<td>00:45<tr><td>1<td>0.164923<td>0.118155<td>0.942410<td>00:46<tr><td>2<td>0.139310<td>0.108408<td>0.952570<td>00:46<tr><td>3<td>0.118630<td>0.106424<td>0.950259<td>00:45<tr><td>4<td>0.104928<td>0.105443<td>0.952151<td>00:46</table><p>Please note that instead of changing the entire model you can use <code>metrics</code> and <code>partial</code>. The sigmoid threshold only applies to the last layer of the neural network.<pre class=language-python data-lang=python style=color:#839496;background-color:#002b36><code class=language-python data-lang=python><span>learn.metrics </span><span style=color:#657b83>= </span><span style=color:#b58900>partial</span><span style=color:#657b83>(</span><span>accuracy_multi, </span><span style=color:#268bd2>thresh </span><span style=color:#657b83>= </span><span style=color:#6c71c4>0.5</span><span style=color:#657b83>)
</span><span>learn.</span><span style=color:#b58900>validate</span><span style=color:#657b83>()
</span><span>
</span><span>    </span><span style=color:#657b83>(</span><span style=color:#586e75>#2) [0.10544303804636002,0.9638046622276306]
</span></code></pre><p>Using <code>validate()</code> returns the validation loss (<code>valid_loss</code>) and the metrics loss (<code>accuracy_multi</code> in this case). A threshold of 0.5 produces a slightly better accuracy loss (0.964 vs previous 0.952)<p>As you can imagine, there must be a way to loop over several thresholds instead of trying all possible thresholds by hand.<p>To loop over different values we can make a batch of predictions using <code>get_preds</code> and use this batch of predictions to loop a range of possible thresholds and compare accuracy.<pre class=language-python data-lang=python style=color:#839496;background-color:#002b36><code class=language-python data-lang=python><span style=color:#586e75># Batch of predictions
</span><span>train, targs </span><span style=color:#657b83>= </span><span>learn.</span><span style=color:#b58900>get_preds</span><span style=color:#657b83>()
</span><span>
</span><span style=color:#586e75># Possible sigmoid thresholds, from 0.05 to 0.95
</span><span>thr </span><span style=color:#657b83>= </span><span>torch.</span><span style=color:#b58900>linspace</span><span style=color:#657b83>(</span><span style=color:#6c71c4>0.05</span><span>,</span><span style=color:#6c71c4>0.95</span><span>,</span><span style=color:#6c71c4>29</span><span style=color:#657b83>)
</span><span>
</span><span style=color:#586e75># Accuracy loop
</span><span>accs </span><span style=color:#657b83>= [</span><span style=color:#b58900>accuracy_multi</span><span style=color:#657b83>(</span><span>train, targs, </span><span style=color:#268bd2>thresh</span><span style=color:#657b83>=</span><span>i, </span><span style=color:#268bd2>sigmoid</span><span style=color:#657b83>=</span><span style=color:#b58900>False</span><span style=color:#657b83>) </span><span style=color:#859900>for </span><span>i </span><span style=color:#859900>in </span><span>thr</span><span style=color:#657b83>]
</span><span>
</span><span style=color:#586e75># plot them
</span><span>plt.</span><span style=color:#b58900>plot</span><span style=color:#657b83>(</span><span>xs,accs</span><span style=color:#657b83>)
</span></code></pre><p><img alt src=https://pipegalera.github.io/mostly_books/book-fastai/./images/output_69_1.png><p>The x-axis denotes the threshold values, and the y-axis the accuracy values. We can see that a sigmoid threshold between 0.45 and 0.7 gives us around 0.96 accuracies in the validation set.<p><code>get_preds()</code> apply by default sigmoid, so you will have to set <code>accuracy_multi(sigmoid=False)</code> in the model to not pass the transformation twice.<h3 id=6-2-regression><a aria-label="Anchor link for: 6-2-regression" class=zola-anchor href=#6-2-regression>6.2 Regression</a></h3><p><strong>Regression</strong> is when your labels are one or several numbers - a quantity instead of a category.<p>Image regression refers to learning from a dataset in which the independent variable is an image or element, and <strong>the dependent variable is one or more floats</strong>.<p>Perhaps we have an independent variable thatâ€™s an image, and a dependent thatâ€™s text (e.g. generating a caption from an image); or perhaps we have an independent variable thatâ€™s text and a dependent thatâ€™s an image (e.g. generating an image from a caption).<p>To illustrate this kind of model weâ€™re going to do a <strong>key point model</strong>. A key point refers to a specific location represented in an image. So the input is face images, and the output should be a float with the coordinates of the center of the face.<p><strong>Head Pose Dataset</strong><p>The data needs a little preprocessing and formating. The idea is the same as before, creating a function that points to the path of the data and create targets.<p>The path of the images is inside objects formatted as <code>obj</code>. The targets will be created with a function that calculates the center of the image. The model will try to predict the coordinates of the center of the image.<pre class=language-python data-lang=python style=color:#839496;background-color:#002b36><code class=language-python data-lang=python><span style=color:#586e75># Load data
</span><span>path </span><span style=color:#657b83>= </span><span style=color:#b58900>untar_data</span><span style=color:#657b83>(</span><span>URLs.</span><span style=color:#268bd2>BIWI_HEAD_POSE</span><span style=color:#657b83>)
</span></code></pre><div><style>progress{background-size:auto;border:none}.progress-bar-interrupted,.progress-bar-interrupted::-webkit-progress-bar{background:#f44336}</style><progress max=452316199 style=vertical-align:middle;width:300px;height:20px value=452321280></progress> 100.00% [452321280/452316199 00:09<00:00 < ] div> <p>The data is inside this objects <code>obj</code> and there are 24 objects.</p> <pre style=color:#839496;background-color:#002b36><code><span>path.ls()
</span><span>
</span><span>    (#50) [Path('/root/.fastai/data/biwi_head_pose/14.obj'),
</span><span>           Path('/root/.fastai/data/biwi_head_pose/18'),
</span><span>           Path('/root/.fastai/data/biwi_head_pose/06.obj'),
</span><span>           Path('/root/.fastai/data/biwi_head_pose/io_sample.cpp'),
</span><span>           ...]
</span></code></pre> <p>Every object has 1000 images and labeled poses.</p> <pre style=color:#839496;background-color:#002b36><code><span>(path/'01').ls()
</span><span>
</span><span>    (#1000) [Path('/root/.fastai/data/biwi_head_pose/01/frame_00307_pose.txt'),
</span><span>             Path('/root/.fastai/data/biwi_head_pose/01/frame_00159_pose.txt'),
</span><span>             Path('/root/.fastai/data/biwi_head_pose/01/frame_00363_pose.txt'),
</span><span>             Path('/root/.fastai/data/biwi_head_pose/01/frame_00434_pose.txt'),
</span><span>             ...]
</span></code></pre> <p>We will create the function <code>img2pose</code> to extract the pose path.</p> <pre class=language-python data-lang=python style=color:#839496;background-color:#002b36><code class=language-python data-lang=python><span>img_files </span><span style=color:#657b83>= </span><span style=color:#b58900>get_image_files</span><span style=color:#657b83>(</span><span>path</span><span style=color:#657b83>)
</span><span style=color:#586e75># write a function that converts an image filename
</span><span style=color:#859900>def </span><span style=color:#b58900>img2pose</span><span style=color:#657b83>(</span><span style=color:#268bd2>x</span><span style=color:#657b83>): </span><span style=color:#859900>return </span><span style=color:#b58900>Path</span><span style=color:#657b83>(</span><span style=color:#268bd2>f</span><span>'</span><span style=color:#657b83>{</span><span style=color:#859900>str</span><span style=color:#657b83>(</span><span>x</span><span style=color:#657b83>)</span><span style=color:#268bd2>[</span><span>:</span><span style=color:#657b83>-</span><span style=color:#6c71c4>7</span><span style=color:#268bd2>]</span><span style=color:#657b83>}</span><span style=color:#2aa198>pose.txt</span><span>'</span><span style=color:#657b83>)
</span></code></pre> <p>Now that we have the pose and the image path, we should have the images in <em>jpg</em> and the labels in <em>txt</em> format under the same identifier.</p> <pre class=language-python data-lang=python style=color:#839496;background-color:#002b36><code class=language-python data-lang=python><span style=color:#859900>print</span><span style=color:#657b83>(</span><span>img_files</span><span style=color:#268bd2>[</span><span style=color:#6c71c4>0</span><span style=color:#268bd2>]</span><span style=color:#657b83>)
</span><span style=color:#859900>print</span><span style=color:#657b83>(</span><span style=color:#b58900>img2pose</span><span style=color:#657b83>(</span><span>img_files</span><span style=color:#268bd2>[</span><span style=color:#6c71c4>0</span><span style=color:#268bd2>]</span><span style=color:#657b83>))
</span><span>
</span><span>    </span><span style=color:#657b83>/</span><span>root</span><span style=color:#657b83>/</span><span>.fastai</span><span style=color:#657b83>/</span><span>data</span><span style=color:#657b83>/</span><span>biwi_head_pose</span><span style=color:#657b83>/</span><span style=color:#6c71c4>18</span><span style=color:#657b83>/</span><span>frame_00518_rgb.jpg
</span><span>    </span><span style=color:#657b83>/</span><span>root</span><span style=color:#657b83>/</span><span>.fastai</span><span style=color:#657b83>/</span><span>data</span><span style=color:#657b83>/</span><span>biwi_head_pose</span><span style=color:#657b83>/</span><span style=color:#6c71c4>18</span><span style=color:#657b83>/</span><span>frame_00518_pose.txt
</span></code></pre> <p>Let's take a look at an image.</p> <pre class=language-python data-lang=python style=color:#839496;background-color:#002b36><code class=language-python data-lang=python><span>im </span><span style=color:#657b83>= </span><span>PILImage.</span><span style=color:#b58900>create</span><span style=color:#657b83>(</span><span>img_files</span><span style=color:#268bd2>[</span><span style=color:#6c71c4>0</span><span style=color:#268bd2>]</span><span style=color:#657b83>)
</span><span>im.</span><span style=color:#b58900>to_thumb</span><span style=color:#657b83>(</span><span style=color:#6c71c4>224</span><span style=color:#657b83>)
</span></code></pre> <p><img alt src=https://pipegalera.github.io/mostly_books/book-fastai/./images/output_83_0.png></p> <p>We extract the center of the image creating a function that returns the coordinates as a tensor of two items. However, the details of the function are not important. Every dataset will require a different cleaning a formatting process.</p> <pre class=language-python data-lang=python style=color:#839496;background-color:#002b36><code class=language-python data-lang=python><span>cal </span><span style=color:#657b83>= </span><span>np.</span><span style=color:#b58900>genfromtxt</span><span style=color:#657b83>(</span><span>path</span><span style=color:#657b83>/</span><span>'</span><span style=color:#2aa198>01</span><span>'</span><span style=color:#657b83>/</span><span>'</span><span style=color:#2aa198>rgb.cal</span><span>', </span><span style=color:#268bd2>skip_footer</span><span style=color:#657b83>=</span><span style=color:#6c71c4>6</span><span style=color:#657b83>)
</span></code></pre> <pre class=language-python data-lang=python style=color:#839496;background-color:#002b36><code class=language-python data-lang=python><span style=color:#859900>def </span><span style=color:#b58900>get_ctr</span><span style=color:#657b83>(</span><span style=color:#268bd2>f</span><span style=color:#657b83>):
</span><span>  ctr </span><span style=color:#657b83>= </span><span>np.</span><span style=color:#b58900>genfromtxt</span><span style=color:#657b83>(</span><span style=color:#b58900>img2pose</span><span style=color:#657b83>(</span><span>f</span><span style=color:#657b83>)</span><span>, </span><span style=color:#268bd2>skip_header</span><span style=color:#657b83>=</span><span style=color:#6c71c4>3</span><span style=color:#657b83>)
</span><span>  c1 </span><span style=color:#657b83>= </span><span>ctr</span><span style=color:#268bd2>[</span><span style=color:#6c71c4>0</span><span style=color:#268bd2>] </span><span style=color:#657b83>* </span><span>cal</span><span style=color:#268bd2>[</span><span style=color:#6c71c4>0</span><span style=color:#268bd2>][</span><span style=color:#6c71c4>0</span><span style=color:#268bd2>]</span><span style=color:#657b83>/</span><span>ctr</span><span style=color:#268bd2>[</span><span style=color:#6c71c4>2</span><span style=color:#268bd2>] </span><span style=color:#657b83>+ </span><span>cal</span><span style=color:#268bd2>[</span><span style=color:#6c71c4>0</span><span style=color:#268bd2>][</span><span style=color:#6c71c4>2</span><span style=color:#268bd2>]
</span><span>  c2 </span><span style=color:#657b83>= </span><span>ctr</span><span style=color:#268bd2>[</span><span style=color:#6c71c4>1</span><span style=color:#268bd2>] </span><span style=color:#657b83>* </span><span>cal</span><span style=color:#268bd2>[</span><span style=color:#6c71c4>1</span><span style=color:#268bd2>][</span><span style=color:#6c71c4>1</span><span style=color:#268bd2>]</span><span style=color:#657b83>/</span><span>ctr</span><span style=color:#268bd2>[</span><span style=color:#6c71c4>2</span><span style=color:#268bd2>] </span><span style=color:#657b83>+ </span><span>cal</span><span style=color:#268bd2>[</span><span style=color:#6c71c4>1</span><span style=color:#268bd2>][</span><span style=color:#6c71c4>2</span><span style=color:#268bd2>]
</span><span>  </span><span style=color:#859900>return </span><span style=color:#b58900>tensor</span><span style=color:#657b83>([</span><span>c1,c2</span><span style=color:#657b83>])
</span></code></pre> <pre class=language-python data-lang=python style=color:#839496;background-color:#002b36><code class=language-python data-lang=python><span style=color:#586e75># The center of the image is the label that we are trying to predict
</span><span style=color:#b58900>get_ctr</span><span style=color:#657b83>(</span><span>img_files</span><span style=color:#268bd2>[</span><span style=color:#6c71c4>0</span><span style=color:#268bd2>]</span><span style=color:#657b83>)
</span><span>
</span><span>    </span><span style=color:#b58900>tensor</span><span style=color:#657b83>([</span><span style=color:#6c71c4>344.3451</span><span>, </span><span style=color:#6c71c4>330.0573</span><span style=color:#657b83>])
</span></code></pre> <p><strong>Building the DataBlock</strong></p> <pre class=language-python data-lang=python style=color:#839496;background-color:#002b36><code class=language-python data-lang=python><span>biwi_data </span><span style=color:#657b83>= </span><span style=color:#b58900>DataBlock</span><span style=color:#657b83>(
</span><span>    </span><span style=color:#268bd2>blocks</span><span style=color:#657b83>=(</span><span>ImageBlock, PointBlock</span><span style=color:#657b83>)</span><span>,
</span><span>    </span><span style=color:#268bd2>get_items</span><span style=color:#657b83>=</span><span>get_image_files,
</span><span>    </span><span style=color:#268bd2>get_y</span><span style=color:#657b83>=</span><span>get_ctr,
</span><span>    </span><span style=color:#586e75># Splitter function that returns True for just one person,
</span><span>    </span><span style=color:#586e75># as we dont want to train with the same person all over and over.
</span><span>    </span><span style=color:#268bd2>splitter</span><span style=color:#657b83>=</span><span style=color:#b58900>FuncSplitter</span><span style=color:#657b83>(</span><span style=color:#859900>lambda </span><span style=color:#268bd2>o</span><span style=color:#657b83>: </span><span>o.parent.name</span><span style=color:#657b83>==</span><span>'</span><span style=color:#2aa198>13</span><span>'</span><span style=color:#657b83>)</span><span>,
</span><span>    </span><span style=color:#586e75># Data augmentation and normalization
</span><span>    </span><span style=color:#268bd2>batch_tfms</span><span style=color:#657b83>=[</span><span style=color:#859900>*</span><span style=color:#b58900>aug_transforms</span><span style=color:#657b83>(</span><span style=color:#268bd2>size</span><span style=color:#657b83>=(</span><span style=color:#6c71c4>240</span><span>,</span><span style=color:#6c71c4>320</span><span style=color:#657b83>))</span><span>,
</span><span>                Normalize.</span><span style=color:#b58900>from_stats</span><span style=color:#657b83>(*</span><span>imagenet_stats</span><span style=color:#657b83>)]
</span><span style=color:#657b83>)
</span></code></pre> <pre class=language-python data-lang=python style=color:#839496;background-color:#002b36><code class=language-python data-lang=python><span>dls </span><span style=color:#657b83>= </span><span>biwi_data.</span><span style=color:#b58900>dataloaders</span><span style=color:#657b83>(</span><span>path</span><span style=color:#657b83>)
</span><span>dls.</span><span style=color:#b58900>show_batch</span><span style=color:#657b83>()
</span></code></pre> <p><img alt src=https://pipegalera.github.io/mostly_books/book-fastai/./images/output_89_1.png></p> <p>The input is the image, and the target is the red dots. The batch of data looks correct.</p> <p><strong>Modeling</strong></p> <pre class=language-python data-lang=python style=color:#839496;background-color:#002b36><code class=language-python data-lang=python><span>learn </span><span style=color:#657b83>= </span><span style=color:#b58900>cnn_learner</span><span style=color:#657b83>(</span><span>dls, resnet18, </span><span style=color:#268bd2>y_range</span><span style=color:#657b83>=(-</span><span style=color:#6c71c4>1</span><span>,</span><span style=color:#6c71c4>1</span><span style=color:#657b83>))
</span></code></pre> <p>When coordinates are used as the dependent variable, most of the time weâ€™re likely to be trying to predict something as close as possible, so we would like to use the MSE loss function. We can check the default loss function using <code>loss_func</code>:</p> <pre class=language-python data-lang=python style=color:#839496;background-color:#002b36><code class=language-python data-lang=python><span>learn.loss_func
</span><span>
</span><span>    FlattenedLoss of </span><span style=color:#b58900>MSELoss</span><span style=color:#657b83>()
</span></code></pre> <p>Fastai applied the loss function correctly. Let's find a good learning rate and fit the model. You can use <code>one_cyle_fit</code> instead of <code>fine_tune</code> to save time using large learning rates (more <a href=https://fastai1.fast.ai/callbacks.one_cycle.html>here</a> and <a href=https://arxiv.org/abs/1708.07120>here</a>).</p> <pre class=language-python data-lang=python style=color:#839496;background-color:#002b36><code class=language-python data-lang=python><span>lr_finder </span><span style=color:#657b83>= </span><span>learn.</span><span style=color:#b58900>lr_find</span><span style=color:#657b83>()
</span><span>learn.</span><span style=color:#b58900>fine_tune</span><span style=color:#657b83>(</span><span style=color:#6c71c4>7</span><span>, lr_finder</span><span style=color:#268bd2>[</span><span style=color:#6c71c4>0</span><span style=color:#268bd2>]</span><span style=color:#657b83>)
</span></code></pre> <table border=0 class=dataframe><thead><tr style=text-align:left><th>epoch<th>train_loss<th>valid_loss<th>time<tbody><tr><td>0<td>0.111715<td>0.004949<td>03:32</table> <table border=0 class=dataframe><thead><tr style=text-align:left><th>epoch<th>train_loss<th>valid_loss<th>time<tbody><tr><td>0<td>0.009237<td>0.001873<td>04:41<tr><td>1<td>0.003953<td>0.000574<td>04:41<tr><td>2<td>0.002914<td>0.000619<td>04:41<tr><td>3<td>0.002445<td>0.000372<td>04:41<tr><td>4<td>0.001847<td>0.000476<td>04:41<tr><td>5<td>0.001449<td>0.000187<td>04:41<tr><td>6<td>0.001440<td>0.000143<td>04:41</table> <p>The predicted center points are quite close to the real center of the faces!</p> <pre class=language-python data-lang=python style=color:#839496;background-color:#002b36><code class=language-python data-lang=python><span>learn.</span><span style=color:#b58900>show_results</span><span style=color:#657b83>(</span><span style=color:#268bd2>ds_idx</span><span style=color:#657b83>=</span><span style=color:#6c71c4>1</span><span>, </span><span style=color:#268bd2>max_n </span><span style=color:#657b83>= </span><span style=color:#6c71c4>3</span><span style=color:#657b83>)
</span></code></pre> <p><img alt src=https://pipegalera.github.io/mostly_books/book-fastai/./images/output_100_1.png></p> <p>In problems that are at first glance completely different (single-label classification, multi-label classification, and regression), we end up using the same model with just different numbers of outputs. The loss function is the one thing that changes, which is why itâ€™s important to double-check that you are using the right loss function for your problem using <code>loss_func</code>.</p> <h2 id=chapter-7-training-a-state-of-the-art-model><a aria-label="Anchor link for: chapter-7-training-a-state-of-the-art-model" class=zola-anchor href=#chapter-7-training-a-state-of-the-art-model>Chapter 7 - Training a State-of-the-Art Model</a></h2> <h3 id=7-1-imagenette-dataset><a aria-label="Anchor link for: 7-1-imagenette-dataset" class=zola-anchor href=#7-1-imagenette-dataset>7.1 Imagenette Dataset</a></h3> <p>Imagenette is a lighter version of the dataset ImageNet.</p> <ul><li><p><strong>ImageNet</strong>: 1.3 million images of various sizes, around 500 pixels across, in 1,000 categories.</p><li><p><strong>Imagenette</strong>: Smaller version of ImageNet that takes only 10 classes that looks very different from one another.</p></ul> <p>Trayining models using ImageNet took several hours so fastai created this lighter version. The philosophy behind is that you should aim to have an iteration speed of no more than a couple of minutes - that is, when you come up with a new idea you want to try out, you should be able to train a model and see how it goes within a couple of minutes.</p> <pre class=language-python data-lang=python style=color:#839496;background-color:#002b36><code class=language-python data-lang=python><span style=color:#586e75># Imagenette
</span><span>path </span><span style=color:#657b83>= </span><span style=color:#b58900>untar_data</span><span style=color:#657b83>(</span><span>URLs.</span><span style=color:#268bd2>IMAGENETTE</span><span style=color:#657b83>)
</span></code></pre> <pre class=language-python data-lang=python style=color:#839496;background-color:#002b36><code class=language-python data-lang=python><span>dblock </span><span style=color:#657b83>= </span><span style=color:#b58900>DataBlock</span><span style=color:#657b83>(</span><span style=color:#268bd2>blocks</span><span style=color:#657b83>=(</span><span style=color:#b58900>ImageBlock</span><span style=color:#657b83>()</span><span>, </span><span style=color:#b58900>CategoryBlock</span><span style=color:#657b83>())</span><span>,
</span><span>                   </span><span style=color:#268bd2>get_items</span><span style=color:#657b83>=</span><span>get_image_files,
</span><span>                   </span><span style=color:#268bd2>get_y</span><span style=color:#657b83>=</span><span>parent_label,
</span><span>                   </span><span style=color:#268bd2>item_tfms</span><span style=color:#657b83>=</span><span style=color:#b58900>Resize</span><span style=color:#657b83>(</span><span style=color:#6c71c4>460</span><span style=color:#657b83>)</span><span>,
</span><span>                   </span><span style=color:#268bd2>batch_tfms</span><span style=color:#657b83>=</span><span style=color:#b58900>aug_transforms</span><span style=color:#657b83>(</span><span style=color:#268bd2>size</span><span style=color:#657b83>=</span><span style=color:#6c71c4>224</span><span>, </span><span style=color:#268bd2>min_scale</span><span style=color:#657b83>=</span><span style=color:#6c71c4>0.75</span><span style=color:#657b83>))
</span><span style=color:#586e75># bs indicates how many samples per batch to load
</span><span>dls </span><span style=color:#657b83>= </span><span>dblock.</span><span style=color:#b58900>dataloaders</span><span style=color:#657b83>(</span><span>path, </span><span style=color:#268bd2>bs</span><span style=color:#657b83>=</span><span style=color:#6c71c4>64</span><span style=color:#657b83>)
</span></code></pre> <h3 id=7-2-normalization><a aria-label="Anchor link for: 7-2-normalization" class=zola-anchor href=#7-2-normalization>7.2 Normalization</a></h3> <p>When training a model, it helps if your input data is normalized â€” that is, has a mean of 0 and a standard deviation of 1. But most images and computer vision libraries use values between 0 and 255 for pixels, or between 0 and 1; in either case, your data is not going to have a mean of 0 and a standard deviation of 1.</p> <p>To normalize the dat, you can add <code>batch_tfms</code> to the datablock to transform the mean andstandard deviation that you want to use.</p> <pre class=language-python data-lang=python style=color:#839496;background-color:#002b36><code class=language-python data-lang=python><span>dblock_norm </span><span style=color:#657b83>= </span><span style=color:#b58900>DataBlock</span><span style=color:#657b83>(</span><span style=color:#268bd2>blocks</span><span style=color:#657b83>=(</span><span style=color:#b58900>ImageBlock</span><span style=color:#657b83>()</span><span>, </span><span style=color:#b58900>CategoryBlock</span><span style=color:#657b83>())</span><span>,
</span><span>                   </span><span style=color:#268bd2>get_items</span><span style=color:#657b83>=</span><span>get_image_files,
</span><span>                   </span><span style=color:#268bd2>get_y</span><span style=color:#657b83>=</span><span>parent_label,
</span><span>                   </span><span style=color:#268bd2>item_tfms</span><span style=color:#657b83>=</span><span style=color:#b58900>Resize</span><span style=color:#657b83>(</span><span style=color:#6c71c4>460</span><span style=color:#657b83>)</span><span>,
</span><span>                   </span><span style=color:#268bd2>batch_tfms</span><span style=color:#657b83>= [</span><span style=color:#859900>*</span><span style=color:#b58900>aug_transforms</span><span style=color:#657b83>(</span><span style=color:#268bd2>size</span><span style=color:#657b83>=</span><span style=color:#6c71c4>224</span><span>, </span><span style=color:#268bd2>min_scale</span><span style=color:#657b83>=</span><span style=color:#6c71c4>0.75</span><span style=color:#657b83>)</span><span>,
</span><span>                                </span><span style=color:#586e75># Normalization
</span><span>                                Normalize.</span><span style=color:#b58900>from_stats</span><span style=color:#657b83>(*</span><span>imagenet_stats</span><span style=color:#657b83>)])
</span><span>
</span><span>dls_norm </span><span style=color:#657b83>= </span><span>dblock_norm.</span><span style=color:#b58900>dataloaders</span><span style=color:#657b83>(</span><span>path, </span><span style=color:#268bd2>bs</span><span style=color:#657b83>=</span><span style=color:#6c71c4>64</span><span style=color:#657b83>)
</span></code></pre> <p>Let's compare two models, one with normalized data and one without normalization. The baseline model is <code>xResNet50</code>. To keep it short, <code>xResNet50</code> is a twist of <code>ResNet50</code> that have shown favourable results when compared to other RestNets <strong>when training from scratch</strong>. For testing use <code>fit_one_cycle()</code> and not<code>fine_tune()</code>, as it faster.</p> <ol><li><strong>Non-normalzied xRestNet50</strong></ol> <pre class=language-python data-lang=python style=color:#839496;background-color:#002b36><code class=language-python data-lang=python><span>model </span><span style=color:#657b83>= </span><span style=color:#b58900>xresnet50</span><span style=color:#657b83>()
</span><span>learn </span><span style=color:#657b83>= </span><span style=color:#b58900>Learner</span><span style=color:#657b83>(</span><span>dls, model, </span><span style=color:#268bd2>loss_func </span><span style=color:#657b83>= </span><span style=color:#b58900>CrossEntropyLossFlat</span><span style=color:#657b83>()</span><span>, </span><span style=color:#268bd2>metrics</span><span style=color:#657b83>=</span><span>accuracy</span><span style=color:#657b83>)
</span><span>learn.</span><span style=color:#b58900>fit_one_cycle</span><span style=color:#657b83>(</span><span style=color:#6c71c4>5</span><span>, </span><span style=color:#6c71c4>3e-3</span><span style=color:#657b83>)
</span></code></pre> <table class=dataframe><thead><tr style=text-align:left><th>epoch<th>train_loss<th>valid_loss<th>accuracy<th>time<tbody><tr><td>0<td>1.639044<td>7.565507<td>0.211725<td>02:20<tr><td>1<td>1.264875<td>1.688994<td>0.523152<td>02:16<tr><td>2<td>0.961111<td>1.115392<td>0.664302<td>02:17<tr><td>3<td>0.717251<td>0.651410<td>0.789768<td>02:22<tr><td>4<td>0.589625<td>0.550697<td>0.825243<td>02:16</table> <ol start=2><li><strong>Normalized xRestNet50</strong></ol> <pre class=language-python data-lang=python style=color:#839496;background-color:#002b36><code class=language-python data-lang=python><span style=color:#586e75># Normalized data
</span><span>learn_norm </span><span style=color:#657b83>= </span><span style=color:#b58900>Learner</span><span style=color:#657b83>(</span><span>dls_norm, model, </span><span style=color:#268bd2>loss_func </span><span style=color:#657b83>= </span><span style=color:#b58900>CrossEntropyLossFlat</span><span style=color:#657b83>()</span><span>, </span><span style=color:#268bd2>metrics</span><span style=color:#657b83>=</span><span>accuracy</span><span style=color:#657b83>)
</span><span>learn_norm.</span><span style=color:#b58900>fit_one_cycle</span><span style=color:#657b83>(</span><span style=color:#6c71c4>5</span><span>, </span><span style=color:#6c71c4>3e-3</span><span style=color:#657b83>)
</span></code></pre> <table class=dataframe><thead><tr style=text-align:left><th>epoch<th>train_loss<th>valid_loss<th>accuracy<th>time<tbody><tr><td>0<td>0.817426<td>1.625511<td>0.572069<td>02:17<tr><td>1<td>0.790636<td>1.329097<td>0.592233<td>02:15<tr><td>2<td>0.671544<td>0.681273<td>0.781553<td>02:17<tr><td>3<td>0.501642<td>0.431404<td>0.864078<td>02:15<tr><td>4<td>0.395240<td>0.387665<td>0.875280<td>02:17</table> <p><strong>Normalizing the data helped achive 4% to 5% more accuracy!</strong></p> <p>Normalization is specially important in pre-trained models. If the model was trained with normalized data (pixels with mean 1 and standard deviation 1), then it will perform better if your data is also normalized. Matching the statistics is very important for transfer learning to work well.</p> <p>The default behaviour in fastai <code>cnn_learner</code> is adding the proper <code>Normalize</code> function automatically, but you will have to add it manually when training models from scratch.</p> <h3 id=7-3-progressive-resizing><a aria-label="Anchor link for: 7-3-progressive-resizing" class=zola-anchor href=#7-3-progressive-resizing>7.3 Progressive Resizing</a></h3> <p>Progressive resizing is gradually using larger and larger images as you train the model.</p> <p>Benefits:</p> <ul><li><p>Training complete much faster, as most of the epochs are used training small images.</p><li><p>You will have better generalization of your models, as progressive resizing is just a method of data augmentation and therefore tend to improve external validity.</p></ul> <p>How it works?</p> <p>First, we create a <code>get_dls</code> function that calls the exactly same datablock that we made before, <strong>but with arguments for the size of the images and the size of the batch</strong> - so we can test different batch sizes.</p> <pre class=language-python data-lang=python style=color:#839496;background-color:#002b36><code class=language-python data-lang=python><span style=color:#859900>def </span><span style=color:#b58900>get_dls</span><span style=color:#657b83>(</span><span style=color:#268bd2>batch_size</span><span>, </span><span style=color:#268bd2>image_size</span><span style=color:#657b83>):
</span><span>  dblock_norm </span><span style=color:#657b83>= </span><span style=color:#b58900>DataBlock</span><span style=color:#657b83>(</span><span style=color:#268bd2>blocks</span><span style=color:#657b83>=(</span><span style=color:#b58900>ImageBlock</span><span style=color:#657b83>()</span><span>, </span><span style=color:#b58900>CategoryBlock</span><span style=color:#657b83>())</span><span>,
</span><span>                    </span><span style=color:#268bd2>get_items</span><span style=color:#657b83>=</span><span>get_image_files,
</span><span>                    </span><span style=color:#268bd2>get_y</span><span style=color:#657b83>=</span><span>parent_label,
</span><span>                    </span><span style=color:#268bd2>item_tfms</span><span style=color:#657b83>=</span><span style=color:#b58900>Resize</span><span style=color:#657b83>(</span><span style=color:#6c71c4>460</span><span style=color:#657b83>)</span><span>,
</span><span>                    </span><span style=color:#268bd2>batch_tfms</span><span style=color:#657b83>= [</span><span style=color:#859900>*</span><span style=color:#b58900>aug_transforms</span><span style=color:#657b83>(</span><span style=color:#268bd2>size</span><span style=color:#657b83>=</span><span>image_size, </span><span style=color:#268bd2>min_scale</span><span style=color:#657b83>=</span><span style=color:#6c71c4>0.75</span><span style=color:#657b83>)</span><span>,
</span><span>                                  Normalize.</span><span style=color:#b58900>from_stats</span><span style=color:#657b83>(*</span><span>imagenet_stats</span><span style=color:#657b83>)])
</span><span>
</span><span>  </span><span style=color:#859900>return </span><span>dblock_norm.</span><span style=color:#b58900>dataloaders</span><span style=color:#657b83>(</span><span>path, </span><span style=color:#268bd2>bs</span><span style=color:#657b83>=</span><span>batch_size</span><span style=color:#657b83>)
</span></code></pre> <p>Let's start with 128 batch of images of 128 pixels each:</p> <pre class=language-python data-lang=python style=color:#839496;background-color:#002b36><code class=language-python data-lang=python><span>dls </span><span style=color:#657b83>= </span><span style=color:#b58900>get_dls</span><span style=color:#657b83>(</span><span style=color:#6c71c4>128</span><span>, </span><span style=color:#6c71c4>128</span><span style=color:#657b83>)
</span><span>learn </span><span style=color:#657b83>= </span><span style=color:#b58900>Learner</span><span style=color:#657b83>(</span><span>dls, </span><span style=color:#b58900>xresnet50</span><span style=color:#657b83>()</span><span>, </span><span style=color:#268bd2>loss_func</span><span style=color:#657b83>=</span><span style=color:#b58900>CrossEntropyLossFlat</span><span style=color:#657b83>()</span><span>, </span><span style=color:#268bd2>metrics</span><span style=color:#657b83>=</span><span>accuracy</span><span style=color:#657b83>)
</span><span>learn.</span><span style=color:#b58900>fit_one_cycle</span><span style=color:#657b83>(</span><span style=color:#6c71c4>4</span><span>, </span><span style=color:#6c71c4>3e-3</span><span style=color:#657b83>)
</span></code></pre> <table class=dataframe><thead><tr style=text-align:left><th>epoch<th>train_loss<th>valid_loss<th>accuracy<th>time<tbody><tr><td>0<td>1.859451<td>2.136631<td>0.392084<td>01:14<tr><td>1<td>1.297873<td>1.321736<td>0.585138<td>01:12<tr><td>2<td>0.979822<td>0.863942<td>0.723674<td>01:12<tr><td>3<td>0.761521<td>0.687464<td>0.781927<td>01:11</table> <p>As with transfered learning, we take the model and we train it 5 more batches with 64 more images but this time with a larger size of 224 pixels:</p> <pre class=language-python data-lang=python style=color:#839496;background-color:#002b36><code class=language-python data-lang=python><span>learn.dls </span><span style=color:#657b83>= </span><span style=color:#b58900>get_dls</span><span style=color:#657b83>(</span><span style=color:#6c71c4>64</span><span>, </span><span style=color:#6c71c4>224</span><span style=color:#657b83>)
</span><span>learn.</span><span style=color:#b58900>fine_tune</span><span style=color:#657b83>(</span><span style=color:#6c71c4>5</span><span>, </span><span style=color:#6c71c4>1e-3</span><span style=color:#657b83>)
</span></code></pre> <table class=dataframe><thead><tr style=text-align:left><th>epoch<th>train_loss<th>valid_loss<th>accuracy<th>time<tbody><tr><td>0<td>0.863330<td>1.115129<td>0.645631<td>02:16</table> <table class=dataframe><thead><tr style=text-align:left><th>epoch<th>train_loss<th>valid_loss<th>accuracy<th>time<tbody><tr><td>0<td>0.677025<td>0.756777<td>0.762136<td>02:15<tr><td>1<td>0.659812<td>0.931320<td>0.712099<td>02:15<tr><td>2<td>0.592581<td>0.682786<td>0.775579<td>02:15<tr><td>3<td>0.481050<td>0.454066<td>0.855863<td>02:17<tr><td>4<td>0.427033<td>0.425391<td>0.868185<td>02:23</table> <p>Pregressive resizing can be done at more epochs and for as big an image as you wish, but notice that you will not get any benefit by using an image size larger that the size of the images.</p> <h3 id=7-4-test-time-augmentation><a aria-label="Anchor link for: 7-4-test-time-augmentation" class=zola-anchor href=#7-4-test-time-augmentation>7.4 Test Time augmentation</a></h3> <p>We have been using random cropping as a way to get some useful data augmentation, which leads to better generalization, and results in a need for less training data. When we use random cropping, fastai will automatically use center-cropping for the validation set â€” that is, it will select the largest square area it can in the center of the image, without going past the imageâ€™s edges.</p> <p>This can often be problematic. For instance, in a multi-label dataset, sometimes there are small objects toward the edges of an image; these could be entirely cropped out by center cropping.</p> <p><em>Squishing</em> could be a solution but also can make the image recognition more difficult for our model. It has to learn how to recognize squished and squeezed images, rather than just correctly proportioned images.</p> <p><strong>Test Time Augmentation (TTA)</strong> is a method that instead of centering or squishing, takes a number of areas to crop from the original rectangular image, pass each of them through our model, and take the maximum or average of the predictions.</p> <p>It does not change the time required to train at all, but will increase the amount of time required for validation or inference by the number of test-time-augmented images requested. By default, fastai will use the unaugmented center crop image plus four randomly augmented images</p> <p>To use it, pass the DataLoader to fastaiâ€™s <code>tta</code> method; by default, it will crop your validation set - you just have to store the "new validation set" in a variable.</p> <p>Run it to observe the output shape:</p> <pre class=language-python data-lang=python style=color:#839496;background-color:#002b36><code class=language-python data-lang=python><span>learn.</span><span style=color:#b58900>tta</span><span style=color:#657b83>()
</span><span>
</span><span>    </span><span style=color:#657b83>(</span><span style=color:#b58900>TensorBase</span><span style=color:#657b83>([[</span><span style=color:#6c71c4>1.3654e-03</span><span>, </span><span style=color:#6c71c4>1.1131e-04</span><span>, </span><span style=color:#6c71c4>4.8078e-05</span><span>,  </span><span style=color:#b58900>...</span><span>, </span><span style=color:#6c71c4>8.0065e-09</span><span>, </span><span style=color:#6c71c4>1.8123e-08</span><span>,
</span><span>              </span><span style=color:#6c71c4>2.7091e-08</span><span style=color:#657b83>]</span><span>,
</span><span>             </span><span style=color:#657b83>[</span><span style=color:#6c71c4>1.8131e-04</span><span>, </span><span style=color:#6c71c4>3.0205e-04</span><span>, </span><span style=color:#6c71c4>4.8520e-03</span><span>,  </span><span style=color:#b58900>...</span><span>, </span><span style=color:#6c71c4>1.0132e-11</span><span>, </span><span style=color:#6c71c4>8.4396e-12</span><span>,
</span><span>              </span><span style=color:#6c71c4>1.2754e-11</span><span style=color:#657b83>]</span><span>,
</span><span>             </span><span style=color:#657b83>[</span><span style=color:#6c71c4>7.4551e-05</span><span>, </span><span style=color:#6c71c4>4.6013e-03</span><span>, </span><span style=color:#6c71c4>9.6602e-03</span><span>,  </span><span style=color:#b58900>...</span><span>, </span><span style=color:#6c71c4>3.2817e-09</span><span>, </span><span style=color:#6c71c4>2.7115e-09</span><span>,
</span><span>              </span><span style=color:#6c71c4>6.0039e-09</span><span style=color:#657b83>]</span><span>,
</span><span>             </span><span style=color:#b58900>...</span><span>,
</span><span>             </span><span style=color:#657b83>[</span><span style=color:#6c71c4>6.5209e-05</span><span>, </span><span style=color:#6c71c4>9.8668e-01</span><span>, </span><span style=color:#6c71c4>7.5150e-07</span><span>,  </span><span style=color:#b58900>...</span><span>, </span><span style=color:#6c71c4>1.3289e-11</span><span>, </span><span style=color:#6c71c4>1.2414e-11</span><span>,
</span><span>              </span><span style=color:#6c71c4>9.5075e-12</span><span style=color:#657b83>]</span><span>,
</span><span>             </span><span style=color:#657b83>[</span><span style=color:#6c71c4>9.9031e-01</span><span>, </span><span style=color:#6c71c4>1.3725e-04</span><span>, </span><span style=color:#6c71c4>3.4502e-04</span><span>,  </span><span style=color:#b58900>...</span><span>, </span><span style=color:#6c71c4>3.1489e-11</span><span>, </span><span style=color:#6c71c4>2.6372e-11</span><span>,
</span><span>              </span><span style=color:#6c71c4>2.8058e-11</span><span style=color:#657b83>]</span><span>,
</span><span>             </span><span style=color:#657b83>[</span><span style=color:#6c71c4>1.1344e-05</span><span>, </span><span style=color:#6c71c4>6.2957e-05</span><span>, </span><span style=color:#6c71c4>9.8214e-01</span><span>,  </span><span style=color:#b58900>...</span><span>, </span><span style=color:#6c71c4>1.0300e-11</span><span>, </span><span style=color:#6c71c4>1.2358e-11</span><span>,
</span><span>              </span><span style=color:#6c71c4>2.7416e-11</span><span style=color:#657b83>]])</span><span>,
</span><span>     </span><span style=color:#b58900>TensorCategory</span><span style=color:#657b83>([</span><span style=color:#6c71c4>4</span><span>, </span><span style=color:#6c71c4>6</span><span>, </span><span style=color:#6c71c4>4</span><span>,  </span><span style=color:#b58900>...</span><span>, </span><span style=color:#6c71c4>1</span><span>, </span><span style=color:#6c71c4>0</span><span>, </span><span style=color:#6c71c4>2</span><span style=color:#657b83>]))
</span></code></pre> <p>The outputs are:</p> <ul><li>The validation set (after this "random average cropping" technique), and<li>The real labels</ul> <p>Notice that the model do not have to be retrained because <strong>we don't use the validation set in the training phase</strong>. We only take cropping averages of the images in the validation set, so the model doesn't change.</p> <pre class=language-python data-lang=python style=color:#839496;background-color:#002b36><code class=language-python data-lang=python><span>preds, targs </span><span style=color:#657b83>= </span><span>learn.</span><span style=color:#b58900>tta</span><span style=color:#657b83>()
</span><span style=color:#b58900>accuracy</span><span style=color:#657b83>(</span><span>preds, targs</span><span style=color:#657b83>)</span><span>.</span><span style=color:#b58900>item</span><span style=color:#657b83>()
</span><span>
</span><span>    </span><span style=color:#6c71c4>0.869305431842804
</span></code></pre> <p><strong>TTA gives a little boost in performance (~1%) - taking into account that it doesn't require additional model training.</strong></p> <p>However, it does make inference slower. For example, if youâ€™re averaging five images for TTA inference will be five times slower.</p> <h3 id=7-5-mixup><a aria-label="Anchor link for: 7-5-mixup" class=zola-anchor href=#7-5-mixup>7.5 Mixup</a></h3> <p>Mixup is a powerful data augmentation technique that <strong>can provide dramatically higher accuracy, especially when you donâ€™t have much data</strong> and donâ€™t have a pretrained model that was trained on data similar to your dataset</p> <p>Mixup is a technique that uses the weighted average of random images to improve the accuracy of the model. It iterates through the images in the dataset to combine:</p> <ol><li>The pixel and label values of each image with;<li>The pixel and label values of a random image.</ol> <p>For example, the following image is a mixup of a church with a gas station image:</p> <p><img alt="Mixing a church and a gas station" src=https://i.postimg.cc/kG6kLbJ5/fig1.png></p> <p>The constructed image is a <strong>linear combination of the first and the second images</strong> - like a linear regresion in which the dependent variable is the mixup image and the dependent variables the 2 images. It is built by adding 0.3 times the first one and 0.7 times the second.</p> <p>In this example, should the model predict â€œchurchâ€ or â€œgas stationâ€?</p> <p>The right answer is 30% church and 70% gas station, since thatâ€™s what weâ€™ll get if we take the linear combination of the one-hot-encoded targets.</p> <p>For instance, suppose we have 10 classes, and â€œchurchâ€ is represented by the index 2 and â€œgas stationâ€ by the index 7. The onehot- encoded representations are as follows:</p> <pre style=color:#839496;background-color:#002b36><code><span>[0, 0, 1, 0, 0, 0, 0, 0, 0, 0] and [0, 0, 0, 0, 0, 0, 0, 1, 0, 0]
</span></code></pre> <p>So here is our final target:</p> <pre style=color:#839496;background-color:#002b36><code><span>[0, 0, 0.3, 0, 0, 0, 0, 0.7, 0, 0]
</span></code></pre> <div class="alert alert-block alert-info">Notice that for Mixup to work, our targets need to be one-hot encoded.</div> <p>Here is how we train a model with Mixup:</p> <pre class=language-python data-lang=python style=color:#839496;background-color:#002b36><code class=language-python data-lang=python><span>model </span><span style=color:#657b83>= </span><span style=color:#b58900>xresnet50</span><span style=color:#657b83>()
</span><span>learn </span><span style=color:#657b83>= </span><span style=color:#b58900>Learner</span><span style=color:#657b83>(</span><span>dls, model, </span><span style=color:#268bd2>loss_func</span><span style=color:#657b83>=</span><span style=color:#b58900>CrossEntropyLossFlat</span><span style=color:#657b83>()</span><span>,
</span><span>                </span><span style=color:#268bd2>metrics</span><span style=color:#657b83>=</span><span>accuracy,
</span><span>                </span><span style=color:#586e75># Mixup!
</span><span>                </span><span style=color:#268bd2>cbs</span><span style=color:#657b83>= </span><span style=color:#b58900>MixUp</span><span style=color:#657b83>(</span><span style=color:#6c71c4>0.5</span><span style=color:#657b83>))
</span><span>learn.</span><span style=color:#b58900>fit_one_cycle</span><span style=color:#657b83>(</span><span style=color:#6c71c4>46</span><span>, </span><span style=color:#6c71c4>3e-3</span><span style=color:#657b83>)
</span></code></pre> <table class=dataframe><thead><tr style=text-align:left><th>epoch<th>train_loss<th>valid_loss<th>accuracy<th>time<tbody><tr><td>0<td>2.328936<td>1.526767<td>0.511576<td>01:11<tr><td>1<td>1.774001<td>1.380210<td>0.552651<td>01:11<tr><td>2<td>1.623476<td>1.196524<td>0.612397<td>01:11<tr><td>3<td>1.564727<td>1.234234<td>0.609783<td>01:11<tr><td>3<td>1.564727<td>1.234234<td>0.609783<td>01:11<tr><td>[...]<td>[...]<td>[...]<td>[...]<td>[...]<tr><td>29<td>0.862966<td>0.427176<td>0.874160<td>01:09<tr><td>30<td>0.856436<td>0.375472<td>0.889096<td>01:09<tr><tr><td>[...]<td>[...]<td>[...]<td>[...]<td>[...]</tr><td>46<td>0.714792<td>0.288479<td>0.922704<td>01:08</table> <p><strong>Mixup requires far more epochs to train to get better accuracy</strong>, compared with other models.</p> <p>With normalization, we reached 87% accuracy after 5 epochs, while by using mixup we needed 29.</p> <p>The model is harder to train, because itâ€™s harder to see whatâ€™s in each image. And the model has to predict two labels per image, rather than just one, as well as figuring out how much each one is weighted.</p> <p>Overfitting seems less likely to be a problem, however, because weâ€™re not showing the same image in each epoch, but are instead showing a random combination of two images.</p> <h3 id=7-6-label-smoothing><a aria-label="Anchor link for: 7-6-label-smoothing" class=zola-anchor href=#7-6-label-smoothing>7.6 Label Smoothing</a></h3> <p>ML models optimize for the metric that you select. If the metric is accuracy, the model search for the maximum accuracy - minimazing the loss function by SGD.</p> <p>The optimization process, in practice, tells the model to return 0 for all categories but one, for which it is trained to return 1. Even 0.999 is not â€œgood enoughâ€; the model will get gradients and learn to predict activations with even higher confidence. This can become very harmful if your data is not perfectly labeled, and it never is in real life scenarios.</p> <p><strong>Label smoothing</strong> replace all the 1 with a number a bit less than 1, and the 0s with a number a bit more than 0. When you train the model, the model doesn't have to be 100% sure that it found the correct label - with 99% is good enough.</p> <p>For example, for a 10 class classification problem (Imagenette) with the correct label in the index 3:</p> <pre style=color:#839496;background-color:#002b36><code><span>[0.01, 0.01, 0.01, 0.91, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01]
</span></code></pre> <p>Label smoothing can be incorporated in the <code>loss_func</code> argument: <code>loss_func=LabelSmoothingCrossEntropy()</code></p> <pre class=language-python data-lang=python style=color:#839496;background-color:#002b36><code class=language-python data-lang=python><span>model </span><span style=color:#657b83>= </span><span style=color:#b58900>xresnet50</span><span style=color:#657b83>()
</span><span>learn </span><span style=color:#657b83>= </span><span style=color:#b58900>Learner</span><span style=color:#657b83>(</span><span>dls, model, </span><span style=color:#268bd2>loss_func</span><span style=color:#657b83>=</span><span style=color:#b58900>LabelSmoothingCrossEntropy</span><span style=color:#657b83>()</span><span>,
</span><span>                </span><span style=color:#268bd2>metrics</span><span style=color:#657b83>=</span><span>accuracy</span><span style=color:#657b83>)
</span><span>learn.</span><span style=color:#b58900>fit_one_cycle</span><span style=color:#657b83>(</span><span style=color:#6c71c4>5</span><span>, </span><span style=color:#6c71c4>3e-3</span><span style=color:#657b83>)
</span></code></pre> <table class=dataframe><thead><tr style=text-align:left><th>epoch<th>train_loss<th>valid_loss<th>accuracy<th>time<tbody><tr><td>0<td>2.512356<td>2.483313<td>0.449216<td>02:24<tr><td>1<td>2.120067<td>2.909898<td>0.462659<td>02:24<tr><td>2<td>1.868167<td>1.840382<td>0.730769<td>02:28<tr><td>3<td>1.704343<td>1.646435<td>0.801344<td>02:28<tr><td>4<td>1.598507<td>1.552380<td>0.827110<td>02:28</table> <p>As with Mixup, you wonâ€™t generally see significant improvements from label smoothing until you train more epochs.</p> <h2 id=chapter-9-tabular-modeling-deep-dive><a aria-label="Anchor link for: chapter-9-tabular-modeling-deep-dive" class=zola-anchor href=#chapter-9-tabular-modeling-deep-dive>Chapter 9 - Tabular Modeling Deep Dive</a></h2> <p>For this Chapter we will use more than the <code>fastai</code> package so I let below the necessary imports:</p> <pre class=language-python data-lang=python style=color:#839496;background-color:#002b36><code class=language-python data-lang=python><span style=color:#cb4b16>import </span><span>torch
</span><span style=color:#cb4b16>import </span><span>pandas </span><span style=color:#cb4b16>as </span><span>pd
</span><span style=color:#cb4b16>import </span><span>numpy </span><span style=color:#cb4b16>as </span><span>np
</span><span style=color:#cb4b16>import </span><span>matplotlib.pyplot </span><span style=color:#cb4b16>as </span><span>plt
</span><span style=color:#cb4b16>import </span><span>seaborn </span><span style=color:#cb4b16>as </span><span>sns
</span><span style=color:#cb4b16>import </span><span>IPython
</span><span style=color:#cb4b16>import </span><span>graphviz
</span><span style=color:#cb4b16>from </span><span>dtreeviz.trees </span><span style=color:#cb4b16>import </span><span style=color:#b58900>*
</span><span style=color:#cb4b16>from </span><span>scipy.cluster </span><span style=color:#cb4b16>import </span><span>hierarchy </span><span style=color:#cb4b16>as </span><span>hc
</span><span style=color:#cb4b16>from </span><span>sklearn.model_selection </span><span style=color:#cb4b16>import </span><span>train_test_split,
</span><span>                                    cross_val_score
</span><span style=color:#cb4b16>from </span><span>sklearn.tree </span><span style=color:#cb4b16>import </span><span>DecisionTreeRegressor,
</span><span>                         DecisionTreeClassifier,
</span><span>                         export_graphviz
</span><span style=color:#cb4b16>from </span><span>sklearn.ensemble </span><span style=color:#cb4b16>import </span><span>BaggingClassifier,
</span><span>                             RandomForestClassifier,
</span><span>                             BaggingRegressor,
</span><span>                             RandomForestRegressor,
</span><span>                             GradientBoostingRegressor
</span><span style=color:#cb4b16>from </span><span>sklearn.metrics </span><span style=color:#cb4b16>import </span><span>mean_squared_error,
</span><span>                            confusion_matrix,
</span><span>                            classification_report
</span><span style=color:#cb4b16>from </span><span>fastai.tabular.all </span><span style=color:#cb4b16>import </span><span style=color:#b58900>*
</span><span>
</span><span>plt.style.</span><span style=color:#b58900>use</span><span style=color:#657b83>(</span><span>'</span><span style=color:#2aa198>seaborn-white</span><span>'</span><span style=color:#657b83>)
</span><span>
</span><span style=color:#cb4b16>import </span><span>warnings
</span><span>warnings.</span><span style=color:#b58900>filterwarnings</span><span style=color:#657b83>(</span><span>'</span><span style=color:#2aa198>ignore</span><span>'</span><span style=color:#657b83>)
</span></code></pre> <pre class=language-python data-lang=python style=color:#839496;background-color:#002b36><code class=language-python data-lang=python><span>x </span><span style=color:#657b83>= </span><span>torch.cuda.</span><span style=color:#b58900>get_device_name</span><span style=color:#657b83>(</span><span style=color:#6c71c4>0</span><span style=color:#657b83>) </span><span style=color:#859900>if </span><span>torch.cuda.</span><span style=color:#b58900>is_available</span><span style=color:#657b83>() </span><span style=color:#859900>else </span><span style=color:#b58900>None
</span><span style=color:#859900>print</span><span style=color:#657b83>(</span><span>x</span><span style=color:#657b83>)
</span><span>
</span><span>      Tesla T4
</span></code></pre> <p>Tabular modeling takes data in the form of a table (like a spreadsheet or a CSV). The objective is to predict the value in one column based on the values in the other columns.</p> <h3 id=9-1-beyond-deep-learning><a aria-label="Anchor link for: 9-1-beyond-deep-learning" class=zola-anchor href=#9-1-beyond-deep-learning>9.1 Beyond Deep Learning</a></h3> <p>So far, the solution to all of our modeling problems has been to train a deep learning model. And indeed, that is a pretty good rule of thumb for complex unstructured data like images, sounds, natural language text, and so forth.</p> <p>Deep learning also works very well for collaborative filtering. But it is not always the best starting point for analyzing tabular data.</p> <p>Although deep learning is nearly always clearly superior for unstructured data, Ensembles of decision trees tend to give <strong>quite similar results for many kinds of structured data</strong>. Also, they train faster, are often easier to interpret, do not require special GPU hardware, and require less hyperparameter tuning.</p> <h3 id=9-2-the-dataset><a aria-label="Anchor link for: 9-2-the-dataset" class=zola-anchor href=#9-2-the-dataset>9.2 The Dataset</a></h3> <p>The dataset we use in this chapter is from the Blue Book for Bulldozers Kaggle competition, which has the following description:</p> <p><em>"The goal of the contest is to predict the sale price of a particular piece of heavy equipment at auction based on its usage, equipment type, and configuration."</em></p> <pre class=language-python data-lang=python style=color:#839496;background-color:#002b36><code class=language-python data-lang=python><span>df </span><span style=color:#657b83>= </span><span>pd.</span><span style=color:#b58900>read_csv</span><span style=color:#657b83>(</span><span>'</span><span style=color:#2aa198>/home/studio-lab-user/sagemaker-studiolab-notebooks/TrainAndValid.csv</span><span>', </span><span style=color:#268bd2>low_memory</span><span style=color:#657b83>=</span><span style=color:#b58900>False</span><span style=color:#657b83>)
</span><span>df.</span><span style=color:#b58900>head</span><span style=color:#657b83>()
</span></code></pre> <table class=dataframe><thead><tr><th><th>SalesID<th>SalePrice<th>MachineID<th>ModelID<th>datasource<th>auctioneerID<th>YearMade<th>MachineHoursCurrentMeter<th>UsageBand<th>saledate<th>...<th>Undercarriage_Pad_Width<th>Stick_Length<th>Thumb<th>Pattern_Changer<th>Grouser_Type<th>Backhoe_Mounting<th>Blade_Type<th>Travel_Controls<th>Differential_Type<th>Steering_Controls<tbody><tr><th>0<td>1139246<td>66000.0<td>999089<td>3157<td>121<td>3.0<td>2004<td>68.0<td>Low<td>11/16/2006 0:00<td>...<td>NaN<td>NaN<td>NaN<td>NaN<td>NaN<td>NaN<td>NaN<td>NaN<td>Standard<td>Conventional<tr><th>1<td>1139248<td>57000.0<td>117657<td>77<td>121<td>3.0<td>1996<td>4640.0<td>Low<td>3/26/2004 0:00<td>...<td>NaN<td>NaN<td>NaN<td>NaN<td>NaN<td>NaN<td>NaN<td>NaN<td>Standard<td>Conventional<tr><th>2<td>1139249<td>10000.0<td>434808<td>7009<td>121<td>3.0<td>2001<td>2838.0<td>High<td>2/26/2004 0:00<td>...<td>NaN<td>NaN<td>NaN<td>NaN<td>NaN<td>NaN<td>NaN<td>NaN<td>NaN<td>NaN<tr><th>3<td>1139251<td>38500.0<td>1026470<td>332<td>121<td>3.0<td>2001<td>3486.0<td>High<td>5/19/2011 0:00<td>...<td>NaN<td>NaN<td>NaN<td>NaN<td>NaN<td>NaN<td>NaN<td>NaN<td>NaN<td>NaN<tr><th>4<td>1139253<td>11000.0<td>1057373<td>17311<td>121<td>3.0<td>2007<td>722.0<td>Medium<td>7/23/2009 0:00<td>...<td>NaN<td>NaN<td>NaN<td>NaN<td>NaN<td>NaN<td>NaN<td>NaN<td>NaN<td>NaN</table> <p>5 rows Ã— 53 columns</p> <p>The <strong>metric</strong> selected to evaluate the model is the <strong>root mean squared log error (RMLSE)</strong> between the actual and predicted auction prices. We are going to transform the sales price column into a logarithm, so when we apply the RMSE, it is already taking the logarithm into account.</p> <pre class=language-python data-lang=python style=color:#839496;background-color:#002b36><code class=language-python data-lang=python><span>df</span><span style=color:#268bd2>[</span><span>'</span><span style=color:#2aa198>SalePrice</span><span>'</span><span style=color:#268bd2>] </span><span style=color:#657b83>= </span><span>np.</span><span style=color:#b58900>log</span><span style=color:#657b83>(</span><span>df</span><span style=color:#268bd2>[</span><span>'</span><span style=color:#2aa198>SalePrice</span><span>'</span><span style=color:#268bd2>]</span><span style=color:#657b83>)
</span></code></pre> <h3 id=9-3-categorical-embeddings><a aria-label="Anchor link for: 9-3-categorical-embeddings" class=zola-anchor href=#9-3-categorical-embeddings>9.3 Categorical Embeddings</a></h3> <p>Categorical embeddings transforms the categorical variables into inputs that are both continuous and meaningful. Clustering or ordening different categories is important because models are better at understanding continuous variables.</p> <p>This is unsurprising considering models are built of many continuous parameter weights and continuous activation values, which are updated via gradient descent.</p> <p>Categorical embedding also:</p> <ul><li>Reduces memory usage and speeds up neural networks compared with one-hot encoding.<li>Reveals the intrinsic properties of the categorical variables - increasing their predictive power.<li>It can be used for visualizing categorical data and for data clustering. The model learns an embedding for these entities that defines a continuous notion of distance between them.<li>Avoid overfitting. It is especially useful for datasets with lots of high cardinality features, where other methods tend to overfit.</ul> <p>We will start by embedding the "Product Size" variable, giving it it's natural order:</p> <pre class=language-python data-lang=python style=color:#839496;background-color:#002b36><code class=language-python data-lang=python><span>df</span><span style=color:#268bd2>[</span><span>'</span><span style=color:#2aa198>ProductSize</span><span>'</span><span style=color:#268bd2>]</span><span>.</span><span style=color:#b58900>unique</span><span style=color:#657b83>()
</span><span>
</span><span>    </span><span style=color:#b58900>array</span><span style=color:#657b83>([</span><span>nan, '</span><span style=color:#2aa198>Medium</span><span>', '</span><span style=color:#2aa198>Small</span><span>', '</span><span style=color:#2aa198>Large / Medium</span><span>', '</span><span style=color:#2aa198>Mini</span><span>', '</span><span style=color:#2aa198>Large</span><span>',
</span><span>           '</span><span style=color:#2aa198>Compact</span><span>'</span><span style=color:#657b83>]</span><span>, </span><span style=color:#268bd2>dtype</span><span style=color:#657b83>=</span><span style=color:#859900>object</span><span style=color:#657b83>)
</span></code></pre> <pre class=language-python data-lang=python style=color:#839496;background-color:#002b36><code class=language-python data-lang=python><span>df</span><span style=color:#268bd2>[</span><span>'</span><span style=color:#2aa198>ProductSize</span><span>'</span><span style=color:#268bd2>]</span><span>.dtype
</span><span>
</span><span>    </span><span style=color:#b58900>dtype</span><span style=color:#657b83>(</span><span>'</span><span style=color:#2aa198>O</span><span>'</span><span style=color:#657b83>)
</span></code></pre> <pre class=language-python data-lang=python style=color:#839496;background-color:#002b36><code class=language-python data-lang=python><span style=color:#586e75># Order
</span><span>sizes </span><span style=color:#657b83>= [</span><span>'</span><span style=color:#2aa198>Large</span><span>','</span><span style=color:#2aa198>Large / Medium</span><span>','</span><span style=color:#2aa198>Medium</span><span>','</span><span style=color:#2aa198>Small</span><span>','</span><span style=color:#2aa198>Mini</span><span>','</span><span style=color:#2aa198>Compact</span><span>'</span><span style=color:#657b83>]
</span><span>
</span><span>df</span><span style=color:#268bd2>[</span><span>'</span><span style=color:#2aa198>ProductSize</span><span>'</span><span style=color:#268bd2>] </span><span style=color:#657b83>= </span><span>df</span><span style=color:#268bd2>[</span><span>'</span><span style=color:#2aa198>ProductSize</span><span>'</span><span style=color:#268bd2>]</span><span>.</span><span style=color:#b58900>astype</span><span style=color:#657b83>(</span><span>'</span><span style=color:#2aa198>category</span><span>'</span><span style=color:#657b83>)
</span><span>df</span><span style=color:#268bd2>[</span><span>'</span><span style=color:#2aa198>ProductSize</span><span>'</span><span style=color:#268bd2>] </span><span style=color:#657b83>= </span><span>df</span><span style=color:#268bd2>[</span><span>'</span><span style=color:#2aa198>ProductSize</span><span>'</span><span style=color:#268bd2>]</span><span>.cat.</span><span style=color:#b58900>set_categories</span><span style=color:#657b83>(</span><span>sizes, </span><span style=color:#268bd2>ordered</span><span style=color:#657b83>=</span><span style=color:#b58900>True</span><span style=color:#657b83>)
</span></code></pre> <pre class=language-python data-lang=python style=color:#839496;background-color:#002b36><code class=language-python data-lang=python><span>df</span><span style=color:#268bd2>[</span><span>'</span><span style=color:#2aa198>ProductSize</span><span>'</span><span style=color:#268bd2>]</span><span>.dtype
</span><span>
</span><span>    </span><span style=color:#b58900>CategoricalDtype</span><span style=color:#657b83>(</span><span style=color:#268bd2>categories</span><span style=color:#657b83>=[</span><span>'</span><span style=color:#2aa198>Large</span><span>', '</span><span style=color:#2aa198>Large / Medium</span><span>', '</span><span style=color:#2aa198>Medium</span><span>', '</span><span style=color:#2aa198>Small</span><span>', '</span><span style=color:#2aa198>Mini</span><span>',
</span><span>                      '</span><span style=color:#2aa198>Compact</span><span>'</span><span style=color:#657b83>]</span><span>,
</span><span>    , </span><span style=color:#268bd2>ordered</span><span style=color:#657b83>=</span><span style=color:#b58900>True</span><span style=color:#657b83>)
</span></code></pre> <p><strong>It is not needed to do hot-encoding</strong>. For binary classification and regression, it was shown that ordering the predictor categories in each split leads to exactly the same splits as the standard approach. This reduces computational complexity because only k âˆ’ 1 splits have to be considered for a nominal predictor with k categories</p> <h3 id=9-4-feature-engineering-dates><a aria-label="Anchor link for: 9-4-feature-engineering-dates" class=zola-anchor href=#9-4-feature-engineering-dates>9.4 Feature Engineering: Dates</a></h3> <p>The fundamental basis of the decision tree is <strong>bisection</strong> â€” dividing a group into two.</p> <p>We look at the ordinal variables and divide the dataset based on whether the variableâ€™s value is greater (or lower) than a threshold, and we look at the categorical variables and divide the dataset based on whether the variableâ€™s level is a particular level. So this algorithm has a way of dividing the dataset based on both ordinal and categorical data.</p> <p><strong>But how does this apply to a common data type, the date?</strong></p> <p>We might want our model to make decisions based on that dateâ€™s day of the week, on whether a day is a holiday, on what month it is in, and so forth. fastai comes with a function that will do this for us: <code>add_datepart</code></p> <pre class=language-python data-lang=python style=color:#839496;background-color:#002b36><code class=language-python data-lang=python><span>df </span><span style=color:#657b83>= </span><span style=color:#b58900>add_datepart</span><span style=color:#657b83>(</span><span>df, '</span><span style=color:#2aa198>saledate</span><span>'</span><span style=color:#657b83>)
</span></code></pre> <pre class=language-python data-lang=python style=color:#839496;background-color:#002b36><code class=language-python data-lang=python><span style=color:#586e75># Last 15 columns, now we added more feature columns based on the day
</span><span>df.</span><span style=color:#b58900>sample</span><span style=color:#657b83>(</span><span style=color:#6c71c4>5</span><span style=color:#657b83>)</span><span>.iloc</span><span style=color:#268bd2>[</span><span>:,</span><span style=color:#657b83>-</span><span style=color:#6c71c4>15</span><span>:</span><span style=color:#268bd2>]
</span></code></pre> <table class=dataframe><thead><tr><th><th>Differential_Type<th>Steering_Controls<th>saleYear<th>saleMonth<th>saleWeek<th>saleDay<th>saleDayofweek<th>saleDayofyear<th>saleIs_month_end<th>saleIs_month_start<th>saleIs_quarter_end<th>saleIs_quarter_start<th>saleIs_year_end<th>saleIs_year_start<th>saleElapsed<tbody><tr><th>295937<td>Standard<td>Conventional<td>2007<td>4<td>16<td>18<td>2<td>108<td>False<td>False<td>False<td>False<td>False<td>False<td>1.176854e+09<tr><th>177280<td>Standard<td>Conventional<td>2005<td>3<td>12<td>21<td>0<td>80<td>False<td>False<td>False<td>False<td>False<td>False<td>1.111363e+09<tr><th>198868<td>NaN<td>NaN<td>2007<td>3<td>13<td>27<td>1<td>86<td>False<td>False<td>False<td>False<td>False<td>False<td>1.174954e+09<tr><th>55758<td>NaN<td>NaN<td>1991<td>5<td>21<td>21<td>1<td>141<td>False<td>False<td>False<td>False<td>False<td>False<td>6.747840e+08<tr><th>154301<td>NaN<td>NaN<td>2006<td>2<td>8<td>23<td>3<td>54<td>False<td>False<td>False<td>False<td>False<td>False<td>1.140653e+09</table> <h3 id=9-5-using-tabularpandas-and-tabularproc><a aria-label="Anchor link for: 9-5-using-tabularpandas-and-tabularproc" class=zola-anchor href=#9-5-using-tabularpandas-and-tabularproc>9.5 Using TabularPandas and TabularProc</a></h3> <p>A second piece of preparatory processing is to be sure we can handle strings and missing data. fastai includes <code>Categorify</code> for the fists and <code>FillMissing</code> for the second.</p> <ul><li><p><code>Categorify</code> is a TabularProc that replaces a column value with a numeric categorical transformation levels chosen consecutively as they are seen in a column.</p><li><p><code>FillMissing</code> is a TabularProc that replaces missing values with the median of the column, and creates a new Boolean column that is set to True for any row where the value was missing.</p></ul> <pre class=language-python data-lang=python style=color:#839496;background-color:#002b36><code class=language-python data-lang=python><span>procs </span><span style=color:#657b83>= [</span><span>Categorify, FillMissing</span><span style=color:#657b83>]
</span></code></pre> <p>The Kaggle training data ends in April 2012, so we will define a narrower training dataset that consists only of the Kaggle training data from before November 2011, and weâ€™ll define a validation set consisting of data from after November 2011.</p> <pre class=language-python data-lang=python style=color:#839496;background-color:#002b36><code class=language-python data-lang=python><span>cond </span><span style=color:#657b83>= (</span><span>df.saleYear </span><span style=color:#657b83>< </span><span style=color:#6c71c4>2011</span><span style=color:#657b83>) | (</span><span>df.saleMonth</span><span style=color:#657b83>< </span><span style=color:#6c71c4>10</span><span style=color:#657b83>)
</span><span>train_idx </span><span style=color:#657b83>= </span><span>np.</span><span style=color:#b58900>where</span><span style=color:#657b83>(</span><span>cond</span><span style=color:#657b83>)</span><span style=color:#268bd2>[</span><span style=color:#6c71c4>0</span><span style=color:#268bd2>]
</span><span>valid_idx </span><span style=color:#657b83>= </span><span>np.</span><span style=color:#b58900>where</span><span style=color:#657b83>(~</span><span>cond</span><span style=color:#657b83>)</span><span style=color:#268bd2>[</span><span style=color:#6c71c4>0</span><span style=color:#268bd2>]
</span><span>
</span><span>splits </span><span style=color:#657b83>= (</span><span style=color:#859900>list</span><span style=color:#657b83>(</span><span>train_idx</span><span style=color:#657b83>)</span><span>, </span><span style=color:#859900>list</span><span style=color:#657b83>(</span><span>valid_idx</span><span style=color:#657b83>))
</span></code></pre> <p><strong>TabularPandas needs to be told which columns are continuous and which are categorical</strong>. We can handle that automatically using the helper function cont_cat_split:</p> <pre class=language-python data-lang=python style=color:#839496;background-color:#002b36><code class=language-python data-lang=python><span>cont, cat </span><span style=color:#657b83>= </span><span style=color:#b58900>cont_cat_split</span><span style=color:#657b83>(</span><span>df, </span><span style=color:#6c71c4>1</span><span>, </span><span style=color:#268bd2>dep_var</span><span style=color:#657b83>=</span><span>'</span><span style=color:#2aa198>SalePrice</span><span>'</span><span style=color:#657b83>)
</span><span>
</span><span>to </span><span style=color:#657b83>= </span><span style=color:#b58900>TabularPandas</span><span style=color:#657b83>(</span><span>df,
</span><span>                   </span><span style=color:#268bd2>procs </span><span style=color:#657b83>= </span><span>procs,
</span><span>                   </span><span style=color:#268bd2>cat_names</span><span style=color:#657b83>=</span><span>cat,
</span><span>                   </span><span style=color:#268bd2>cont_names</span><span style=color:#657b83>=</span><span>cont,
</span><span>                   </span><span style=color:#268bd2>y_names</span><span style=color:#657b83>=</span><span>'</span><span style=color:#2aa198>SalePrice</span><span>',
</span><span>                   </span><span style=color:#268bd2>splits</span><span style=color:#657b83>=</span><span>splits</span><span style=color:#657b83>)
</span></code></pre> <pre class=language-python data-lang=python style=color:#839496;background-color:#002b36><code class=language-python data-lang=python><span style=color:#859900>len</span><span style=color:#657b83>(</span><span>to.train</span><span style=color:#657b83>)</span><span>, </span><span style=color:#859900>len</span><span style=color:#657b83>(</span><span>to.valid</span><span style=color:#657b83>)
</span><span>
</span><span>
</span><span>    </span><span style=color:#657b83>(</span><span style=color:#6c71c4>404710</span><span>, </span><span style=color:#6c71c4>7988</span><span style=color:#657b83>)
</span></code></pre> <p>Fastai <code>TabularPandas</code> helps pre-processing the data. The following table is the first items of the orginal dataset:</p> <pre class=language-python data-lang=python style=color:#839496;background-color:#002b36><code class=language-python data-lang=python><span>df.</span><span style=color:#b58900>head</span><span style=color:#657b83>(</span><span style=color:#6c71c4>5</span><span style=color:#657b83>)</span><span style=color:#268bd2>[</span><span style=color:#657b83>[</span><span>'</span><span style=color:#2aa198>UsageBand</span><span>', '</span><span style=color:#2aa198>fiModelDesc</span><span>','</span><span style=color:#2aa198>fiBaseModel</span><span>', '</span><span style=color:#2aa198>fiSecondaryDesc</span><span>', '</span><span style=color:#2aa198>fiModelSeries</span><span>'</span><span style=color:#657b83>]</span><span style=color:#268bd2>]
</span></code></pre> <table class=dataframe><thead><tr><th><th>UsageBand<th>fiModelDesc<th>fiBaseModel<th>fiSecondaryDesc<th>fiModelSeries<tbody><tr><th>0<td>Low<td>521D<td>521<td>D<td>NaN<tr><th>1<td>Low<td>950FII<td>950<td>F<td>II<tr><th>2<td>High<td>226<td>226<td>NaN<td>NaN<tr><th>3<td>High<td>PC120-6E<td>PC120<td>NaN<td>-6E<tr><th>4<td>Medium<td>S175<td>S175<td>NaN<td>NaN</table> <p>And this is how <code>to</code> dataframe looks afert the transformation:</p> <pre class=language-python data-lang=python style=color:#839496;background-color:#002b36><code class=language-python data-lang=python><span style=color:#586e75># Numerical version of the columns
</span><span>to.items.</span><span style=color:#b58900>head</span><span style=color:#657b83>(</span><span style=color:#6c71c4>5</span><span style=color:#657b83>)</span><span style=color:#268bd2>[</span><span style=color:#657b83>[</span><span>'</span><span style=color:#2aa198>UsageBand</span><span>', '</span><span style=color:#2aa198>fiModelDesc</span><span>','</span><span style=color:#2aa198>fiBaseModel</span><span>', '</span><span style=color:#2aa198>fiSecondaryDesc</span><span>', '</span><span style=color:#2aa198>fiModelSeries</span><span>'</span><span style=color:#657b83>]</span><span style=color:#268bd2>]
</span></code></pre> <table class=dataframe><thead><tr><th><th>UsageBand<th>fiModelDesc<th>fiBaseModel<th>fiSecondaryDesc<th>fiModelSeries<tbody><tr><th>0<td>2<td>963<td>298<td>43<td>0<tr><th>1<td>2<td>1745<td>529<td>57<td>98<tr><th>2<td>1<td>336<td>111<td>0<td>0<tr><th>3<td>1<td>3716<td>1381<td>0<td>45<tr><th>4<td>3<td>4261<td>1538<td>0<td>0</table> <p>The conversion of categorical columns to numbers is done by simply replacing each unique level with a number. <strong>The numbers associated with the levels are chosen consecutively as they are seen in a column</strong>, so thereâ€™s no particular meaning to the numbers in categorical columns after conversion.</p> <p>The exception is if you first convert a column to a Pandas ordered category (as we did for ProductSize earlier), in which case the ordering you chose is used. We can see the mapping by looking at the classes attribute:</p> <pre class=language-python data-lang=python style=color:#839496;background-color:#002b36><code class=language-python data-lang=python><span>df</span><span style=color:#268bd2>[</span><span>'</span><span style=color:#2aa198>ProductSize</span><span>'</span><span style=color:#268bd2>]</span><span>.</span><span style=color:#b58900>unique</span><span style=color:#657b83>()
</span><span>
</span><span>    </span><span style=color:#657b83>[</span><span>NaN, '</span><span style=color:#2aa198>Medium</span><span>', '</span><span style=color:#2aa198>Small</span><span>', '</span><span style=color:#2aa198>Large / Medium</span><span>', '</span><span style=color:#2aa198>Mini</span><span>', '</span><span style=color:#2aa198>Large</span><span>', '</span><span style=color:#2aa198>Compact</span><span>'</span><span style=color:#657b83>]
</span><span>    </span><span style=color:#b58900>Categories </span><span style=color:#657b83>(</span><span style=color:#6c71c4>6</span><span>, </span><span style=color:#859900>object</span><span style=color:#657b83>)</span><span>: </span><span style=color:#657b83>[</span><span>'</span><span style=color:#2aa198>Large</span><span>' </span><span style=color:#657b83>< </span><span>'</span><span style=color:#2aa198>Large / Medium</span><span>' </span><span style=color:#657b83>< </span><span>'</span><span style=color:#2aa198>Medium</span><span>' </span><span style=color:#657b83>< </span><span>'</span><span style=color:#2aa198>Small</span><span>' </span><span style=color:#657b83>< </span><span>'</span><span style=color:#2aa198>Mini</span><span>' </span><span style=color:#657b83>< </span><span>'</span><span style=color:#2aa198>Compact</span><span>'</span><span style=color:#657b83>]
</span></code></pre> <pre class=language-python data-lang=python style=color:#839496;background-color:#002b36><code class=language-python data-lang=python><span>to</span><span style=color:#268bd2>[</span><span>'</span><span style=color:#2aa198>ProductSize</span><span>'</span><span style=color:#268bd2>]</span><span>.</span><span style=color:#b58900>unique</span><span style=color:#657b83>()
</span><span>
</span><span>
</span><span>    </span><span style=color:#b58900>array</span><span style=color:#657b83>([</span><span style=color:#6c71c4>0</span><span>, </span><span style=color:#6c71c4>3</span><span>, </span><span style=color:#6c71c4>4</span><span>, </span><span style=color:#6c71c4>2</span><span>, </span><span style=color:#6c71c4>5</span><span>, </span><span style=color:#6c71c4>1</span><span>, </span><span style=color:#6c71c4>6</span><span style=color:#657b83>]</span><span>, </span><span style=color:#268bd2>dtype</span><span style=color:#657b83>=</span><span>int8</span><span style=color:#657b83>)
</span></code></pre> <pre class=language-python data-lang=python style=color:#839496;background-color:#002b36><code class=language-python data-lang=python><span>to.classes</span><span style=color:#268bd2>[</span><span>'</span><span style=color:#2aa198>ProductSize</span><span>'</span><span style=color:#268bd2>]
</span><span>
</span><span>    </span><span style=color:#657b83>[</span><span>'</span><span style=color:#2aa198>#na#</span><span>', '</span><span style=color:#2aa198>Large</span><span>', '</span><span style=color:#2aa198>Large / Medium</span><span>', '</span><span style=color:#2aa198>Medium</span><span>', '</span><span style=color:#2aa198>Small</span><span>', '</span><span style=color:#2aa198>Mini</span><span>', '</span><span style=color:#2aa198>Compact</span><span>'</span><span style=color:#657b83>]
</span></code></pre> <pre class=language-python data-lang=python style=color:#839496;background-color:#002b36><code class=language-python data-lang=python><span style=color:#586e75># Save the progress
</span><span style=color:#b58900>save_pickle</span><span style=color:#657b83>(</span><span>'</span><span style=color:#2aa198>to.pkl</span><span>',to</span><span style=color:#657b83>)
</span><span style=color:#586e75># To load progress:
</span><span style=color:#586e75>#to = load_pickle('to.pkl')
</span></code></pre> <h3 id=9-7-decision-trees-avoiding-overfitting><a aria-label="Anchor link for: 9-7-decision-trees-avoiding-overfitting" class=zola-anchor href=#9-7-decision-trees-avoiding-overfitting>9.7 Decision Trees: Avoiding Overfitting</a></h3> <p>To begin, we define our independent and dependent variables. The <code>TabularPandas</code> dataframe knows that the dependent variable is the sale price, because we specify it at <code>y_names='SalePrice'</code> inside the transformation. It is also stored which rows are from the test and which rows are from the validation dataset as we set it by the <code>splits=splits</code> in which we splitted the data based on the condition <code>cond = (df.saleYear < 2011) | (df.saleMonth< 10)</code></p> <p>The arguments <code>xs</code>, <code>y</code>, and <code>train</code>, <code>valid</code> can be used to split the data accordingly - and very fast!</p> <pre class=language-python data-lang=python style=color:#839496;background-color:#002b36><code class=language-python data-lang=python><span style=color:#586e75># X train and y train
</span><span>X, y </span><span style=color:#657b83>= </span><span>to.train.xs, to.train.y
</span><span>
</span><span style=color:#586e75># X valid and y valid
</span><span>X_valid, y_valid </span><span style=color:#657b83>= </span><span>to.valid.xs, to.valid.y
</span></code></pre> <p>Now that our data is all numeric, and there are no missing values, we can create a decision tree:</p> <pre class=language-python data-lang=python style=color:#839496;background-color:#002b36><code class=language-python data-lang=python><span>tree_model </span><span style=color:#657b83>= </span><span style=color:#b58900>DecisionTreeRegressor</span><span style=color:#657b83>(</span><span style=color:#268bd2>max_leaf_nodes</span><span style=color:#657b83>=</span><span style=color:#6c71c4>4</span><span style=color:#657b83>)
</span><span>tree_model.</span><span style=color:#b58900>fit</span><span style=color:#657b83>(</span><span>X, y</span><span style=color:#657b83>)
</span></code></pre> <p>To keep it simple, weâ€™ve told sklearn to create just four leaf nodes. To see what itâ€™s learned, we can display the tree:</p> <pre class=language-python data-lang=python style=color:#839496;background-color:#002b36><code class=language-python data-lang=python><span style=color:#859900>def </span><span style=color:#b58900>draw_tree</span><span style=color:#657b83>(</span><span style=color:#268bd2>t</span><span>, </span><span style=color:#268bd2>df</span><span>, </span><span style=color:#268bd2>size</span><span style=color:#657b83>=</span><span style=color:#6c71c4>10</span><span>, </span><span style=color:#268bd2>ratio</span><span style=color:#657b83>=</span><span style=color:#6c71c4>0.6</span><span>, </span><span style=color:#268bd2>precision</span><span style=color:#657b83>=</span><span style=color:#6c71c4>0</span><span>, </span><span style=color:#859900>**</span><span style=color:#268bd2>kwargs</span><span style=color:#657b83>):
</span><span>    s</span><span style=color:#657b83>=</span><span style=color:#b58900>export_graphviz</span><span style=color:#657b83>(</span><span>t, </span><span style=color:#268bd2>out_file</span><span style=color:#657b83>=</span><span style=color:#b58900>None</span><span>, </span><span style=color:#268bd2>feature_names</span><span style=color:#657b83>=</span><span>df.columns, </span><span style=color:#268bd2>filled</span><span style=color:#657b83>=</span><span style=color:#b58900>True</span><span>, </span><span style=color:#268bd2>rounded</span><span style=color:#657b83>=</span><span style=color:#b58900>True</span><span>,
</span><span>                      </span><span style=color:#268bd2>special_characters</span><span style=color:#657b83>=</span><span style=color:#b58900>True</span><span>, </span><span style=color:#268bd2>rotate</span><span style=color:#657b83>=</span><span style=color:#b58900>False</span><span>, </span><span style=color:#268bd2>precision</span><span style=color:#657b83>=</span><span>precision, </span><span style=color:#859900>**</span><span>kwargs</span><span style=color:#657b83>)
</span><span>    </span><span style=color:#859900>return </span><span>graphviz.</span><span style=color:#b58900>Source</span><span style=color:#657b83>(</span><span>re.</span><span style=color:#b58900>sub</span><span style=color:#657b83>(</span><span>'</span><span style=color:#2aa198>Tree {</span><span>', </span><span style=color:#268bd2>f</span><span>'</span><span style=color:#2aa198>Tree </span><span style=color:#dc322f>{{</span><span style=color:#2aa198> size=</span><span style=color:#657b83>{</span><span>size</span><span style=color:#657b83>}</span><span style=color:#2aa198>; ratio=</span><span style=color:#657b83>{</span><span>ratio</span><span style=color:#657b83>}</span><span>', s</span><span style=color:#657b83>))
</span></code></pre> <pre class=language-python data-lang=python style=color:#839496;background-color:#002b36><code class=language-python data-lang=python><span style=color:#b58900>draw_tree</span><span style=color:#657b83>(</span><span>tree_model, X, </span><span style=color:#268bd2>size</span><span style=color:#657b83>=</span><span style=color:#6c71c4>7</span><span>, </span><span style=color:#268bd2>leaves_parallel</span><span style=color:#657b83>=</span><span style=color:#b58900>True</span><span>, </span><span style=color:#268bd2>precision</span><span style=color:#657b83>=</span><span style=color:#6c71c4>2</span><span style=color:#657b83>)
</span></code></pre> <p><img alt src=https://pipegalera.github.io/mostly_books/book-fastai/./images/output_47_0.svg></p> <p>We see the importance of bisection: only dividing the dataset based on the value of <code>Copler_System</code> predicts an average value of 9.21 versus 10.1. The deeper the model, the more questions it will be able to ask separating high-value from low-value auction results.</p> <p>We will use the package <code>dtreeviz</code> to see the distribution of the tree leafs, and catch possible data quality issues.</p> <pre class=language-python data-lang=python style=color:#839496;background-color:#002b36><code class=language-python data-lang=python><span style=color:#586e75># Random sample of the data
</span><span>samp_idx </span><span style=color:#657b83>= </span><span>np.random.</span><span style=color:#b58900>permutation</span><span style=color:#657b83>(</span><span style=color:#859900>len</span><span style=color:#657b83>(</span><span>y</span><span style=color:#657b83>))</span><span style=color:#268bd2>[</span><span>:</span><span style=color:#6c71c4>500</span><span style=color:#268bd2>]
</span><span>
</span><span style=color:#586e75># Representation for decision tree visualization and model interpretation
</span><span style=color:#b58900>dtreeviz</span><span style=color:#657b83>(</span><span>tree_model,
</span><span>         X.iloc</span><span style=color:#268bd2>[</span><span>samp_idx</span><span style=color:#268bd2>]</span><span>,
</span><span>         y.iloc</span><span style=color:#268bd2>[</span><span>samp_idx</span><span style=color:#268bd2>]</span><span>,
</span><span>         X.columns,
</span><span>         '</span><span style=color:#2aa198>SalePrice</span><span>',
</span><span>         </span><span style=color:#268bd2>fontname</span><span style=color:#657b83>=</span><span>'</span><span style=color:#2aa198>DejaVu Sans</span><span>', </span><span style=color:#268bd2>scale</span><span style=color:#657b83>=</span><span style=color:#6c71c4>1.6</span><span>, </span><span style=color:#268bd2>label_fontsize</span><span style=color:#657b83>=</span><span style=color:#6c71c4>10</span><span>, </span><span style=color:#268bd2>orientation</span><span style=color:#657b83>=</span><span>'</span><span style=color:#2aa198>LR</span><span>'</span><span style=color:#657b83>)
</span></code></pre> <p><img alt=svg src=https://pipegalera.github.io/mostly_books/book-fastai/./images/output_49_0.svg></p> <p>We can clearly see that thereâ€™s a problem with our YearMade data: there are bulldozers made in the year 1000. Letâ€™s replace it with 1950:</p> <pre class=language-python data-lang=python style=color:#839496;background-color:#002b36><code class=language-python data-lang=python><span>X.loc</span><span style=color:#268bd2>[</span><span>X</span><span style=color:#268bd2>[</span><span>'</span><span style=color:#2aa198>YearMade</span><span>'</span><span style=color:#268bd2>]</span><span style=color:#657b83><</span><span style=color:#6c71c4>1900</span><span>, '</span><span style=color:#2aa198>YearMade</span><span>'</span><span style=color:#268bd2>] </span><span style=color:#657b83>= </span><span style=color:#6c71c4>1950
</span><span>X_valid.loc</span><span style=color:#268bd2>[</span><span>X_valid</span><span style=color:#268bd2>[</span><span>'</span><span style=color:#2aa198>YearMade</span><span>'</span><span style=color:#268bd2>]</span><span style=color:#657b83><</span><span style=color:#6c71c4>1900</span><span>, '</span><span style=color:#2aa198>YearMade</span><span>'</span><span style=color:#268bd2>] </span><span style=color:#657b83>= </span><span style=color:#6c71c4>1950
</span></code></pre> <p>That change makes the split much clearer in the tree visualization, even although it doesnâ€™t change the result of the model in any significant way. This is a great example of how resilient decision trees are to data issues.</p> <pre class=language-python data-lang=python style=color:#839496;background-color:#002b36><code class=language-python data-lang=python><span>tree_model_2 </span><span style=color:#657b83>= </span><span style=color:#b58900>DecisionTreeRegressor</span><span style=color:#657b83>(</span><span style=color:#268bd2>max_leaf_nodes</span><span style=color:#657b83>=</span><span style=color:#6c71c4>4</span><span style=color:#657b83>)
</span><span>tree_model_2.</span><span style=color:#b58900>fit</span><span style=color:#657b83>(</span><span>X, y</span><span style=color:#657b83>)
</span><span>
</span><span style=color:#b58900>dtreeviz</span><span style=color:#657b83>(</span><span>tree_model_2,
</span><span>         X.iloc</span><span style=color:#268bd2>[</span><span>samp_idx</span><span style=color:#268bd2>]</span><span>,
</span><span>         y.iloc</span><span style=color:#268bd2>[</span><span>samp_idx</span><span style=color:#268bd2>]</span><span>,
</span><span>         X.columns,
</span><span>         '</span><span style=color:#2aa198>SalePrice</span><span>',
</span><span>         </span><span style=color:#268bd2>fontname</span><span style=color:#657b83>=</span><span>'</span><span style=color:#2aa198>DejaVu Sans</span><span>', </span><span style=color:#268bd2>scale</span><span style=color:#657b83>=</span><span style=color:#6c71c4>1.6</span><span>, </span><span style=color:#268bd2>label_fontsize</span><span style=color:#657b83>=</span><span style=color:#6c71c4>10</span><span>, </span><span style=color:#268bd2>orientation</span><span style=color:#657b83>=</span><span>'</span><span style=color:#2aa198>LR</span><span>'</span><span style=color:#657b83>)
</span></code></pre> <p><img alt=svg src=https://pipegalera.github.io/mostly_books/book-fastai/./images/output_53_0.svg></p> <p>Weâ€™ll create a little function to check the root mean squared error of our model (m_rmse), since thatâ€™s how the competition was judged:</p> <pre class=language-python data-lang=python style=color:#839496;background-color:#002b36><code class=language-python data-lang=python><span>
</span><span style=color:#859900>def </span><span style=color:#b58900>r_mse</span><span style=color:#657b83>(</span><span style=color:#268bd2>a</span><span>, </span><span style=color:#268bd2>b</span><span style=color:#657b83>):
</span><span>    </span><span style=color:#586e75># Formula: Root mean squared error between 2 values: a and b
</span><span>    </span><span style=color:#859900>return round</span><span style=color:#657b83>(</span><span>math.</span><span style=color:#b58900>sqrt</span><span style=color:#657b83>(((</span><span>a</span><span style=color:#657b83>-</span><span>b</span><span style=color:#657b83>)**</span><span style=color:#6c71c4>2</span><span style=color:#657b83>)</span><span>.</span><span style=color:#b58900>mean</span><span style=color:#657b83>())</span><span>, </span><span style=color:#6c71c4>6</span><span style=color:#657b83>)
</span><span>
</span><span style=color:#859900>def </span><span style=color:#b58900>m_rmse</span><span style=color:#657b83>(</span><span style=color:#268bd2>model</span><span>, </span><span style=color:#268bd2>X</span><span>, </span><span style=color:#268bd2>y</span><span style=color:#657b83>):
</span><span>    </span><span style=color:#586e75># Model application: RMSE between the predictions of the model and the y
</span><span>    </span><span style=color:#859900>return </span><span style=color:#b58900>r_mse</span><span style=color:#657b83>(</span><span>model.</span><span style=color:#b58900>predict</span><span style=color:#657b83>(</span><span>X</span><span style=color:#657b83>)</span><span>, y</span><span style=color:#657b83>)
</span><span>
</span><span style=color:#859900>def </span><span style=color:#b58900>print_rmse</span><span style=color:#657b83>(</span><span style=color:#268bd2>model</span><span style=color:#657b83>):
</span><span>    </span><span style=color:#859900>print</span><span style=color:#657b83>(</span><span>"</span><span style=color:#2aa198>Training RMSE: </span><span style=color:#cb4b16>{}</span><span>".</span><span style=color:#b58900>format</span><span style=color:#657b83>(</span><span style=color:#b58900>m_rmse</span><span style=color:#657b83>(</span><span>model, X, y</span><span style=color:#657b83>)))
</span><span>    </span><span style=color:#859900>print</span><span style=color:#657b83>(</span><span>"</span><span style=color:#2aa198>Validation RMSE: </span><span style=color:#cb4b16>{}</span><span>".</span><span style=color:#b58900>format</span><span style=color:#657b83>(</span><span style=color:#b58900>m_rmse</span><span style=color:#657b83>(</span><span>model, X_valid, y_valid</span><span style=color:#657b83>)))
</span></code></pre> <p>To ilustrate overfitting, let the model create a tree model without a limit of leafs:</p> <pre class=language-python data-lang=python style=color:#839496;background-color:#002b36><code class=language-python data-lang=python><span>tree_model_3 </span><span style=color:#657b83>= </span><span style=color:#b58900>DecisionTreeRegressor</span><span style=color:#657b83>()
</span><span>tree_model_3.</span><span style=color:#b58900>fit</span><span style=color:#657b83>(</span><span>X, y</span><span style=color:#657b83>)
</span><span>
</span><span style=color:#b58900>print_rmse</span><span style=color:#657b83>(</span><span>tree_model_3</span><span style=color:#657b83>)
</span></code></pre> <pre style=color:#839496;background-color:#002b36><code><span>Training RMSE: 0.0
</span><span>Validation RMSE: 0.332212
</span></code></pre> <p>The model perfectly predicts the price of the auctions on the training, but checking it on the validation sets it seems to be overfitting indeed.</p> <pre class=language-python data-lang=python style=color:#839496;background-color:#002b36><code class=language-python data-lang=python><span>tree_model_3.</span><span style=color:#b58900>get_n_leaves</span><span style=color:#657b83>()
</span><span>
</span><span>    </span><span style=color:#6c71c4>324565
</span></code></pre> <p>The model uses around 325k leafs for 400k datapoints - of course it is overfitting, we have nearly as many leaf nodes as data points.</p> <p>Let's try a new model with at least 25 autions per leaf.</p> <pre class=language-python data-lang=python style=color:#839496;background-color:#002b36><code class=language-python data-lang=python><span>tree_model_4 </span><span style=color:#657b83>= </span><span style=color:#b58900>DecisionTreeRegressor</span><span style=color:#657b83>(</span><span style=color:#268bd2>min_samples_leaf</span><span style=color:#657b83>=</span><span style=color:#6c71c4>25</span><span style=color:#657b83>)
</span><span>tree_model_4.</span><span style=color:#b58900>fit</span><span style=color:#657b83>(</span><span>X, y</span><span style=color:#657b83>)
</span><span>
</span><span style=color:#b58900>print_rmse</span><span style=color:#657b83>(</span><span>tree_model_4</span><span style=color:#657b83>)
</span><span>
</span><span>
</span><span>    Training </span><span style=color:#268bd2>RMSE</span><span>: </span><span style=color:#6c71c4>0.211706
</span><span>    Validation </span><span style=color:#268bd2>RMSE</span><span>: </span><span style=color:#6c71c4>0.268875
</span></code></pre> <pre class=language-python data-lang=python style=color:#839496;background-color:#002b36><code class=language-python data-lang=python><span>tree_model_4.</span><span style=color:#b58900>get_n_leaves</span><span style=color:#657b83>()
</span><span>
</span><span>
</span><span>    </span><span style=color:#6c71c4>12400
</span></code></pre> <h3 id=9-8-random-forests><a aria-label="Anchor link for: 9-8-random-forests" class=zola-anchor href=#9-8-random-forests>9.8 Random Forests</a></h3> <p>Random Forests are based on a process called <em>bagging</em>:</p> <ol><li>Randomly choose a subset of the rows of your data.<li>Train a model using this subset.<li>Save that model, and then return to step 1 a few times.<li>This will give you multiple trained models. To make a prediction, predict using all of the models, and then take the average of each of those modelâ€™s predictions.</ol> <p>Although each of the models trained on a subset of data will make more errors than a model trained on the full dataset, <strong>those errors will not be correlated with each other</strong>.</p> <p>Different models will make different errors. The average of those errors, therefore, is zero! So if we take the average of all of the modelsâ€™ predictions, we should end up with a prediction that gets closer and closer to the correct answer, the more models we have.</p> <p>In the following function:</p> <ul><li><code>n_estimators</code> defines the number of trees we want.<li><code>max_samples</code> defines how many rows to sample for training each tree.<li><code>max_features</code> defines how many columns to sample at each split point (where 0.5 means â€œtake half the total number of columnsâ€).<li><code>min_samples_leaf</code> specify when to stop splitting the tree nodes, effectively limiting the depth of the tree.<li><code>n_jobs=-1</code> tells sklearn to use all our CPUs to build the trees in parallel.</ul> <pre class=language-python data-lang=python style=color:#839496;background-color:#002b36><code class=language-python data-lang=python><span style=color:#859900>def </span><span style=color:#b58900>random_forest</span><span style=color:#657b83>(</span><span style=color:#268bd2>X</span><span>, </span><span style=color:#268bd2>y</span><span>, </span><span style=color:#268bd2>n_estimators</span><span style=color:#657b83>=</span><span style=color:#6c71c4>100</span><span>,
</span><span>              </span><span style=color:#268bd2>max_samples</span><span style=color:#657b83>=</span><span style=color:#6c71c4>200_000</span><span>,
</span><span>              </span><span style=color:#268bd2>max_features</span><span style=color:#657b83>=</span><span style=color:#6c71c4>0.5</span><span>,
</span><span>              </span><span style=color:#268bd2>min_samples_leaf</span><span style=color:#657b83>=</span><span style=color:#6c71c4>5</span><span>, </span><span style=color:#859900>**</span><span style=color:#268bd2>kwargs</span><span style=color:#657b83>):
</span><span>
</span><span>    </span><span style=color:#859900>return </span><span style=color:#b58900>RandomForestRegressor</span><span style=color:#657b83>(</span><span style=color:#268bd2>n_jobs</span><span style=color:#657b83>=-</span><span style=color:#6c71c4>1</span><span>,
</span><span>                                 </span><span style=color:#268bd2>n_estimators</span><span style=color:#657b83>=</span><span>n_estimators,
</span><span>                                 </span><span style=color:#268bd2>max_samples</span><span style=color:#657b83>=</span><span>max_samples,
</span><span>                                 </span><span style=color:#268bd2>max_features</span><span style=color:#657b83>=</span><span>max_features,
</span><span>                                 </span><span style=color:#268bd2>min_samples_leaf</span><span style=color:#657b83>=</span><span>min_samples_leaf,
</span><span>                                 </span><span style=color:#268bd2>oob_score</span><span style=color:#657b83>=</span><span style=color:#b58900>True</span><span style=color:#657b83>)</span><span>.</span><span style=color:#b58900>fit</span><span style=color:#657b83>(</span><span>X, y</span><span style=color:#657b83>)
</span></code></pre> <pre class=language-python data-lang=python style=color:#839496;background-color:#002b36><code class=language-python data-lang=python><span>rf_model </span><span style=color:#657b83>= </span><span style=color:#b58900>random_forest</span><span style=color:#657b83>(</span><span>X, y</span><span style=color:#657b83>)
</span></code></pre> <p>Our validation RMSE is now much improved over our last result produced by the <code>DecisionTreeRegressor</code>, which made just one tree using all the available data:</p> <pre class=language-python data-lang=python style=color:#839496;background-color:#002b36><code class=language-python data-lang=python><span style=color:#b58900>print_rmse</span><span style=color:#657b83>(</span><span>rf_model</span><span style=color:#657b83>)
</span><span>
</span><span>
</span><span>    Training </span><span style=color:#268bd2>RMSE</span><span>: </span><span style=color:#6c71c4>0.169543
</span><span>    Validation </span><span style=color:#268bd2>RMSE</span><span>: </span><span style=color:#6c71c4>0.231052
</span></code></pre> <div class="alert alert-block alert-info">You can set <b>n_estimators</b> to as high a number as you have time to train â€” the more trees you have, the more accurate the model will be.</div> <h3 id=9-10-out-of-bag-error-and-prediction><a aria-label="Anchor link for: 9-10-out-of-bag-error-and-prediction" class=zola-anchor href=#9-10-out-of-bag-error-and-prediction>9.10 Out-of-Bag Error and Prediction</a></h3> <p>The OOB error is a way of measuring prediction error in the training dataset by including in the calculation of a rowâ€™s error trees only where that row was <em>not</em> included in training.</p> <p>Imagining that every tree it has also has its own validation set. That validation set is simply the rows that were not selected for that treeâ€™s training.</p> <p>The OOB predictions are available in the <code>oob_prediction_</code> attribute.</p> <pre class=language-python data-lang=python style=color:#839496;background-color:#002b36><code class=language-python data-lang=python><span>rf_model.oob_prediction_
</span><span>
</span><span>    </span><span style=color:#b58900>array</span><span style=color:#657b83>([</span><span style=color:#6c71c4>10.96384715</span><span>, </span><span style=color:#6c71c4>10.89122526</span><span>,  </span><span style=color:#6c71c4>9.39799785</span><span>, </span><span style=color:#b58900>...</span><span>,  </span><span style=color:#6c71c4>9.30305792</span><span>,
</span><span>            </span><span style=color:#6c71c4>9.46965767</span><span>,  </span><span style=color:#6c71c4>9.5851676 </span><span style=color:#657b83>])
</span></code></pre> <pre class=language-python data-lang=python style=color:#839496;background-color:#002b36><code class=language-python data-lang=python><span style=color:#b58900>r_mse</span><span style=color:#657b83>(</span><span>rf_model.oob_prediction_, y</span><span style=color:#657b83>)
</span><span>
</span><span>    </span><span style=color:#6c71c4>0.20854
</span></code></pre> <p><code>sklearn</code> also have a a <code>oob_score_</code> attribute that calculates the number of correctly predicted rows from the out of bag sample.</p> <pre class=language-python data-lang=python style=color:#839496;background-color:#002b36><code class=language-python data-lang=python><span>rf_model.oob_score_
</span><span>
</span><span>
</span><span>    </span><span style=color:#6c71c4>0.909784962573175
</span></code></pre> <p>We can include them in the definition above to having a full picture of the RMSE loss:</p> <pre class=language-python data-lang=python style=color:#839496;background-color:#002b36><code class=language-python data-lang=python><span style=color:#859900>def </span><span style=color:#b58900>print_rmse</span><span style=color:#657b83>(</span><span style=color:#268bd2>model</span><span>, </span><span style=color:#268bd2>X</span><span>, </span><span style=color:#268bd2>X_valid</span><span>, </span><span style=color:#268bd2>y</span><span>, </span><span style=color:#268bd2>y_valid</span><span style=color:#657b83>):
</span><span>    </span><span style=color:#859900>print</span><span style=color:#657b83>(</span><span>"</span><span style=color:#2aa198>Training RMSE: </span><span style=color:#cb4b16>{}</span><span>".</span><span style=color:#b58900>format</span><span style=color:#657b83>(</span><span style=color:#b58900>m_rmse</span><span style=color:#657b83>(</span><span>model, X, y</span><span style=color:#657b83>)))
</span><span>    </span><span style=color:#859900>print</span><span style=color:#657b83>(</span><span>"</span><span style=color:#2aa198>Validation RMSE: </span><span style=color:#cb4b16>{}</span><span>".</span><span style=color:#b58900>format</span><span style=color:#657b83>(</span><span style=color:#b58900>m_rmse</span><span style=color:#657b83>(</span><span>model, X_valid, y_valid</span><span style=color:#657b83>)))
</span><span>    </span><span style=color:#859900>print</span><span style=color:#657b83>(</span><span>"</span><span style=color:#2aa198>Out-of-Bag RMSE: </span><span style=color:#cb4b16>{}</span><span>".</span><span style=color:#b58900>format</span><span style=color:#657b83>(</span><span style=color:#b58900>r_mse</span><span style=color:#657b83>(</span><span>model.oob_prediction_, y</span><span style=color:#657b83>)))
</span><span>    </span><span style=color:#859900>print</span><span style=color:#657b83>(</span><span>"</span><span style=color:#2aa198>Out-of-Bag Accuracy: </span><span style=color:#cb4b16>{}</span><span>".</span><span style=color:#b58900>format</span><span style=color:#657b83>(</span><span>model.oob_score_.</span><span style=color:#b58900>round</span><span style=color:#657b83>(</span><span style=color:#6c71c4>3</span><span style=color:#657b83>)))
</span></code></pre> <h3 id=9-11-model-simplification-and-improvements><a aria-label="Anchor link for: 9-11-model-simplification-and-improvements" class=zola-anchor href=#9-11-model-simplification-and-improvements>9.11 Model Simplification and Improvements</a></h3> <p>For tabular data, model interpretation is particularly important. For a given model, we are most likely to be interested in are the following:</p> <ul><li>How confident are we in our predictions using a particular row of data?<li>For predicting with a particular row of data, what were the most important factors, and how did they influence that prediction?<li>Which columns are the strongest predictors, which can we ignore?<li>Which columns are effectively redundant with each other, for purposes of prediction?<li>How do predictions vary as we vary these columns?</ul> <p>This section covers the first questions above, not necessarery improving the accuracy of the model but simplyfing the variables to focus to and identifying the part of the data that the model have more problems with.</p> <h4 id=9-11-1-tree-variance-for-prediction-confidence><a aria-label="Anchor link for: 9-11-1-tree-variance-for-prediction-confidence" class=zola-anchor href=#9-11-1-tree-variance-for-prediction-confidence>9.11.1 Tree Variance for Prediction Confidence</a></h4> <p>How can we know the conficdence of the estimate? One simple way is to use the standard deviation of predictions across the tree, instead of just the mean. This tells us the relative confidence of predictions.</p> <p>Therefore, the task is taking all the trees in the model, stack the different predictions and call the standard deviation between them - insteal of the mean.</p> <p>The different trees from a <code>RandomForestRegressor</code> model can be called as elements of a list:</p> <pre class=language-python data-lang=python style=color:#839496;background-color:#002b36><code class=language-python data-lang=python><span>rf_model</span><span style=color:#268bd2>[</span><span style=color:#6c71c4>0</span><span style=color:#268bd2>]
</span><span>
</span><span>    </span><span style=color:#b58900>DecisionTreeRegressor</span><span style=color:#657b83>(</span><span style=color:#268bd2>max_features</span><span style=color:#657b83>=</span><span style=color:#6c71c4>0.5</span><span>, </span><span style=color:#268bd2>min_samples_leaf</span><span style=color:#657b83>=</span><span style=color:#6c71c4>5</span><span>,
</span><span>                          </span><span style=color:#268bd2>random_state</span><span style=color:#657b83>=</span><span style=color:#6c71c4>1600246232</span><span style=color:#657b83>)
</span></code></pre> <p><code>predict()</code> can be called on individual trees - for every one of the 7988 auction predictions.</p> <pre class=language-python data-lang=python style=color:#839496;background-color:#002b36><code class=language-python data-lang=python><span>rf_model</span><span style=color:#268bd2>[</span><span style=color:#6c71c4>0</span><span style=color:#268bd2>]</span><span>.</span><span style=color:#b58900>predict</span><span style=color:#657b83>(</span><span>X_valid</span><span style=color:#657b83>)
</span><span>
</span><span>
</span><span>    </span><span style=color:#b58900>array</span><span style=color:#657b83>([ </span><span style=color:#6c71c4>9.97461469</span><span>, </span><span style=color:#6c71c4>10.10483758</span><span>,  </span><span style=color:#6c71c4>9.32772859</span><span>, </span><span style=color:#b58900>...</span><span>,  </span><span style=color:#6c71c4>9.38366519</span><span>,
</span><span>            </span><span style=color:#6c71c4>9.37713079</span><span>,  </span><span style=color:#6c71c4>9.37713079</span><span style=color:#657b83>])
</span></code></pre> <pre class=language-python data-lang=python style=color:#839496;background-color:#002b36><code class=language-python data-lang=python><span style=color:#859900>len</span><span style=color:#657b83>(</span><span>rf_model</span><span style=color:#268bd2>[</span><span style=color:#6c71c4>0</span><span style=color:#268bd2>]</span><span>.</span><span style=color:#b58900>predict</span><span style=color:#657b83>(</span><span>X_valid</span><span style=color:#657b83>))
</span><span>
</span><span>
</span><span>    </span><span style=color:#6c71c4>7988
</span></code></pre> <p>All the trees are under the <code>m.estimators_</code>.</p> <pre class=language-python data-lang=python style=color:#839496;background-color:#002b36><code class=language-python data-lang=python><span style=color:#859900>len</span><span style=color:#657b83>(</span><span>rf_model.estimators_</span><span style=color:#657b83>)
</span><span>
</span><span>
</span><span>    </span><span style=color:#6c71c4>100
</span></code></pre> <p>Let's stack all the predictions. 7988 predictions, in each of 100 trees.</p> <pre class=language-python data-lang=python style=color:#839496;background-color:#002b36><code class=language-python data-lang=python><span>preds_stacked </span><span style=color:#657b83>= </span><span>np.</span><span style=color:#b58900>stack</span><span style=color:#657b83>(</span><span>i.</span><span style=color:#b58900>predict</span><span style=color:#657b83>(</span><span>X_valid</span><span style=color:#657b83>) </span><span style=color:#859900>for </span><span>i </span><span style=color:#859900>in </span><span>rf_model.estimators_</span><span style=color:#657b83>)
</span><span>preds_stacked
</span><span>
</span><span>    </span><span style=color:#b58900>array</span><span style=color:#657b83>([[ </span><span style=color:#6c71c4>9.97461469</span><span>, </span><span style=color:#6c71c4>10.10483758</span><span>,  </span><span style=color:#6c71c4>9.32772859</span><span>, </span><span style=color:#b58900>...</span><span>,  </span><span style=color:#6c71c4>9.38366519</span><span>,
</span><span>             </span><span style=color:#6c71c4>9.37713079</span><span>,  </span><span style=color:#6c71c4>9.37713079</span><span style=color:#657b83>]</span><span>,
</span><span>           </span><span style=color:#657b83>[</span><span style=color:#6c71c4>10.02496635</span><span>,  </span><span style=color:#6c71c4>9.99724274</span><span>,  </span><span style=color:#6c71c4>9.23241147</span><span>, </span><span style=color:#b58900>...</span><span>,  </span><span style=color:#6c71c4>9.3199054 </span><span>,
</span><span>             </span><span style=color:#6c71c4>9.38743793</span><span>,  </span><span style=color:#6c71c4>9.38743793</span><span style=color:#657b83>]</span><span>,
</span><span>           </span><span style=color:#657b83>[ </span><span style=color:#6c71c4>9.93373553</span><span>,  </span><span style=color:#6c71c4>9.96011698</span><span>,  </span><span style=color:#6c71c4>9.01997169</span><span>, </span><span style=color:#b58900>...</span><span>,  </span><span style=color:#6c71c4>9.1301562 </span><span>,
</span><span>             </span><span style=color:#6c71c4>9.22006596</span><span>,  </span><span style=color:#6c71c4>9.22006596</span><span style=color:#657b83>]</span><span>,
</span><span>           </span><span style=color:#b58900>...</span><span>,
</span><span>           </span><span style=color:#657b83>[ </span><span style=color:#6c71c4>9.84292495</span><span>,  </span><span style=color:#6c71c4>9.95399866</span><span>,  </span><span style=color:#6c71c4>9.43168683</span><span>, </span><span style=color:#b58900>...</span><span>,  </span><span style=color:#6c71c4>9.41749875</span><span>,
</span><span>             </span><span style=color:#6c71c4>9.11293326</span><span>,  </span><span style=color:#6c71c4>9.11293326</span><span style=color:#657b83>]</span><span>,
</span><span>           </span><span style=color:#657b83>[ </span><span style=color:#6c71c4>9.91806875</span><span>, </span><span style=color:#6c71c4>10.12426186</span><span>,  </span><span style=color:#6c71c4>9.37828723</span><span>, </span><span style=color:#b58900>...</span><span>,  </span><span style=color:#6c71c4>9.47753124</span><span>,
</span><span>             </span><span style=color:#6c71c4>9.22080501</span><span>,  </span><span style=color:#6c71c4>9.22080501</span><span style=color:#657b83>]</span><span>,
</span><span>           </span><span style=color:#657b83>[</span><span style=color:#6c71c4>10.29240811</span><span>, </span><span style=color:#6c71c4>10.00102539</span><span>,  </span><span style=color:#6c71c4>9.40523815</span><span>, </span><span style=color:#b58900>...</span><span>,  </span><span style=color:#6c71c4>9.34376642</span><span>,
</span><span>             </span><span style=color:#6c71c4>9.50345051</span><span>,  </span><span style=color:#6c71c4>9.50345051</span><span style=color:#657b83>]])
</span></code></pre> <pre class=language-python data-lang=python style=color:#839496;background-color:#002b36><code class=language-python data-lang=python><span>preds_stacked.shape
</span><span>
</span><span>    </span><span style=color:#657b83>(</span><span style=color:#6c71c4>100</span><span>, </span><span style=color:#6c71c4>7988</span><span style=color:#657b83>)
</span></code></pre> <pre class=language-python data-lang=python style=color:#839496;background-color:#002b36><code class=language-python data-lang=python><span>preds_stacked</span><span style=color:#268bd2>[</span><span style=color:#6c71c4>0</span><span style=color:#268bd2>]
</span><span>
</span><span>    </span><span style=color:#b58900>array</span><span style=color:#657b83>([ </span><span style=color:#6c71c4>9.97461469</span><span>, </span><span style=color:#6c71c4>10.10483758</span><span>,  </span><span style=color:#6c71c4>9.32772859</span><span>, </span><span style=color:#b58900>...</span><span>,  </span><span style=color:#6c71c4>9.38366519</span><span>,
</span><span>            </span><span style=color:#6c71c4>9.37713079</span><span>,  </span><span style=color:#6c71c4>9.37713079</span><span style=color:#657b83>])
</span></code></pre> <p>Lastly, we use <code>std</code> to calculate the standard deviation for every auction.</p> <p>We are setting the axis to 0 calculate the standard deviation at a column level - it takes the 100 tree prediction of the 1st auction and compares the results, takes 100 predictions of the 2nd auction and compares the results, and so forth.</p> <p>Giving 7988 standard deviations - one for every auction. The ones with a high standard deviation means that the trees dissagree more. If every tree gives the same prediction, the standard deviation would be 0.</p> <p>Wrapping everything into a function:</p> <pre class=language-python data-lang=python style=color:#839496;background-color:#002b36><code class=language-python data-lang=python><span style=color:#859900>def </span><span style=color:#b58900>tree_variance</span><span style=color:#657b83>(</span><span style=color:#268bd2>model</span><span style=color:#657b83>):
</span><span>    </span><span style=color:#586e75># Stack the estimations for every tree
</span><span>    preds_stacked </span><span style=color:#657b83>= </span><span>np.</span><span style=color:#b58900>stack</span><span style=color:#657b83>(</span><span>i.</span><span style=color:#b58900>predict</span><span style=color:#657b83>(</span><span>X_valid</span><span style=color:#657b83>) </span><span style=color:#859900>for </span><span>i </span><span style=color:#859900>in </span><span>model.estimators_</span><span style=color:#657b83>)
</span><span>
</span><span>    </span><span style=color:#586e75># Calculate the standard deviation
</span><span>    pres_std </span><span style=color:#657b83>= </span><span>preds_stacked.</span><span style=color:#b58900>std</span><span style=color:#657b83>(</span><span style=color:#6c71c4>0</span><span style=color:#657b83>)
</span><span>
</span><span>    </span><span style=color:#586e75># Discrepancies
</span><span>    max_std </span><span style=color:#657b83>= </span><span>pres_std.</span><span style=color:#b58900>max</span><span style=color:#657b83>()</span><span>.</span><span style=color:#b58900>round</span><span style=color:#657b83>(</span><span style=color:#6c71c4>3</span><span style=color:#657b83>)
</span><span>    max_row </span><span style=color:#657b83>= </span><span>np.</span><span style=color:#b58900>where</span><span style=color:#657b83>(</span><span>pres_std </span><span style=color:#657b83>== </span><span>pres_std.</span><span style=color:#b58900>max</span><span style=color:#657b83>())</span><span style=color:#268bd2>[</span><span style=color:#6c71c4>0</span><span style=color:#268bd2>]</span><span>.</span><span style=color:#b58900>astype</span><span style=color:#657b83>(</span><span>np.int</span><span style=color:#657b83>)
</span><span>    min_std </span><span style=color:#657b83>= </span><span>pres_std.</span><span style=color:#b58900>min</span><span style=color:#657b83>()</span><span>.</span><span style=color:#b58900>round</span><span style=color:#657b83>(</span><span style=color:#6c71c4>3</span><span style=color:#657b83>)
</span><span>    min_row </span><span style=color:#657b83>= </span><span>np.</span><span style=color:#b58900>where</span><span style=color:#657b83>(</span><span>pres_std </span><span style=color:#657b83>== </span><span>pres_std.</span><span style=color:#b58900>min</span><span style=color:#657b83>())</span><span style=color:#268bd2>[</span><span style=color:#6c71c4>0</span><span style=color:#268bd2>]</span><span>.</span><span style=color:#b58900>astype</span><span style=color:#657b83>(</span><span>np.int</span><span style=color:#657b83>)
</span><span>
</span><span>    </span><span style=color:#586e75># Checking differences
</span><span>    </span><span style=color:#859900>print</span><span style=color:#657b83>(</span><span>"</span><span style=color:#2aa198>The row </span><span style=color:#cb4b16>{}</span><span style=color:#2aa198> have the MAX standard deviation between trees (</span><span style=color:#cb4b16>{}</span><span style=color:#2aa198>)</span><span>".</span><span style=color:#b58900>format</span><span style=color:#657b83>(</span><span>max_row, max_std</span><span style=color:#657b83>))
</span><span>    </span><span style=color:#859900>print</span><span style=color:#657b83>(</span><span>"</span><span style=color:#2aa198>The row </span><span style=color:#cb4b16>{}</span><span style=color:#2aa198> have the MIN standard deviation between trees (</span><span style=color:#cb4b16>{}</span><span style=color:#2aa198>)</span><span>".</span><span style=color:#b58900>format</span><span style=color:#657b83>(</span><span>min_row, min_std</span><span style=color:#657b83>))
</span><span>
</span></code></pre> <pre class=language-python data-lang=python style=color:#839496;background-color:#002b36><code class=language-python data-lang=python><span style=color:#b58900>tree_variance</span><span style=color:#657b83>(</span><span>rf_model</span><span style=color:#657b83>)
</span><span>
</span><span>    The row </span><span style=color:#268bd2>[</span><span style=color:#6c71c4>7083 7084</span><span style=color:#268bd2>] </span><span>have the </span><span style=color:#268bd2>MAX </span><span>standard deviation between </span><span style=color:#b58900>trees </span><span style=color:#657b83>(</span><span style=color:#6c71c4>0.625</span><span style=color:#657b83>)
</span><span>    The row </span><span style=color:#268bd2>[</span><span style=color:#6c71c4>5364</span><span style=color:#268bd2>] </span><span>have the </span><span style=color:#268bd2>MIN </span><span>standard deviation between </span><span style=color:#b58900>trees </span><span style=color:#657b83>(</span><span style=color:#6c71c4>0.058</span><span style=color:#657b83>)
</span></code></pre> <p>As you can see, the confidence in the predictions varies widely. For the auction in the index position 6722th, the trees disagree "a lot". For the the auction 5364th, the trees predictions varely differ.</p> <h4 id=9-11-2-feature-importance><a aria-label="Anchor link for: 9-11-2-feature-importance" class=zola-anchor href=#9-11-2-feature-importance>9.11.2 Feature Importance</a></h4> <p>We also want to know how the model its making predictions. The feature importances give us this insight.</p> <p>The attribute <code>feature_importances_</code> gives the list of importance of every feature the model is using to create the splits.</p> <p>The feature importance algorithm loops through each tree, and then recursively explores each branch. At each branch, it looks to see what feature was used for that split, and how much the model improves as a result of that split.</p> <p>The improvement (weighted by the number of rows in that group) is added to the importance score for that feature. This is summed across all branches of all trees, and finally the scores are normalized such that they add to 1.</p> <pre class=language-python data-lang=python style=color:#839496;background-color:#002b36><code class=language-python data-lang=python><span>rf_model.feature_importances_
</span><span>
</span><span>
</span><span>    </span><span style=color:#b58900>array</span><span style=color:#657b83>([</span><span style=color:#6c71c4>5.60696687e-04</span><span>, </span><span style=color:#6c71c4>3.31017616e-02</span><span>, </span><span style=color:#6c71c4>2.25121316e-02</span><span>, </span><span style=color:#6c71c4>4.93692577e-02</span><span>,
</span><span>           </span><span style=color:#6c71c4>3.80074883e-03</span><span>, </span><span style=color:#6c71c4>2.32673274e-02</span><span>, </span><span style=color:#6c71c4>1.17510826e-01</span><span>, </span><span style=color:#6c71c4>7.59427101e-02</span><span>,
</span><span>           </span><span style=color:#6c71c4>4.71958629e-03</span><span>, </span><span style=color:#6c71c4>1.34531419e-02</span><span>, </span><span style=color:#6c71c4>1.60803859e-02</span><span>, </span><span style=color:#6c71c4>8.05581866e-03</span><span>,
</span><span>           </span><span style=color:#6c71c4>2.71543507e-02</span><span>, </span><span style=color:#6c71c4>5.76569695e-04</span><span>, </span><span style=color:#6c71c4>2.19521447e-03</span><span>, </span><span style=color:#6c71c4>6.22032682e-04</span><span>,
</span><span>           </span><span style=color:#6c71c4>2.19242811e-03</span><span>, </span><span style=color:#6c71c4>1.59219664e-03</span><span>, </span><span style=color:#6c71c4>3.07939210e-04</span><span>, </span><span style=color:#6c71c4>5.75216860e-04</span><span>,
</span><span>           </span><span style=color:#6c71c4>1.05861815e-03</span><span>, </span><span style=color:#6c71c4>2.83936750e-04</span><span>, </span><span style=color:#6c71c4>1.14647214e-03</span><span>, </span><span style=color:#6c71c4>8.98867415e-03</span><span>,
</span><span>           </span><span style=color:#6c71c4>7.09370102e-04</span><span>, </span><span style=color:#6c71c4>2.32816635e-03</span><span>, </span><span style=color:#6c71c4>1.42691323e-03</span><span>, </span><span style=color:#6c71c4>9.85881769e-04</span><span>,
</span><span>           </span><span style=color:#6c71c4>7.29902352e-03</span><span>, </span><span style=color:#6c71c4>1.87666527e-03</span><span>, </span><span style=color:#6c71c4>1.26387160e-01</span><span>, </span><span style=color:#6c71c4>3.53398306e-02</span><span>,
</span><span>           </span><span style=color:#6c71c4>3.44002655e-02</span><span>, </span><span style=color:#6c71c4>1.95951710e-03</span><span>, </span><span style=color:#6c71c4>9.28346841e-04</span><span>, </span><span style=color:#6c71c4>1.29951677e-03</span><span>,
</span><span>           </span><span style=color:#6c71c4>5.37011193e-04</span><span>, </span><span style=color:#6c71c4>3.16194890e-04</span><span>, </span><span style=color:#6c71c4>3.62936850e-04</span><span>, </span><span style=color:#6c71c4>4.99996690e-04</span><span>,
</span><span>           </span><span style=color:#6c71c4>2.58723627e-03</span><span>, </span><span style=color:#6c71c4>2.19530794e-03</span><span>, </span><span style=color:#6c71c4>2.28332319e-04</span><span>, </span><span style=color:#6c71c4>2.65172973e-04</span><span>,
</span><span>           </span><span style=color:#6c71c4>2.80335713e-05</span><span>, </span><span style=color:#6c71c4>1.72524636e-05</span><span>, </span><span style=color:#6c71c4>1.06478776e-05</span><span>, </span><span style=color:#6c71c4>4.18794614e-06</span><span>,
</span><span>           </span><span style=color:#6c71c4>0.00000000e+00</span><span>, </span><span style=color:#6c71c4>0.00000000e+00</span><span>, </span><span style=color:#6c71c4>1.16771593e-04</span><span>, </span><span style=color:#6c71c4>6.35195462e-04</span><span>,
</span><span>           </span><span style=color:#6c71c4>2.45309332e-02</span><span>, </span><span style=color:#6c71c4>1.70504793e-02</span><span>, </span><span style=color:#6c71c4>5.21241853e-02</span><span>, </span><span style=color:#6c71c4>8.65017421e-04</span><span>,
</span><span>           </span><span style=color:#6c71c4>2.74614566e-03</span><span>, </span><span style=color:#6c71c4>1.76327989e-01</span><span>, </span><span style=color:#6c71c4>1.73509851e-03</span><span>, </span><span style=color:#6c71c4>1.98023956e-02</span><span>,
</span><span>           </span><span style=color:#6c71c4>1.60375078e-03</span><span>, </span><span style=color:#6c71c4>3.41878336e-03</span><span>, </span><span style=color:#6c71c4>4.36842581e-03</span><span>, </span><span style=color:#6c71c4>2.15207722e-03</span><span>,
</span><span>           </span><span style=color:#6c71c4>4.90070273e-03</span><span>, </span><span style=color:#6c71c4>5.05610397e-02</span><span style=color:#657b83>])
</span></code></pre> <p>Sadly, <code>.feature_importances_</code> doesn't provide a visual way to present the data - so we will create a function to translate the array output into a visual representation.</p> <pre class=language-python data-lang=python style=color:#839496;background-color:#002b36><code class=language-python data-lang=python><span style=color:#859900>def </span><span style=color:#b58900>plot_importance</span><span style=color:#657b83>(</span><span style=color:#268bd2>model</span><span>, </span><span style=color:#268bd2>features</span><span>, </span><span style=color:#268bd2>n</span><span style=color:#657b83>):
</span><span>    df_importance </span><span style=color:#657b83>= </span><span>pd.</span><span style=color:#b58900>DataFrame</span><span style=color:#657b83>({</span><span>'</span><span style=color:#2aa198>Feature</span><span>': features.columns, '</span><span style=color:#2aa198>Importance</span><span>': model.feature_importances_</span><span style=color:#657b83>})
</span><span>    df_importance_storted </span><span style=color:#657b83>= </span><span>df_importance.</span><span style=color:#b58900>sort_values</span><span style=color:#657b83>(</span><span>'</span><span style=color:#2aa198>Importance</span><span>', </span><span style=color:#268bd2>ascending </span><span style=color:#657b83>= </span><span style=color:#b58900>False</span><span style=color:#657b83>)</span><span>.</span><span style=color:#b58900>reset_index</span><span style=color:#657b83>(</span><span style=color:#268bd2>drop </span><span style=color:#657b83>= </span><span style=color:#b58900>True</span><span style=color:#657b83>)
</span><span>    df_importance_top </span><span style=color:#657b83>= </span><span>df_importance_storted.</span><span style=color:#b58900>head</span><span style=color:#657b83>(</span><span>n</span><span style=color:#657b83>)
</span><span>
</span><span>    fig, ax </span><span style=color:#657b83>= </span><span>plt.</span><span style=color:#b58900>subplots</span><span style=color:#657b83>(</span><span style=color:#268bd2>figsize</span><span style=color:#657b83>=(</span><span style=color:#6c71c4>12</span><span>,n</span><span style=color:#657b83>))
</span><span>    sns.</span><span style=color:#b58900>barplot</span><span style=color:#657b83>(</span><span style=color:#268bd2>x </span><span style=color:#657b83>= </span><span>'</span><span style=color:#2aa198>Importance</span><span>', </span><span style=color:#268bd2>y </span><span style=color:#657b83>= </span><span>'</span><span style=color:#2aa198>Feature</span><span>',
</span><span>                </span><span style=color:#268bd2>data </span><span style=color:#657b83>= </span><span>df_importance_top,
</span><span>                </span><span style=color:#268bd2>palette </span><span style=color:#657b83>= </span><span>'</span><span style=color:#2aa198>Blues_r</span><span>'</span><span style=color:#657b83>)
</span><span>    plt.</span><span style=color:#b58900>xticks</span><span style=color:#657b83>(</span><span style=color:#268bd2>size</span><span style=color:#657b83>=</span><span style=color:#6c71c4>14</span><span style=color:#657b83>)
</span><span>    plt.</span><span style=color:#b58900>yticks</span><span style=color:#657b83>(</span><span style=color:#268bd2>size</span><span style=color:#657b83>=</span><span style=color:#6c71c4>14</span><span style=color:#657b83>)
</span><span>    plt.</span><span style=color:#b58900>ylabel</span><span style=color:#657b83>(</span><span>''</span><span style=color:#657b83>)
</span><span>    sns.</span><span style=color:#b58900>despine</span><span style=color:#657b83>(</span><span style=color:#268bd2>left</span><span style=color:#657b83>=</span><span style=color:#b58900>True</span><span style=color:#657b83>)</span><span>;
</span><span>
</span></code></pre> <pre class=language-python data-lang=python style=color:#839496;background-color:#002b36><code class=language-python data-lang=python><span style=color:#b58900>plot_importance</span><span style=color:#657b83>(</span><span>rf_model, X, </span><span style=color:#6c71c4>10</span><span style=color:#657b83>)
</span></code></pre> <p><img alt src=https://pipegalera.github.io/mostly_books/book-fastai/./images/output_102_0.png></p> <h4 id=9-11-3-removing-low-importance-variables><a aria-label="Anchor link for: 9-11-3-removing-low-importance-variables" class=zola-anchor href=#9-11-3-removing-low-importance-variables>9.11.3 Removing Low-Importance Variables</a></h4> <p>We have 66 features in the initial mode, let's try keeping just those with a feature importance greater than 0.005:</p> <pre class=language-python data-lang=python style=color:#839496;background-color:#002b36><code class=language-python data-lang=python><span>columns_keep </span><span style=color:#657b83>= </span><span>X.columns</span><span style=color:#268bd2>[</span><span>rf_model.feature_importances_ </span><span style=color:#657b83>> </span><span style=color:#6c71c4>0.005</span><span style=color:#268bd2>]
</span><span>columns_keep
</span><span>
</span><span>
</span><span>    </span><span style=color:#b58900>Index</span><span style=color:#657b83>([</span><span>'</span><span style=color:#2aa198>fiModelDesc</span><span>', '</span><span style=color:#2aa198>fiBaseModel</span><span>', '</span><span style=color:#2aa198>fiSecondaryDesc</span><span>', '</span><span style=color:#2aa198>fiModelDescriptor</span><span>',
</span><span>           '</span><span style=color:#2aa198>ProductSize</span><span>', '</span><span style=color:#2aa198>fiProductClassDesc</span><span>', '</span><span style=color:#2aa198>ProductGroup</span><span>', '</span><span style=color:#2aa198>ProductGroupDesc</span><span>',
</span><span>           '</span><span style=color:#2aa198>Drive_System</span><span>', '</span><span style=color:#2aa198>Enclosure</span><span>', '</span><span style=color:#2aa198>Hydraulics</span><span>', '</span><span style=color:#2aa198>Tire_Size</span><span>',
</span><span>           '</span><span style=color:#2aa198>Coupler_System</span><span>', '</span><span style=color:#2aa198>Grouser_Tracks</span><span>', '</span><span style=color:#2aa198>Hydraulics_Flow</span><span>', '</span><span style=color:#2aa198>SalesID</span><span>',
</span><span>           '</span><span style=color:#2aa198>MachineID</span><span>', '</span><span style=color:#2aa198>ModelID</span><span>', '</span><span style=color:#2aa198>YearMade</span><span>', '</span><span style=color:#2aa198>saleYear</span><span>', '</span><span style=color:#2aa198>saleElapsed</span><span>'</span><span style=color:#657b83>]</span><span>,
</span><span>          </span><span style=color:#268bd2>dtype</span><span style=color:#657b83>=</span><span>'</span><span style=color:#2aa198>object</span><span>'</span><span style=color:#657b83>)
</span></code></pre> <p>We should trim the column both in the train and in the validation set - and then we test the model again:</p> <pre class=language-python data-lang=python style=color:#839496;background-color:#002b36><code class=language-python data-lang=python><span style=color:#586e75># Only keep important features based on `feature_importances_` attribute
</span><span>X_imp </span><span style=color:#657b83>= </span><span>X</span><span style=color:#268bd2>[</span><span>columns_keep</span><span style=color:#268bd2>]
</span><span>X_valid_imp </span><span style=color:#657b83>= </span><span>X_valid</span><span style=color:#268bd2>[</span><span>columns_keep</span><span style=color:#268bd2>]
</span><span>
</span><span style=color:#586e75># Retrain the model with less features
</span><span>rf_model_2 </span><span style=color:#657b83>= </span><span style=color:#b58900>random_forest</span><span style=color:#657b83>(</span><span>X_imp, y</span><span style=color:#657b83>)
</span></code></pre> <pre class=language-python data-lang=python style=color:#839496;background-color:#002b36><code class=language-python data-lang=python><span style=color:#586e75># New model with less features
</span><span style=color:#b58900>print_rmse</span><span style=color:#657b83>(</span><span>rf_model_2, X_imp, X_valid_imp</span><span style=color:#657b83>)
</span><span>
</span><span>
</span><span>    Training </span><span style=color:#268bd2>RMSE</span><span>: </span><span style=color:#6c71c4>0.180246
</span><span>    Validation </span><span style=color:#268bd2>RMSE</span><span>: </span><span style=color:#6c71c4>0.229436
</span><span>    Out</span><span style=color:#657b83>-</span><span>of</span><span style=color:#657b83>-</span><span>Bag </span><span style=color:#268bd2>RMSE</span><span>: </span><span style=color:#6c71c4>0.212309
</span><span>    Out</span><span style=color:#657b83>-</span><span>of</span><span style=color:#657b83>-</span><span>Bag Accuracy: </span><span style=color:#6c71c4>0.906
</span></code></pre> <pre class=language-python data-lang=python style=color:#839496;background-color:#002b36><code class=language-python data-lang=python><span style=color:#586e75># Previous model
</span><span style=color:#b58900>print_rmse</span><span style=color:#657b83>(</span><span>rf_model, X, X_valid</span><span style=color:#657b83>)
</span><span>
</span><span>
</span><span>    Training </span><span style=color:#268bd2>RMSE</span><span>: </span><span style=color:#6c71c4>0.169543
</span><span>    Validation </span><span style=color:#268bd2>RMSE</span><span>: </span><span style=color:#6c71c4>0.231052
</span><span>    Out</span><span style=color:#657b83>-</span><span>of</span><span style=color:#657b83>-</span><span>Bag </span><span style=color:#268bd2>RMSE</span><span>: </span><span style=color:#6c71c4>0.20854
</span><span>    Out</span><span style=color:#657b83>-</span><span>of</span><span style=color:#657b83>-</span><span>Bag Accuracy: </span><span style=color:#6c71c4>0.91
</span></code></pre> <p>Our validation accuracy is about the same than before (<code>rf_model</code>), even a little bit better, and we have 45(!!) fewer columns to study:</p> <pre class=language-python data-lang=python style=color:#839496;background-color:#002b36><code class=language-python data-lang=python><span style=color:#859900>len</span><span style=color:#657b83>(</span><span>X.columns</span><span style=color:#657b83>) - </span><span style=color:#859900>len</span><span style=color:#657b83>(</span><span>columns_keep</span><span style=color:#657b83>)
</span><span>
</span><span>
</span><span>    </span><span style=color:#6c71c4>45
</span></code></pre> <h4 id=9-11-4-removing-redundant-features><a aria-label="Anchor link for: 9-11-4-removing-redundant-features" class=zola-anchor href=#9-11-4-removing-redundant-features>9.11.4 Removing Redundant Features</a></h4> <p>We will create a function using Spearman or rank correlation between the variables.</p> <p>Intuitively, the <strong>Spearman correlation</strong> between variables will be high when observations have a similar rank, and low when observations have a dissimilar (or fully opposed for a correlation of âˆ’1) rank between the two variables.</p> <p>We use rank correlation because not all the variables follow the same normal distribution and range of values (a.k.a <em>distribution-free/nonparametric</em>). For example, the distribution and range of values of the <code>YearID</code> and the <code>Tire_Size</code> of the auctions are widely different.</p> <p>The only requirement to Spearman correlation is that the variables follow a given order (a.k.a <em>monotonic</em>).</p> <pre class=language-python data-lang=python style=color:#839496;background-color:#002b36><code class=language-python data-lang=python><span style=color:#859900>def </span><span style=color:#b58900>cluster_columns</span><span style=color:#657b83>(</span><span style=color:#268bd2>df</span><span>, </span><span style=color:#268bd2>figsize</span><span style=color:#657b83>=(</span><span style=color:#6c71c4>10</span><span>,</span><span style=color:#6c71c4>6</span><span style=color:#657b83>)</span><span>, </span><span style=color:#268bd2>font_size</span><span style=color:#657b83>=</span><span style=color:#6c71c4>12</span><span style=color:#657b83>):
</span><span>    corr </span><span style=color:#657b83>= </span><span>np.</span><span style=color:#b58900>round</span><span style=color:#657b83>(</span><span>scipy.stats.</span><span style=color:#b58900>spearmanr</span><span style=color:#657b83>(</span><span>df</span><span style=color:#657b83>)</span><span>.correlation, </span><span style=color:#6c71c4>4</span><span style=color:#657b83>)
</span><span>    corr_condensed </span><span style=color:#657b83>= </span><span>hc.distance.</span><span style=color:#b58900>squareform</span><span style=color:#657b83>(</span><span style=color:#6c71c4>1</span><span style=color:#657b83>-</span><span>corr</span><span style=color:#657b83>)
</span><span>    z </span><span style=color:#657b83>= </span><span>hc.</span><span style=color:#b58900>linkage</span><span style=color:#657b83>(</span><span>corr_condensed, </span><span style=color:#268bd2>method</span><span style=color:#657b83>=</span><span>'</span><span style=color:#2aa198>average</span><span>'</span><span style=color:#657b83>)
</span><span>    fig </span><span style=color:#657b83>= </span><span>plt.</span><span style=color:#b58900>figure</span><span style=color:#657b83>(</span><span style=color:#268bd2>figsize</span><span style=color:#657b83>=</span><span>figsize</span><span style=color:#657b83>)
</span><span>    hc.</span><span style=color:#b58900>dendrogram</span><span style=color:#657b83>(</span><span>z, </span><span style=color:#268bd2>labels</span><span style=color:#657b83>=</span><span>df.columns, </span><span style=color:#268bd2>orientation</span><span style=color:#657b83>=</span><span>'</span><span style=color:#2aa198>left</span><span>', </span><span style=color:#268bd2>leaf_font_size</span><span style=color:#657b83>=</span><span>font_size</span><span style=color:#657b83>)
</span><span>    plt.</span><span style=color:#b58900>show</span><span style=color:#657b83>()
</span></code></pre> <pre class=language-python data-lang=python style=color:#839496;background-color:#002b36><code class=language-python data-lang=python><span style=color:#b58900>cluster_columns</span><span style=color:#657b83>(</span><span>X_imp</span><span style=color:#657b83>)
</span></code></pre> <p><img alt src=https://pipegalera.github.io/mostly_books/book-fastai/./images/output_115_0.png></p> <p>The more correlated the features, the early the group at the right of the rank.</p> <p>Out of the 21 variables <code>saleElapsed</code> and <code>saleYear</code> seems to be closelly correlated. Same goes for:</p> <ul><li><code>Hydraulics_Flow</code>, <code>Grouser_Tracks</code>, and <code>Coupler_System</code>.<li><code>ProductGroupDesc</code> and <code>ProductGroup</code>.<li><code>fiBaseModel</code> and <code>fiModelDesc</code>.</ul> <p>Letâ€™s try removing some of these closely related features to see if the model can be simplified. We will use OOB acurracy to see the effect of removing the variables one by one.</p> <pre class=language-python data-lang=python style=color:#839496;background-color:#002b36><code class=language-python data-lang=python><span>var_redundant </span><span style=color:#657b83>= [</span><span>'</span><span style=color:#2aa198>saleElapsed</span><span>', '</span><span style=color:#2aa198>saleYear</span><span>',
</span><span>                 '</span><span style=color:#2aa198>Hydraulics_Flow</span><span>', '</span><span style=color:#2aa198>Grouser_Tracks</span><span>', '</span><span style=color:#2aa198>Coupler_System</span><span>',
</span><span>                 '</span><span style=color:#2aa198>ProductGroupDesc</span><span>', '</span><span style=color:#2aa198>ProductGroup</span><span>',
</span><span>                 '</span><span style=color:#2aa198>fiBaseModel</span><span>', '</span><span style=color:#2aa198>fiModelDesc</span><span>'</span><span style=color:#657b83>]
</span></code></pre> <pre class=language-python data-lang=python style=color:#839496;background-color:#002b36><code class=language-python data-lang=python><span style=color:#859900>def </span><span style=color:#b58900>random_forest_redundancy</span><span style=color:#657b83>(</span><span style=color:#268bd2>X</span><span>, </span><span style=color:#268bd2>redundant_variables</span><span style=color:#657b83>):
</span><span>    </span><span style=color:#859900>print</span><span style=color:#657b83>(</span><span>"</span><span style=color:#2aa198>Baseline Model with the </span><span style=color:#cb4b16>{}</span><span style=color:#2aa198> most important variables</span><span>".</span><span style=color:#b58900>format</span><span style=color:#657b83>(</span><span style=color:#859900>len</span><span style=color:#657b83>(</span><span>X.columns</span><span style=color:#657b83>))</span><span>, </span><span style=color:#b58900>random_forest</span><span style=color:#657b83>(</span><span>X, y</span><span style=color:#657b83>)</span><span>.oob_score_.</span><span style=color:#b58900>round</span><span style=color:#657b83>(</span><span style=color:#6c71c4>3</span><span style=color:#657b83>))
</span><span>    </span><span style=color:#657b83>{</span><span style=color:#859900>print</span><span style=color:#657b83>(</span><span>"</span><span style=color:#2aa198>Model Accuracy without</span><span>", i, "</span><span style=color:#2aa198>:</span><span>", </span><span style=color:#b58900>random_forest</span><span style=color:#657b83>(</span><span>X.</span><span style=color:#b58900>drop</span><span style=color:#657b83>(</span><span>i, </span><span style=color:#268bd2>axis </span><span style=color:#657b83>= </span><span style=color:#6c71c4>1</span><span style=color:#657b83>)</span><span>, y</span><span style=color:#657b83>)</span><span>.oob_score_.</span><span style=color:#b58900>round</span><span style=color:#657b83>(</span><span style=color:#6c71c4>3</span><span style=color:#657b83>)) </span><span style=color:#859900>for </span><span>i </span><span style=color:#859900>in </span><span>redundant_variables</span><span style=color:#657b83>}
</span><span>
</span></code></pre> <pre class=language-python data-lang=python style=color:#839496;background-color:#002b36><code class=language-python data-lang=python><span style=color:#b58900>random_forest_redundancy</span><span style=color:#657b83>(</span><span>X_imp, var_redundant</span><span style=color:#657b83>)
</span><span>
</span><span>    Baseline Model </span><span style=color:#859900>with </span><span>the </span><span style=color:#6c71c4>21 </span><span>most important variables </span><span style=color:#6c71c4>0.906
</span><span>    Model Accuracy without saleElapsed : </span><span style=color:#6c71c4>0.901
</span><span>    Model Accuracy without saleYear : </span><span style=color:#6c71c4>0.906
</span><span>    Model Accuracy without Hydraulics_Flow : </span><span style=color:#6c71c4>0.907
</span><span>    Model Accuracy without Grouser_Tracks : </span><span style=color:#6c71c4>0.906
</span><span>    Model Accuracy without Coupler_System : </span><span style=color:#6c71c4>0.907
</span><span>    Model Accuracy without ProductGroupDesc : </span><span style=color:#6c71c4>0.906
</span><span>    Model Accuracy without ProductGroup : </span><span style=color:#6c71c4>0.907
</span><span>    Model Accuracy without fiBaseModel : </span><span style=color:#6c71c4>0.906
</span><span>    Model Accuracy without fiModelDesc : </span><span style=color:#6c71c4>0.906
</span></code></pre> <p>As we see, removing redundant variables doesn't seem to affect the accuracy.</p> <p>We can try to keep 4 and remove 5 that seems redundant, and see the accuracy impact - e.g. from <code>['Hydraulics_Flow', 'Grouser_Tracks', 'Coupler_System']</code> only keeping <code>Grouser_Tracks</code>.</p> <pre class=language-python data-lang=python style=color:#839496;background-color:#002b36><code class=language-python data-lang=python><span>var_drop </span><span style=color:#657b83>= [</span><span>'</span><span style=color:#2aa198>saleElapsed</span><span>', '</span><span style=color:#2aa198>Hydraulics_Flow</span><span>', '</span><span style=color:#2aa198>Grouser_Tracks</span><span>', '</span><span style=color:#2aa198>ProductGroupDesc</span><span>','</span><span style=color:#2aa198>fiBaseModel</span><span>'</span><span style=color:#657b83>]
</span></code></pre> <pre class=language-python data-lang=python style=color:#839496;background-color:#002b36><code class=language-python data-lang=python><span style=color:#586e75># We remove the redundant variables
</span><span>X_final </span><span style=color:#657b83>= </span><span>X_imp.</span><span style=color:#b58900>drop</span><span style=color:#657b83>(</span><span>var_drop, </span><span style=color:#268bd2>axis</span><span style=color:#657b83>=</span><span style=color:#6c71c4>1</span><span style=color:#657b83>)
</span><span>X_valid_final </span><span style=color:#657b83>= </span><span>X_valid_imp.</span><span style=color:#b58900>drop</span><span style=color:#657b83>(</span><span>var_drop, </span><span style=color:#268bd2>axis</span><span style=color:#657b83>=</span><span style=color:#6c71c4>1</span><span style=color:#657b83>)
</span><span>
</span><span style=color:#586e75># Fit the model with the reduced features dataset
</span><span>rf_model_3 </span><span style=color:#657b83>= </span><span style=color:#b58900>random_forest</span><span style=color:#657b83>(</span><span>X_final, y</span><span style=color:#657b83>)
</span></code></pre> <pre class=language-python data-lang=python style=color:#839496;background-color:#002b36><code class=language-python data-lang=python><span style=color:#b58900>print_rmse</span><span style=color:#657b83>(</span><span>rf_model_3, X_final, X_valid_final</span><span style=color:#657b83>)
</span><span>
</span><span>
</span><span>    Training </span><span style=color:#268bd2>RMSE</span><span>: </span><span style=color:#6c71c4>0.188442
</span><span>    Validation </span><span style=color:#268bd2>RMSE</span><span>: </span><span style=color:#6c71c4>0.230612
</span><span>    Out</span><span style=color:#657b83>-</span><span>of</span><span style=color:#657b83>-</span><span>Bag </span><span style=color:#268bd2>RMSE</span><span>: </span><span style=color:#6c71c4>0.219032
</span><span>    Out</span><span style=color:#657b83>-</span><span>of</span><span style=color:#657b83>-</span><span>Bag Accuracy: </span><span style=color:#6c71c4>0.9
</span></code></pre> <p>The validation RMSE and Out-of-Bag RMSE is the metrics that we most care about, as they rely on data that the model hasn't seen before. And they are looking good!</p> <p>We made a model with 17 features that achieve almost the same loss as the model using 53 features.</p> <pre class=language-python data-lang=python style=color:#839496;background-color:#002b36><code class=language-python data-lang=python><span>X_final.</span><span style=color:#b58900>to_csv</span><span style=color:#657b83>(</span><span>'</span><span style=color:#2aa198>data/X_final.csv</span><span>', </span><span style=color:#268bd2>index</span><span style=color:#657b83>=</span><span style=color:#b58900>False</span><span style=color:#657b83>)
</span><span>X_valid_final.</span><span style=color:#b58900>to_csv</span><span style=color:#657b83>(</span><span>'</span><span style=color:#2aa198>data/X_valid_final.csv</span><span>', </span><span style=color:#268bd2>index</span><span style=color:#657b83>=</span><span style=color:#b58900>False</span><span style=color:#657b83>)
</span></code></pre> <h4 id=9-11-5-partial-dependence><a aria-label="Anchor link for: 9-11-5-partial-dependence" class=zola-anchor href=#9-11-5-partial-dependence>9.11.5 Partial Dependence</a></h4> <p>Partial dependence plots try to answer the question: if a row varied on nothing other than the feature in question, how would it impact the dependent variable?</p> <p>As weâ€™ve seen, the two most important predictors are <code>ProductSize</code> and <code>YearMade</code>.</p> <p>What we do is replace every single value in the <code>YearMade</code> column with 1950, and then calculate the predicted sale price for every auction, and take the average over all auctions. Then we do the same for 1951, 1952, and so forth until our final year of 2011. This isolates the effect of only YearMade</p> <pre class=language-python data-lang=python style=color:#839496;background-color:#002b36><code class=language-python data-lang=python><span style=color:#cb4b16>from </span><span>sklearn.inspection </span><span style=color:#cb4b16>import </span><span>plot_partial_dependence
</span></code></pre> <pre class=language-python data-lang=python style=color:#839496;background-color:#002b36><code class=language-python data-lang=python><span>fig,ax </span><span style=color:#657b83>= </span><span>plt.</span><span style=color:#b58900>subplots</span><span style=color:#657b83>(</span><span style=color:#268bd2>figsize</span><span style=color:#657b83>=(</span><span style=color:#6c71c4>12</span><span>, </span><span style=color:#6c71c4>4</span><span style=color:#657b83>))
</span><span style=color:#b58900>plot_partial_dependence</span><span style=color:#657b83>(</span><span>rf_model_3, X_valid_final, </span><span style=color:#657b83>[</span><span>'</span><span style=color:#2aa198>YearMade</span><span>','</span><span style=color:#2aa198>ProductSize</span><span>'</span><span style=color:#657b83>]</span><span>, </span><span style=color:#268bd2>ax</span><span style=color:#657b83>=</span><span>ax</span><span style=color:#657b83>)</span><span>;
</span></code></pre> <p><img alt src=https://pipegalera.github.io/mostly_books/book-fastai/./images/output_129_0.png></p> <ul><li><p>The <code>YearMade</code> partial plot show a nearly linear relationship between <code>YearMade</code> and <code>Salesprice</code> after year 1970</p><li><p>The <code>ProductSize</code> partial shows that for 5 and 6 classes the auctions have the lowest <code>Salesprice</code>.</p></ul> <p>This kind of insights can give an extra advantage to squish a bit of accuracy in, for example, Kaggle competitions.</p> <h4 id=9-11-6-data-leakage><a aria-label="Anchor link for: 9-11-6-data-leakage" class=zola-anchor href=#9-11-6-data-leakage>9.11.6 Data Leakage</a></h4> <p>Data leakage is another way to get an advantage in programming competitions.</p> <p>Tips to identify data leakages:</p> <ul><li>Check whether the accuracy of the model is <strong>too good to be true</strong>.<li>Look for <strong>important predictors that donâ€™t make sense in practice</strong>.<li>Look for <strong>partial dependence plot</strong> results that donâ€™t make sense in practice.</ul> <p>The only question that remains is:</p> <p><em>For predicting with a particular row of data, what were the most important factors, and how did they influence that prediction?</em></p> <h3 id=9-12-tree-models-and-extrapolation><a aria-label="Anchor link for: 9-12-tree-models-and-extrapolation" class=zola-anchor href=#9-12-tree-models-and-extrapolation>9.12 Tree-models and Extrapolation</a></h3> <p>A problem with random forests, like all machine learning or deep learning algorithms, is that they donâ€™t always generalize well to new data.</p> <p>Letâ€™s consider the simple task of creating a <code>RandomForestRegressor()</code> that learns from the first 30 points and try to predict the next 10. The "features" is a one-dimensional tensor and the "target" is the same one-dimensional tensor plus some noise mady by adding random numbers from a normal distribution.</p> <p>Therefore, the relation between the features and the target is almost linear plus noise - they are almost the same number. Any human could see the corralation between the <code>X</code> numbers and the <code>y</code> numbers in the tensors below:</p> <pre class=language-python data-lang=python style=color:#839496;background-color:#002b36><code class=language-python data-lang=python><span>X </span><span style=color:#657b83>= </span><span>torch.</span><span style=color:#b58900>linspace</span><span style=color:#657b83>(</span><span style=color:#6c71c4>0</span><span>,</span><span style=color:#6c71c4>20</span><span>, </span><span style=color:#268bd2>steps</span><span style=color:#657b83>=</span><span style=color:#6c71c4>40</span><span style=color:#657b83>)
</span><span>target </span><span style=color:#657b83>= </span><span>X </span><span style=color:#657b83>+ </span><span>torch.</span><span style=color:#b58900>randn_like</span><span style=color:#657b83>(</span><span>X</span><span style=color:#657b83>)
</span></code></pre> <pre class=language-python data-lang=python style=color:#839496;background-color:#002b36><code class=language-python data-lang=python><span>X
</span><span>
</span><span>
</span><span>    </span><span style=color:#b58900>tensor</span><span style=color:#657b83>([ </span><span style=color:#6c71c4>0.0000</span><span>,  </span><span style=color:#6c71c4>0.5128</span><span>,  </span><span style=color:#6c71c4>1.0256</span><span>,  </span><span style=color:#6c71c4>1.5385</span><span>,  </span><span style=color:#6c71c4>2.0513</span><span>,  </span><span style=color:#6c71c4>2.5641</span><span>,  </span><span style=color:#6c71c4>3.0769</span><span>,  </span><span style=color:#6c71c4>3.5897</span><span>,
</span><span>             </span><span style=color:#6c71c4>4.1026</span><span>,  </span><span style=color:#6c71c4>4.6154</span><span>,  </span><span style=color:#6c71c4>5.1282</span><span>,  </span><span style=color:#6c71c4>5.6410</span><span>,  </span><span style=color:#6c71c4>6.1538</span><span>,  </span><span style=color:#6c71c4>6.6667</span><span>,  </span><span style=color:#6c71c4>7.1795</span><span>,  </span><span style=color:#6c71c4>7.6923</span><span>,
</span><span>             </span><span style=color:#6c71c4>8.2051</span><span>,  </span><span style=color:#6c71c4>8.7179</span><span>,  </span><span style=color:#6c71c4>9.2308</span><span>,  </span><span style=color:#6c71c4>9.7436</span><span>, </span><span style=color:#6c71c4>10.2564</span><span>, </span><span style=color:#6c71c4>10.7692</span><span>, </span><span style=color:#6c71c4>11.2821</span><span>, </span><span style=color:#6c71c4>11.7949</span><span>,
</span><span>            </span><span style=color:#6c71c4>12.3077</span><span>, </span><span style=color:#6c71c4>12.8205</span><span>, </span><span style=color:#6c71c4>13.3333</span><span>, </span><span style=color:#6c71c4>13.8462</span><span>, </span><span style=color:#6c71c4>14.3590</span><span>, </span><span style=color:#6c71c4>14.8718</span><span>, </span><span style=color:#6c71c4>15.3846</span><span>, </span><span style=color:#6c71c4>15.8974</span><span>,
</span><span>            </span><span style=color:#6c71c4>16.4103</span><span>, </span><span style=color:#6c71c4>16.9231</span><span>, </span><span style=color:#6c71c4>17.4359</span><span>, </span><span style=color:#6c71c4>17.9487</span><span>, </span><span style=color:#6c71c4>18.4615</span><span>, </span><span style=color:#6c71c4>18.9744</span><span>, </span><span style=color:#6c71c4>19.4872</span><span>, </span><span style=color:#6c71c4>20.0000</span><span style=color:#657b83>])
</span></code></pre> <pre class=language-python data-lang=python style=color:#839496;background-color:#002b36><code class=language-python data-lang=python><span>target
</span><span>
</span><span>    </span><span style=color:#b58900>tensor</span><span style=color:#657b83>([-</span><span style=color:#6c71c4>4.8952e-01</span><span>,  </span><span style=color:#6c71c4>1.1971e-02</span><span>,  </span><span style=color:#6c71c4>2.6504e+00</span><span>,  </span><span style=color:#6c71c4>1.0710e+00</span><span>,  </span><span style=color:#6c71c4>3.3717e+00</span><span>,
</span><span>             </span><span style=color:#6c71c4>7.5045e-01</span><span>,  </span><span style=color:#6c71c4>1.3698e+00</span><span>,  </span><span style=color:#6c71c4>2.2385e+00</span><span>,  </span><span style=color:#6c71c4>5.2067e+00</span><span>,  </span><span style=color:#6c71c4>4.5659e+00</span><span>,
</span><span>             </span><span style=color:#6c71c4>5.5455e+00</span><span>,  </span><span style=color:#6c71c4>4.8772e+00</span><span>,  </span><span style=color:#6c71c4>7.8788e+00</span><span>,  </span><span style=color:#6c71c4>5.7786e+00</span><span>,  </span><span style=color:#6c71c4>6.2888e+00</span><span>,
</span><span>             </span><span style=color:#6c71c4>6.7935e+00</span><span>,  </span><span style=color:#6c71c4>8.7160e+00</span><span>,  </span><span style=color:#6c71c4>9.1112e+00</span><span>,  </span><span style=color:#6c71c4>8.8788e+00</span><span>,  </span><span style=color:#6c71c4>1.0618e+01</span><span>,
</span><span>             </span><span style=color:#6c71c4>1.0592e+01</span><span>,  </span><span style=color:#6c71c4>1.2324e+01</span><span>,  </span><span style=color:#6c71c4>1.1950e+01</span><span>,  </span><span style=color:#6c71c4>1.1621e+01</span><span>,  </span><span style=color:#6c71c4>1.1374e+01</span><span>,
</span><span>             </span><span style=color:#6c71c4>1.1379e+01</span><span>,  </span><span style=color:#6c71c4>1.4004e+01</span><span>,  </span><span style=color:#6c71c4>1.4633e+01</span><span>,  </span><span style=color:#6c71c4>1.4821e+01</span><span>,  </span><span style=color:#6c71c4>1.5068e+01</span><span>,
</span><span>             </span><span style=color:#6c71c4>1.4898e+01</span><span>,  </span><span style=color:#6c71c4>1.4943e+01</span><span>,  </span><span style=color:#6c71c4>1.6194e+01</span><span>,  </span><span style=color:#6c71c4>1.6307e+01</span><span>,  </span><span style=color:#6c71c4>1.8478e+01</span><span>,
</span><span>             </span><span style=color:#6c71c4>1.7215e+01</span><span>,  </span><span style=color:#6c71c4>1.9295e+01</span><span>,  </span><span style=color:#6c71c4>1.9452e+01</span><span>,  </span><span style=color:#6c71c4>2.0081e+01</span><span>,  </span><span style=color:#6c71c4>1.9914e+01</span><span style=color:#657b83>])
</span></code></pre> <pre class=language-python data-lang=python style=color:#839496;background-color:#002b36><code class=language-python data-lang=python><span>fig, </span><span style=color:#657b83>(</span><span>ax1, ax2, ax3</span><span style=color:#657b83>) = </span><span>plt.</span><span style=color:#b58900>subplots</span><span style=color:#657b83>(</span><span style=color:#6c71c4>1</span><span>, </span><span style=color:#6c71c4>3</span><span>, </span><span style=color:#268bd2>figsize</span><span style=color:#657b83>=(</span><span style=color:#6c71c4>15</span><span>,</span><span style=color:#6c71c4>5</span><span style=color:#657b83>))
</span><span>ax1.title.</span><span style=color:#b58900>set_text</span><span style=color:#657b83>(</span><span>'</span><span style=color:#2aa198>Generated "features"</span><span>'</span><span style=color:#657b83>)
</span><span>ax2.title.</span><span style=color:#b58900>set_text</span><span style=color:#657b83>(</span><span>'</span><span style=color:#2aa198>Generated target</span><span>'</span><span style=color:#657b83>)
</span><span>ax3.title.</span><span style=color:#b58900>set_text</span><span style=color:#657b83>(</span><span>'</span><span style=color:#2aa198>Relationship</span><span>'</span><span style=color:#657b83>)
</span><span>ax1.</span><span style=color:#b58900>plot</span><span style=color:#657b83>(</span><span>X</span><span style=color:#657b83>)
</span><span>ax2.</span><span style=color:#b58900>plot</span><span style=color:#657b83>(</span><span>target</span><span style=color:#657b83>)
</span><span>ax3.</span><span style=color:#b58900>scatter</span><span style=color:#657b83>(</span><span>X, target</span><span style=color:#657b83>)
</span></code></pre> <p><img alt src=https://pipegalera.github.io/mostly_books/book-fastai/./images/output_139_1.png></p> <p>The linear relationship is really straightforward, as we can see in the "Relationship" plot - X and y values are very correlated.</p> <p>It should be easy for the model to take the relationship between the first 30 points and extrapolate it to predict the next 10 right? Let's try!</p> <pre class=language-python data-lang=python style=color:#839496;background-color:#002b36><code class=language-python data-lang=python><span>X </span><span style=color:#657b83>= </span><span>X.</span><span style=color:#b58900>unsqueeze</span><span style=color:#657b83>(</span><span style=color:#6c71c4>1</span><span style=color:#657b83>)
</span><span style=color:#586e75># Fitting the first 30 datapoints
</span><span>tree_model </span><span style=color:#657b83>= </span><span style=color:#b58900>RandomForestRegressor</span><span style=color:#657b83>()</span><span>.</span><span style=color:#b58900>fit</span><span style=color:#657b83>(</span><span>X</span><span style=color:#268bd2>[</span><span>:</span><span style=color:#6c71c4>30</span><span style=color:#268bd2>]</span><span>, target</span><span style=color:#268bd2>[</span><span>:</span><span style=color:#6c71c4>30</span><span style=color:#268bd2>]</span><span style=color:#657b83>)
</span><span style=color:#586e75># Predictions
</span><span>y_preds </span><span style=color:#657b83>= </span><span>tree_model.</span><span style=color:#b58900>predict</span><span style=color:#657b83>(</span><span>X</span><span style=color:#657b83>)
</span></code></pre> <pre class=language-python data-lang=python style=color:#839496;background-color:#002b36><code class=language-python data-lang=python><span style=color:#586e75># Real values in blue
</span><span>plt.</span><span style=color:#b58900>scatter</span><span style=color:#657b83>(</span><span>X, target</span><span style=color:#657b83>)
</span><span style=color:#586e75># Predictions in red
</span><span>plt.</span><span style=color:#b58900>scatter</span><span style=color:#657b83>(</span><span>X, y_preds, </span><span style=color:#268bd2>color</span><span style=color:#657b83>=</span><span>'</span><span style=color:#2aa198>red</span><span>', </span><span style=color:#268bd2>alpha</span><span style=color:#657b83>=</span><span style=color:#6c71c4>0.5</span><span style=color:#657b83>)</span><span>;
</span></code></pre> <p><img alt src=https://pipegalera.github.io/mostly_books/book-fastai/./images/output_142_0.png></p> <p><strong>The random forest is not able to see the "clear" linear relationship between our linear points!</strong></p> <p>Remember that a random forest just averages the predictions of a number of trees. And a tree simply predicts the average value of the rows in a leaf. Therefore, <strong>a tree and a random forest can never predict values outside the range of the training data</strong>.</p> <p><strong>This is particularly problematic for data indicating a trend over time, such as inflation, and you wish to make predictions for a future time. Your predictions will be systematically too low.</strong></p> <p>Random forests are not able to extrapolate outside the types of data they have seen, in a more general sense. Thatâ€™s why we need to make sure our validation set does not contain out-of-domain data.</p> <h3 id=9-13-finding-out-of-domain-data><a aria-label="Anchor link for: 9-13-finding-out-of-domain-data" class=zola-anchor href=#9-13-finding-out-of-domain-data>9.13 Finding Out-of-Domain Data</a></h3> <p>The main problem above is that test set is distributed in a different way than the training data. <strong>If the tree model hasn't seen a value more than 16, it will never predict more than 16</strong>.</p> <p>Sometimes it is hard to know whether your test set is distributed in the same way as your training data or, if it is different, which columns reflect that difference. Thereâ€™s an easy way to figure this out, which is ironically using a random forest!</p> <p>But in this case, we donâ€™t use the random forest to predict our actual dependent variable. Instead, <strong>we try to predict whether a row is in the validation set or the training set</strong>. To see this in action, letâ€™s combine our training and validation sets, create a dependent variable that represents which dataset each row comes from, build a random forest using that data, and get its feature importance</p> <pre class=language-python data-lang=python style=color:#839496;background-color:#002b36><code class=language-python data-lang=python><span style=color:#586e75># Create a column with the target
</span><span>X_final</span><span style=color:#268bd2>[</span><span>'</span><span style=color:#2aa198>is_valid</span><span>'</span><span style=color:#268bd2>] </span><span style=color:#657b83>= </span><span style=color:#6c71c4>0
</span><span>X_valid_final</span><span style=color:#268bd2>[</span><span>'</span><span style=color:#2aa198>is_valid</span><span>'</span><span style=color:#268bd2>] </span><span style=color:#657b83>= </span><span style=color:#6c71c4>1
</span><span>
</span><span style=color:#586e75># Concat the dfs and create variables
</span><span>X </span><span style=color:#657b83>= </span><span>pd.</span><span style=color:#b58900>concat</span><span style=color:#657b83>([</span><span>X_final, X_valid_final</span><span style=color:#657b83>])
</span><span>is_valid </span><span style=color:#657b83>= </span><span>X</span><span style=color:#268bd2>[</span><span>'</span><span style=color:#2aa198>is_valid</span><span>'</span><span style=color:#268bd2>]</span><span>.</span><span style=color:#b58900>copy</span><span style=color:#657b83>()
</span><span>
</span><span style=color:#586e75># Drop the new variable from the features dataset
</span><span>X </span><span style=color:#657b83>= </span><span>X.</span><span style=color:#b58900>drop</span><span style=color:#657b83>(</span><span>'</span><span style=color:#2aa198>is_valid</span><span>', </span><span style=color:#268bd2>axis</span><span style=color:#657b83>=</span><span style=color:#6c71c4>1</span><span style=color:#657b83>)
</span><span>X_final </span><span style=color:#657b83>= </span><span>X_final.</span><span style=color:#b58900>drop</span><span style=color:#657b83>(</span><span>'</span><span style=color:#2aa198>is_valid</span><span>', </span><span style=color:#268bd2>axis</span><span style=color:#657b83>=</span><span style=color:#6c71c4>1</span><span style=color:#657b83>)
</span><span>X_valid_final </span><span style=color:#657b83>= </span><span>X_valid_final.</span><span style=color:#b58900>drop</span><span style=color:#657b83>(</span><span>'</span><span style=color:#2aa198>is_valid</span><span>', </span><span style=color:#268bd2>axis</span><span style=color:#657b83>=</span><span style=color:#6c71c4>1</span><span style=color:#657b83>)
</span><span>
</span><span style=color:#586e75># Create a model with the target being `is_valid`
</span><span>rf_model_ODD </span><span style=color:#657b83>= </span><span style=color:#b58900>random_forest</span><span style=color:#657b83>(</span><span>X, is_valid</span><span style=color:#657b83>)
</span></code></pre> <pre class=language-python data-lang=python style=color:#839496;background-color:#002b36><code class=language-python data-lang=python><span style=color:#b58900>plot_importance</span><span style=color:#657b83>(</span><span>rf_model_ODD, X, </span><span style=color:#6c71c4>10</span><span style=color:#657b83>)
</span></code></pre> <p><img alt src=https://pipegalera.github.io/mostly_books/book-fastai/./images/output_147_0.png></p> <ul><li>The difference in <code>SalesID</code> suggests that identifiers for auction sales might increment over time, we'll find bigger <code>SalesID</code> values in the validation set.<li><code>saleYear</code> suggest that the latest auctions are in the validation set.<li><code>MachineID</code> suggests something similar might be happening for individual items sold in those auctions, we'll find bigger <code>MachineID</code> values in the validation set.<li><code>YearMade</code>, same same.</ul> <p>All these features that are different in the training and validation set have something in common: <strong>they encode the date of the auction</strong>. This is an issue because we are training the past datapoints to predict future datapoints, and as we have seen in the <em>Tree-models and Extrapolation</em> section this works badly.</p> <p>Let's try to remove the "date variables" to see if we lose accuracy removing the variables 1 by 1:</p> <pre class=language-python data-lang=python style=color:#839496;background-color:#002b36><code class=language-python data-lang=python><span style=color:#b58900>random_forest_redundancy</span><span style=color:#657b83>(</span><span>X_final, </span><span style=color:#657b83>[</span><span>'</span><span style=color:#2aa198>SalesID</span><span>', '</span><span style=color:#2aa198>saleYear</span><span>', '</span><span style=color:#2aa198>MachineID</span><span>'</span><span style=color:#657b83>])
</span><span>
</span><span>
</span><span>    Baseline Model </span><span style=color:#859900>with </span><span>the </span><span style=color:#6c71c4>16 </span><span>most important variables </span><span style=color:#6c71c4>0.9
</span><span>    Model Accuracy without SalesID : </span><span style=color:#6c71c4>0.899
</span><span>    Model Accuracy without saleYear : </span><span style=color:#6c71c4>0.842
</span><span>    Model Accuracy without MachineID : </span><span style=color:#6c71c4>0.901
</span></code></pre> <p>We should not remove <code>saleYear</code>, as we see a drop in the accuracy.But we can remove <code>SalesID</code> and <code>MachineID</code>.</p> <p>We should look as well at the RMSE loss, not only the accuracy:</p> <pre class=language-python data-lang=python style=color:#839496;background-color:#002b36><code class=language-python data-lang=python><span style=color:#586e75># Reduced datasets
</span><span>X_final_2 </span><span style=color:#657b83>= </span><span>X_final.</span><span style=color:#b58900>drop</span><span style=color:#657b83>([</span><span>'</span><span style=color:#2aa198>SalesID</span><span>', '</span><span style=color:#2aa198>MachineID</span><span>'</span><span style=color:#657b83>]</span><span>, </span><span style=color:#268bd2>axis </span><span style=color:#657b83>= </span><span style=color:#6c71c4>1</span><span style=color:#657b83>)
</span><span>X_valid_final_2 </span><span style=color:#657b83>= </span><span>X_valid_final.</span><span style=color:#b58900>drop</span><span style=color:#657b83>([</span><span>'</span><span style=color:#2aa198>SalesID</span><span>', '</span><span style=color:#2aa198>MachineID</span><span>'</span><span style=color:#657b83>]</span><span>, </span><span style=color:#268bd2>axis </span><span style=color:#657b83>= </span><span style=color:#6c71c4>1</span><span style=color:#657b83>)
</span><span>
</span><span style=color:#586e75># Re-train the model
</span><span>rf_model_4 </span><span style=color:#657b83>= </span><span style=color:#b58900>random_forest</span><span style=color:#657b83>(</span><span>X_final_2, y</span><span style=color:#657b83>)
</span></code></pre> <pre class=language-python data-lang=python style=color:#839496;background-color:#002b36><code class=language-python data-lang=python><span style=color:#586e75># New model
</span><span style=color:#b58900>print_rmse</span><span style=color:#657b83>(</span><span>rf_model_4, X_final_2, X_valid_final_2</span><span style=color:#657b83>)
</span><span>
</span><span>
</span><span>    Training </span><span style=color:#268bd2>RMSE</span><span>: </span><span style=color:#6c71c4>0.200645
</span><span>    Validation </span><span style=color:#268bd2>RMSE</span><span>: </span><span style=color:#6c71c4>0.227668
</span><span>    Out</span><span style=color:#657b83>-</span><span>of</span><span style=color:#657b83>-</span><span>Bag </span><span style=color:#268bd2>RMSE</span><span>: </span><span style=color:#6c71c4>0.219294
</span><span>    Out</span><span style=color:#657b83>-</span><span>of</span><span style=color:#657b83>-</span><span>Bag Accuracy: </span><span style=color:#6c71c4>0.9
</span></code></pre> <p>We have improved a bit the model wrt the previous one:</p> <ul><li>Training RMSE: 0.188482<li>Validation RMSE: 0.230356<li>Out-of-Bag RMSE: 0.219128<li>Out-of-Bag Accuracy: 0.9</ul> <p>What we do with <code>salesYear</code>. The distrubtion of this variable is different in the training and in the validation set, but remocing it reduces the accuracy. However... can we trim it?</p> <p>One thing that might help in our case is to simply avoid using old data. Often, old data shows relationships that just arenâ€™t valid anymore. Letâ€™s try just using the most recent few years of the data:</p> <pre class=language-python data-lang=python style=color:#839496;background-color:#002b36><code class=language-python data-lang=python><span>X</span><span style=color:#268bd2>[</span><span>'</span><span style=color:#2aa198>saleYear</span><span>'</span><span style=color:#268bd2>]</span><span>.</span><span style=color:#b58900>hist</span><span style=color:#657b83>()</span><span>;
</span></code></pre> <p><img alt src=https://pipegalera.github.io/mostly_books/book-fastai/./images/output_154_0.png></p> <pre class=language-python data-lang=python style=color:#839496;background-color:#002b36><code class=language-python data-lang=python><span>X_final_2</span><span style=color:#268bd2>[</span><span>X_final_2</span><span style=color:#268bd2>[</span><span>'</span><span style=color:#2aa198>saleYear</span><span>'</span><span style=color:#268bd2>] </span><span style=color:#657b83>> </span><span style=color:#6c71c4>2004</span><span style=color:#268bd2>]
</span></code></pre> <table class=dataframe><thead><tr><th><th>fiModelDesc<th>fiSecondaryDesc<th>fiModelDescriptor<th>ProductSize<th>fiProductClassDesc<th>ProductGroup<th>Drive_System<th>Enclosure<th>Hydraulics<th>Tire_Size<th>Coupler_System<th>ModelID<th>YearMade<th>saleYear<tbody><tr><th>0<td>963<td>43<td>0<td>0<td>59<td>6<td>0<td>3<td>1<td>17<td>0<td>3157<td>2004<td>2006<tr><th>3<td>3716<td>0<td>0<td>4<td>8<td>4<td>0<td>3<td>1<td>0<td>0<td>332<td>2001<td>2011<tr><th>4<td>4261<td>0<td>0<td>0<td>40<td>3<td>0<td>1<td>4<td>0<td>1<td>17311<td>2007<td>2009<tr><th>5<td>500<td>59<td>0<td>0<td>2<td>1<td>2<td>6<td>0<td>0<td>0<td>4605<td>2004<td>2008<tr><th>7<td>749<td>43<td>0<td>0<td>2<td>1<td>2<td>6<td>0<td>0<td>0<td>3539<td>2001<td>2005<tr><th>...<td>...<td>...<td>...<td>...<td>...<td>...<td>...<td>...<td>...<td>...<td>...<td>...<td>...<td>...<tr><th>412693<td>490<td>108<td>0<td>5<td>13<td>4<td>0<td>1<td>12<td>0<td>0<td>21435<td>2005<td>2012<tr><th>412694<td>491<td>108<td>0<td>5<td>17<td>4<td>0<td>1<td>4<td>0<td>0<td>21436<td>2005<td>2012<tr><th>412695<td>490<td>108<td>0<td>5<td>13<td>4<td>0<td>1<td>4<td>0<td>0<td>21435<td>2005<td>2012<tr><th>412696<td>490<td>108<td>0<td>5<td>13<td>4<td>0<td>1<td>4<td>0<td>0<td>21435<td>2006<td>2012<tr><th>412697<td>491<td>108<td>0<td>5<td>17<td>4<td>0<td>1<td>4<td>0<td>0<td>21436<td>2006<td>2012</table> <p>230144 rows Ã— 14 columns</p> <pre class=language-python data-lang=python style=color:#839496;background-color:#002b36><code class=language-python data-lang=python><span>y</span><span style=color:#268bd2>[</span><span>X_final_2</span><span style=color:#268bd2>[</span><span>'</span><span style=color:#2aa198>saleYear</span><span>'</span><span style=color:#268bd2>]</span><span style=color:#657b83>></span><span style=color:#6c71c4>2004</span><span style=color:#268bd2>]
</span><span>
</span><span>
</span><span>    </span><span style=color:#6c71c4>0         11.097410
</span><span>    </span><span style=color:#6c71c4>3         10.558414
</span><span>    </span><span style=color:#6c71c4>4          9.305651
</span><span>    </span><span style=color:#6c71c4>5         10.184900
</span><span>    </span><span style=color:#6c71c4>7         10.203592
</span><span>                </span><span style=color:#b58900>...
</span><span>    </span><span style=color:#6c71c4>412693     9.210340
</span><span>    </span><span style=color:#6c71c4>412694     9.259130
</span><span>    </span><span style=color:#6c71c4>412695     9.433484
</span><span>    </span><span style=color:#6c71c4>412696     9.210340
</span><span>    </span><span style=color:#6c71c4>412697     9.472705
</span><span>    Name: SalePrice, Length: </span><span style=color:#6c71c4>230144</span><span>, dtype: float32
</span></code></pre> <pre class=language-python data-lang=python style=color:#839496;background-color:#002b36><code class=language-python data-lang=python><span>X_trimmed </span><span style=color:#657b83>=       </span><span>X_final_2</span><span style=color:#268bd2>[</span><span>X_final_2</span><span style=color:#268bd2>[</span><span>'</span><span style=color:#2aa198>saleYear</span><span>'</span><span style=color:#268bd2>] </span><span style=color:#657b83>> </span><span style=color:#6c71c4>2004</span><span style=color:#268bd2>]
</span><span>X_valid_trimmed </span><span style=color:#657b83>= </span><span>X_valid_final_2</span><span style=color:#268bd2>[</span><span>X_valid_final_2</span><span style=color:#268bd2>[</span><span>'</span><span style=color:#2aa198>saleYear</span><span>'</span><span style=color:#268bd2>] </span><span style=color:#657b83>> </span><span style=color:#6c71c4>2004</span><span style=color:#268bd2>]
</span><span>y_trimmed </span><span style=color:#657b83>=       </span><span>y</span><span style=color:#268bd2>[</span><span>X_final_2</span><span style=color:#268bd2>[</span><span>'</span><span style=color:#2aa198>saleYear</span><span>'</span><span style=color:#268bd2>]</span><span style=color:#657b83>></span><span style=color:#6c71c4>2004</span><span style=color:#268bd2>]
</span><span>
</span><span>rf_model_5 </span><span style=color:#657b83>= </span><span style=color:#b58900>random_forest</span><span style=color:#657b83>(</span><span>X_trimmed, y_trimmed</span><span style=color:#657b83>)
</span></code></pre> <pre class=language-python data-lang=python style=color:#839496;background-color:#002b36><code class=language-python data-lang=python><span style=color:#586e75># Previous RMSE
</span><span style=color:#b58900>print_rmse</span><span style=color:#657b83>(</span><span>rf_model_4, X_final_2, X_valid_final_2, y, y_valid</span><span style=color:#657b83>)
</span><span>
</span><span>
</span><span>    Training </span><span style=color:#268bd2>RMSE</span><span>: </span><span style=color:#6c71c4>0.200645
</span><span>    Validation </span><span style=color:#268bd2>RMSE</span><span>: </span><span style=color:#6c71c4>0.227668
</span><span>    Out</span><span style=color:#657b83>-</span><span>of</span><span style=color:#657b83>-</span><span>Bag </span><span style=color:#268bd2>RMSE</span><span>: </span><span style=color:#6c71c4>0.219294
</span><span>    Out</span><span style=color:#657b83>-</span><span>of</span><span style=color:#657b83>-</span><span>Bag Accuracy: </span><span style=color:#6c71c4>0.9
</span></code></pre> <pre class=language-python data-lang=python style=color:#839496;background-color:#002b36><code class=language-python data-lang=python><span style=color:#586e75># New RMSE
</span><span style=color:#b58900>print_rmse</span><span style=color:#657b83>(</span><span>rf_model_5, X_trimmed, X_valid_trimmed, y_trimmed, y_valid</span><span style=color:#657b83>)
</span><span>
</span><span>
</span><span>    Training </span><span style=color:#268bd2>RMSE</span><span>: </span><span style=color:#6c71c4>0.19193
</span><span>    Validation </span><span style=color:#268bd2>RMSE</span><span>: </span><span style=color:#6c71c4>0.227894
</span><span>    Out</span><span style=color:#657b83>-</span><span>of</span><span style=color:#657b83>-</span><span>Bag </span><span style=color:#268bd2>RMSE</span><span>: </span><span style=color:#6c71c4>0.218182
</span><span>    Out</span><span style=color:#657b83>-</span><span>of</span><span style=color:#657b83>-</span><span>Bag Accuracy: </span><span style=color:#6c71c4>0.904
</span></code></pre> <p>Itâ€™s a tiny bit better, which shows that you shouldnâ€™t always use your entire dataset - sometimes a subset can be better.</p> <p>Letâ€™s see if using a neural network we can increase even further the accuracy.</p> <h3 id=9-14-neural-networks-for-tabular-data><a aria-label="Anchor link for: 9-14-neural-networks-for-tabular-data" class=zola-anchor href=#9-14-neural-networks-for-tabular-data>9.14 Neural Networks for tabular data</a></h3> <p>We can use the same approach to build a neural network model. Letâ€™s first replicate the steps we took to set up the TabularPandas object:</p> <pre class=language-python data-lang=python style=color:#839496;background-color:#002b36><code class=language-python data-lang=python><span>X_final_2
</span></code></pre> <table class=dataframe><thead><tr><th><th>fiModelDesc<th>fiSecondaryDesc<th>fiModelDescriptor<th>ProductSize<th>fiProductClassDesc<th>ProductGroup<th>Drive_System<th>Enclosure<th>Hydraulics<th>Tire_Size<th>Coupler_System<th>ModelID<th>YearMade<th>saleYear<tbody><tr><th>0<td>963<td>43<td>0<td>0<td>59<td>6<td>0<td>3<td>1<td>17<td>0<td>3157<td>2004<td>2006<tr><th>1<td>1745<td>57<td>0<td>3<td>62<td>6<td>0<td>3<td>1<td>12<td>0<td>77<td>1996<td>2004<tr><th>2<td>336<td>0<td>0<td>0<td>39<td>3<td>0<td>6<td>4<td>0<td>1<td>7009<td>2001<td>2004<tr><th>3<td>3716<td>0<td>0<td>4<td>8<td>4<td>0<td>3<td>1<td>0<td>0<td>332<td>2001<td>2011<tr><th>4<td>4261<td>0<td>0<td>0<td>40<td>3<td>0<td>1<td>4<td>0<td>1<td>17311<td>2007<td>2009<tr><th>...<td>...<td>...<td>...<td>...<td>...<td>...<td>...<td>...<td>...<td>...<td>...<td>...<td>...<td>...<tr><th>412693<td>490<td>108<td>0<td>5<td>13<td>4<td>0<td>1<td>12<td>0<td>0<td>21435<td>2005<td>2012<tr><th>412694<td>491<td>108<td>0<td>5<td>17<td>4<td>0<td>1<td>4<td>0<td>0<td>21436<td>2005<td>2012<tr><th>412695<td>490<td>108<td>0<td>5<td>13<td>4<td>0<td>1<td>4<td>0<td>0<td>21435<td>2005<td>2012<tr><th>412696<td>490<td>108<td>0<td>5<td>13<td>4<td>0<td>1<td>4<td>0<td>0<td>21435<td>2006<td>2012<tr><th>412697<td>491<td>108<td>0<td>5<td>17<td>4<td>0<td>1<td>4<td>0<td>0<td>21436<td>2006<td>2012</table> <p>404710 rows Ã— 14 columns</p> <pre class=language-python data-lang=python style=color:#839496;background-color:#002b36><code class=language-python data-lang=python><span>df_nn </span><span style=color:#657b83>= </span><span>pd.</span><span style=color:#b58900>read_csv</span><span style=color:#657b83>(</span><span>'</span><span style=color:#2aa198>TrainAndValid.csv</span><span>', </span><span style=color:#268bd2>low_memory</span><span style=color:#657b83>=</span><span style=color:#b58900>False</span><span style=color:#657b83>)
</span><span>df_nn</span><span style=color:#268bd2>[</span><span>'</span><span style=color:#2aa198>ProductSize</span><span>'</span><span style=color:#268bd2>] </span><span style=color:#657b83>= </span><span>df_nn</span><span style=color:#268bd2>[</span><span>'</span><span style=color:#2aa198>ProductSize</span><span>'</span><span style=color:#268bd2>]</span><span>.</span><span style=color:#b58900>astype</span><span style=color:#657b83>(</span><span>'</span><span style=color:#2aa198>category</span><span>'</span><span style=color:#657b83>)
</span><span>df_nn</span><span style=color:#268bd2>[</span><span>'</span><span style=color:#2aa198>ProductSize</span><span>'</span><span style=color:#268bd2>]</span><span>.cat.</span><span style=color:#b58900>set_categories</span><span style=color:#657b83>(</span><span>sizes, </span><span style=color:#268bd2>ordered</span><span style=color:#657b83>=</span><span style=color:#b58900>True</span><span>, </span><span style=color:#268bd2>inplace</span><span style=color:#657b83>=</span><span style=color:#b58900>True</span><span style=color:#657b83>)
</span><span>df_nn</span><span style=color:#268bd2>[</span><span>'</span><span style=color:#2aa198>SalePrice</span><span>'</span><span style=color:#268bd2>] </span><span style=color:#657b83>= </span><span>np.</span><span style=color:#b58900>log</span><span style=color:#657b83>(</span><span>df_nn</span><span style=color:#268bd2>[</span><span>'</span><span style=color:#2aa198>SalePrice</span><span>'</span><span style=color:#268bd2>]</span><span style=color:#657b83>)
</span><span>df_nn </span><span style=color:#657b83>= </span><span style=color:#b58900>add_datepart</span><span style=color:#657b83>(</span><span>df_nn, '</span><span style=color:#2aa198>saledate</span><span>'</span><span style=color:#657b83>)
</span><span>df_nn_final </span><span style=color:#657b83>= </span><span>df_nn</span><span style=color:#268bd2>[</span><span style=color:#859900>list</span><span style=color:#657b83>(</span><span>X_final_2.columns</span><span style=color:#657b83>) + [</span><span>'</span><span style=color:#2aa198>SalePrice</span><span>'</span><span style=color:#657b83>]</span><span style=color:#268bd2>]
</span></code></pre> <p>Categorical columns are handled very differently in neural networks, compared to decision tree approaches - <strong>For Neural Networks we will use embeddings</strong>.</p> <p>To create embeddings, fastai needs to determine which columns should be treated as categorical variables. It does this by comparing the number of distinct levels in the variable to the value of the <code>max_card</code> parameter. If itâ€™s lower, fastai will treat the variable as categorical. Embedding sizes larger than 10,000 should generally be used only after youâ€™ve tested whether there are better ways to group the variable, so weâ€™ll use 9,000 as our max_card value:</p> <pre class=language-python data-lang=python style=color:#839496;background-color:#002b36><code class=language-python data-lang=python><span>cont_nn, cat_nn </span><span style=color:#657b83>= </span><span style=color:#b58900>cont_cat_split</span><span style=color:#657b83>(</span><span>df_nn_final, </span><span style=color:#268bd2>max_card</span><span style=color:#657b83>=</span><span style=color:#6c71c4>9000</span><span>, </span><span style=color:#268bd2>dep_var</span><span style=color:#657b83>=</span><span>'</span><span style=color:#2aa198>SalePrice</span><span>'</span><span style=color:#657b83>)
</span></code></pre> <pre class=language-python data-lang=python style=color:#839496;background-color:#002b36><code class=language-python data-lang=python><span>cat_nn
</span><span>
</span><span>    </span><span style=color:#657b83>[</span><span>'</span><span style=color:#2aa198>fiModelDesc</span><span>',
</span><span>     '</span><span style=color:#2aa198>fiSecondaryDesc</span><span>',
</span><span>     '</span><span style=color:#2aa198>fiModelDescriptor</span><span>',
</span><span>     '</span><span style=color:#2aa198>ProductSize</span><span>',
</span><span>     '</span><span style=color:#2aa198>fiProductClassDesc</span><span>',
</span><span>     '</span><span style=color:#2aa198>ProductGroup</span><span>',
</span><span>     '</span><span style=color:#2aa198>Drive_System</span><span>',
</span><span>     '</span><span style=color:#2aa198>Enclosure</span><span>',
</span><span>     '</span><span style=color:#2aa198>Hydraulics</span><span>',
</span><span>     '</span><span style=color:#2aa198>Tire_Size</span><span>',
</span><span>     '</span><span style=color:#2aa198>Coupler_System</span><span>',
</span><span>     '</span><span style=color:#2aa198>ModelID</span><span>',
</span><span>     '</span><span style=color:#2aa198>YearMade</span><span>',
</span><span>     '</span><span style=color:#2aa198>saleYear</span><span>'</span><span style=color:#657b83>]
</span></code></pre> <p>In this case, however, thereâ€™s one variable that we absolutely do not want to treat as categorical: <code>saleYear</code>. A categorical variable cannot, by definition, extrapolate outside the range of values that it has seen, but we want to be able to predict auction sale prices in the future. Therefore, we need to make this a continuous variable:</p> <pre class=language-python data-lang=python style=color:#839496;background-color:#002b36><code class=language-python data-lang=python><span>cont_nn.</span><span style=color:#b58900>append</span><span style=color:#657b83>(</span><span>'</span><span style=color:#2aa198>saleYear</span><span>'</span><span style=color:#657b83>)
</span><span>cat_nn.</span><span style=color:#b58900>remove</span><span style=color:#657b83>(</span><span>'</span><span style=color:#2aa198>saleYear</span><span>'</span><span style=color:#657b83>)
</span></code></pre> <pre class=language-python data-lang=python style=color:#839496;background-color:#002b36><code class=language-python data-lang=python><span>df_nn_final</span><span style=color:#268bd2>[</span><span>cat_nn</span><span style=color:#268bd2>]</span><span>.</span><span style=color:#b58900>nunique</span><span style=color:#657b83>()
</span><span>
</span><span>
</span><span>    fiModelDesc           </span><span style=color:#6c71c4>5059
</span><span>    fiSecondaryDesc        </span><span style=color:#6c71c4>177
</span><span>    fiModelDescriptor      </span><span style=color:#6c71c4>140
</span><span>    ProductSize              </span><span style=color:#6c71c4>6
</span><span>    fiProductClassDesc      </span><span style=color:#6c71c4>74
</span><span>    ProductGroup             </span><span style=color:#6c71c4>6
</span><span>    Drive_System             </span><span style=color:#6c71c4>4
</span><span>    Enclosure                </span><span style=color:#6c71c4>6
</span><span>    Hydraulics              </span><span style=color:#6c71c4>12
</span><span>    Tire_Size               </span><span style=color:#6c71c4>17
</span><span>    Coupler_System           </span><span style=color:#6c71c4>2
</span><span>    ModelID               </span><span style=color:#6c71c4>5281
</span><span>    YearMade                </span><span style=color:#6c71c4>73
</span><span>    dtype: int64
</span></code></pre> <p>We can create our TabularPandas object in the same way as when we created our random forest, with one very important addition: <strong>normalization</strong>. A random forest does not need any normalizationâ€”the tree building procedure cares only about the order of values in a variable, not at all about how they are scaled.</p> <p>Neural networks are definitely affected by the scale of the values. Therefore, we add the Normalize processor when we build our TabularPandas object:</p> <pre class=language-python data-lang=python style=color:#839496;background-color:#002b36><code class=language-python data-lang=python><span>procs_nn </span><span style=color:#657b83>= [</span><span>Categorify, FillMissing, Normalize</span><span style=color:#657b83>]
</span><span>to_nn </span><span style=color:#657b83>= </span><span style=color:#b58900>TabularPandas</span><span style=color:#657b83>(</span><span>df_nn_final,
</span><span>                      procs_nn,
</span><span>                      cat_nn,
</span><span>                      cont_nn,
</span><span>                      </span><span style=color:#268bd2>splits</span><span style=color:#657b83>=</span><span>splits,
</span><span>                      </span><span style=color:#268bd2>y_names</span><span style=color:#657b83>=</span><span>'</span><span style=color:#2aa198>SalePrice</span><span>'</span><span style=color:#657b83>)
</span></code></pre> <p>We load the data into a <code>DataLoader</code>, and set a range for the target. Itâ€™s a good idea to set <code>y_range</code> for regression models, so letâ€™s find the min and max of our dependent variable:</p> <pre class=language-python data-lang=python style=color:#839496;background-color:#002b36><code class=language-python data-lang=python><span style=color:#586e75># Features into the dataloader
</span><span>dls </span><span style=color:#657b83>= </span><span>to_nn.</span><span style=color:#b58900>dataloaders</span><span style=color:#657b83>(</span><span style=color:#6c71c4>1024</span><span style=color:#657b83>)
</span><span style=color:#586e75># Target
</span><span>y </span><span style=color:#657b83>= </span><span>to_nn.train.y
</span><span>
</span><span style=color:#586e75># Range
</span><span>y.</span><span style=color:#b58900>min</span><span style=color:#657b83>()</span><span>,y.</span><span style=color:#b58900>max</span><span style=color:#657b83>()
</span><span>
</span><span>
</span><span>
</span><span>
</span><span>    </span><span style=color:#657b83>(</span><span style=color:#6c71c4>8.465899</span><span>, </span><span style=color:#6c71c4>11.863583</span><span style=color:#657b83>)
</span></code></pre> <p>Lastly, we build the model:</p> <pre class=language-python data-lang=python style=color:#839496;background-color:#002b36><code class=language-python data-lang=python><span>learn </span><span style=color:#657b83>= </span><span style=color:#b58900>tabular_learner</span><span style=color:#657b83>(</span><span>dls, </span><span style=color:#268bd2>y_range</span><span style=color:#657b83>=(</span><span style=color:#6c71c4>8</span><span>,</span><span style=color:#6c71c4>12</span><span style=color:#657b83>)</span><span>, </span><span style=color:#268bd2>layers</span><span style=color:#657b83>=[</span><span style=color:#6c71c4>500</span><span>,</span><span style=color:#6c71c4>250</span><span style=color:#657b83>]</span><span>, </span><span style=color:#268bd2>n_out</span><span style=color:#657b83>=</span><span style=color:#6c71c4>1</span><span>, </span><span style=color:#268bd2>loss_func</span><span style=color:#657b83>=</span><span>F.mse_loss</span><span style=color:#657b83>)
</span></code></pre> <p>Thereâ€™s no need to use fine_tune, so weâ€™ll train with fit_one_cycle for a few epochs and see how it looks:</p> <pre class=language-python data-lang=python style=color:#839496;background-color:#002b36><code class=language-python data-lang=python><span>learn.</span><span style=color:#b58900>fit_one_cycle</span><span style=color:#657b83>(</span><span style=color:#6c71c4>10</span><span>, learn.</span><span style=color:#b58900>lr_find</span><span style=color:#657b83>()</span><span style=color:#268bd2>[</span><span style=color:#6c71c4>0</span><span style=color:#268bd2>]</span><span style=color:#657b83>)
</span></code></pre> <table class=dataframe><thead><tr style=text-align:left><th>epoch<th>train_loss<th>valid_loss<th>time<tbody><tr><td>0<td>0.040625<td>0.051301<td>00:03<tr><td>1<td>0.043241<td>0.052923<td>00:03<tr><td>2<td>0.043518<td>0.053630<td>00:03<tr><td>3<td>0.042394<td>0.054047<td>00:03<tr><td>4<td>0.040913<td>0.052986<td>00:03<tr><td>5<td>0.040410<td>0.052649<td>00:03<tr><td>6<td>0.038336<td>0.051216<td>00:03<tr><td>7<td>0.037320<td>0.052022<td>00:03<tr><td>8<td>0.036384<td>0.051955<td>00:03<tr><td>9<td>0.036191<td>0.051794<td>00:03</table> <p><img alt src=https://pipegalera.github.io/mostly_books/book-fastai/./images/output_179_2.png></p> <p>We can use our r_mse function to compare the result to the random forest result we got earlier:</p> <pre class=language-python data-lang=python style=color:#839496;background-color:#002b36><code class=language-python data-lang=python><span>preds,targs </span><span style=color:#657b83>= </span><span>learn.</span><span style=color:#b58900>get_preds</span><span style=color:#657b83>()
</span><span style=color:#b58900>r_mse</span><span style=color:#657b83>(</span><span>preds,targs</span><span style=color:#657b83>)
</span><span>
</span><span>
</span><span>    </span><span style=color:#6c71c4>0.227582
</span></code></pre> <p>This gives us a similiar result than the best random forest achieved previously. Before we move on, letâ€™s save our model in case we want to come back to it again later:</p> <pre class=language-python data-lang=python style=color:#839496;background-color:#002b36><code class=language-python data-lang=python><span>learn.</span><span style=color:#b58900>save</span><span style=color:#657b83>(</span><span>'</span><span style=color:#2aa198>nn</span><span>'</span><span style=color:#657b83>)
</span><span>
</span><span>    </span><span style=color:#b58900>Path</span><span style=color:#657b83>(</span><span>'</span><span style=color:#2aa198>models/nn.pth</span><span>'</span><span style=color:#657b83>)
</span></code></pre> <p>We can always try to hypertune the model from here.</p> <h3 id=9-15-ensembling><a aria-label="Anchor link for: 9-15-ensembling" class=zola-anchor href=#9-15-ensembling>9.15 Ensembling</a></h3> <p>We have two very different models, trained using very different algorithms: random forest and neural networks.</p> <p>It would be reasonable to expect that the kinds of errors that each one makes would be quite different. Therefore, we might <strong>expect that the average of their predictions would be better than either oneâ€™s individual predictions</strong>.</p> <p>When ensembling the results together, one minor issue we have to be aware of is that our PyTorch model and our sklearn model create data of different types.</p> <ul><li>PyTorch gives us a rank-2 tensor (a column matrix)<li>NumPy gives us a rank-1 array (a vector).</ul> <pre class=language-python data-lang=python style=color:#839496;background-color:#002b36><code class=language-python data-lang=python><span>learn.</span><span style=color:#b58900>get_preds</span><span style=color:#657b83>()
</span><span>
</span><span>
</span><span>    </span><span style=color:#657b83>(</span><span style=color:#b58900>tensor</span><span style=color:#657b83>([[</span><span style=color:#6c71c4>10.2192</span><span style=color:#657b83>]</span><span>,
</span><span>             </span><span style=color:#657b83>[</span><span style=color:#6c71c4>10.0230</span><span style=color:#657b83>]</span><span>,
</span><span>             </span><span style=color:#657b83>[ </span><span style=color:#6c71c4>9.3750</span><span style=color:#657b83>]</span><span>,
</span><span>             </span><span style=color:#b58900>...</span><span>,
</span><span>             </span><span style=color:#657b83>[ </span><span style=color:#6c71c4>9.3017</span><span style=color:#657b83>]</span><span>,
</span><span>             </span><span style=color:#657b83>[ </span><span style=color:#6c71c4>9.2062</span><span style=color:#657b83>]</span><span>,
</span><span>             </span><span style=color:#657b83>[ </span><span style=color:#6c71c4>9.2062</span><span style=color:#657b83>]])</span><span>,
</span><span>     </span><span style=color:#b58900>tensor</span><span style=color:#657b83>([[</span><span style=color:#6c71c4>10.0432</span><span style=color:#657b83>]</span><span>,
</span><span>             </span><span style=color:#657b83>[</span><span style=color:#6c71c4>10.0858</span><span style=color:#657b83>]</span><span>,
</span><span>             </span><span style=color:#657b83>[ </span><span style=color:#6c71c4>9.3927</span><span style=color:#657b83>]</span><span>,
</span><span>             </span><span style=color:#b58900>...</span><span>,
</span><span>             </span><span style=color:#657b83>[ </span><span style=color:#6c71c4>9.3501</span><span style=color:#657b83>]</span><span>,
</span><span>             </span><span style=color:#657b83>[ </span><span style=color:#6c71c4>9.1050</span><span style=color:#657b83>]</span><span>,
</span><span>             </span><span style=color:#657b83>[ </span><span style=color:#6c71c4>8.9554</span><span style=color:#657b83>]]))
</span></code></pre> <pre class=language-python data-lang=python style=color:#839496;background-color:#002b36><code class=language-python data-lang=python><span>rf_model_5.</span><span style=color:#b58900>predict</span><span style=color:#657b83>(</span><span>X_valid_final_2</span><span style=color:#657b83>)
</span><span>
</span><span>    </span><span style=color:#b58900>array</span><span style=color:#657b83>([</span><span style=color:#6c71c4>10.07742579</span><span>, </span><span style=color:#6c71c4>10.03322471</span><span>,  </span><span style=color:#6c71c4>9.35772406</span><span>, </span><span style=color:#b58900>...</span><span>,  </span><span style=color:#6c71c4>9.34768389</span><span>,
</span><span>            </span><span style=color:#6c71c4>9.24583077</span><span>,  </span><span style=color:#6c71c4>9.24583077</span><span style=color:#657b83>])
</span></code></pre> <p><code>squeeze</code> removes any unit axes from a tensor, and to_np converts it into a Numpy array:</p> <pre class=language-python data-lang=python style=color:#839496;background-color:#002b36><code class=language-python data-lang=python><span style=color:#b58900>to_np</span><span style=color:#657b83>(</span><span>preds.</span><span style=color:#b58900>squeeze</span><span style=color:#657b83>())
</span><span>
</span><span>    </span><span style=color:#b58900>array</span><span style=color:#657b83>([</span><span style=color:#6c71c4>10.219167</span><span>, </span><span style=color:#6c71c4>10.023037</span><span>,  </span><span style=color:#6c71c4>9.375016</span><span>, </span><span style=color:#b58900>...</span><span>,  </span><span style=color:#6c71c4>9.301746</span><span>,  </span><span style=color:#6c71c4>9.206213</span><span>,
</span><span>            </span><span style=color:#6c71c4>9.206213</span><span style=color:#657b83>]</span><span>, </span><span style=color:#268bd2>dtype</span><span style=color:#657b83>=</span><span>float32</span><span style=color:#657b83>)
</span></code></pre> <p>Now that both predictions are in numpy arraym they can be ensembled.</p> <pre class=language-python data-lang=python style=color:#839496;background-color:#002b36><code class=language-python data-lang=python><span>ensemble_preds </span><span style=color:#657b83>= (</span><span style=color:#b58900>to_np</span><span style=color:#657b83>(</span><span>preds.</span><span style=color:#b58900>squeeze</span><span style=color:#657b83>()) + </span><span>rf_model_5.</span><span style=color:#b58900>predict</span><span style=color:#657b83>(</span><span>X_valid_final_2</span><span style=color:#657b83>))/</span><span style=color:#6c71c4>2
</span></code></pre> <pre class=language-python data-lang=python style=color:#839496;background-color:#002b36><code class=language-python data-lang=python><span style=color:#b58900>r_mse</span><span style=color:#657b83>(</span><span>ensemble_preds, y_valid</span><span style=color:#657b83>)
</span><span>
</span><span>
</span><span>    </span><span style=color:#6c71c4>0.22322
</span></code></pre> <p>Notice that an RMSE of 0.223 is the best result so far - better than the most tunned random forest and the neural network!</p> <h3 id=9-16-boosting><a aria-label="Anchor link for: 9-16-boosting" class=zola-anchor href=#9-16-boosting>9.16 Boosting</a></h3> <p>In another important approach to ensembling, called boosting, where we add models instead of averaging them.</p> <p>Here is how boosting works:</p> <ol><li>Train a small model that underfits your dataset.<li>Calculate the predictions in the training set for this model.<li>Subtract the predictions from the targets; these are called the residuals and represent the error for each point in the training set.<li>Go back to step 1, but <strong>instead of using the original targets, use the residuals as the targets for the training</strong>.<li>Continue doing this until you reach a stopping criterion, such as a maximum number of trees, or you observe your validation set error getting worse.</ol> <p>Using this approach, each new tree will be attempting to fit the error of all of the previous trees combined.</p> <p>Note that, unlike with random forests, with this approach, <strong>there is nothing to stop us from overfitting</strong>.</p> <p>Using more trees in a random forest does not lead to overfitting, because each tree is independent of the others. But <strong>in a boosted ensemble, the more trees you have, the better the training error becomes</strong>, and eventually you will see overfitting on the validation set.</p> <h3 id=9-17-tabular-models-conclusion><a aria-label="Anchor link for: 9-17-tabular-models-conclusion" class=zola-anchor href=#9-17-tabular-models-conclusion>9.17 Tabular models conclusion</a></h3> <p>We have discussed two approaches to tabular modeling: decision tree ensembles and neural networks. Weâ€™ve also mentioned two decision tree ensembles: random forests and gradient boosting machines. Each is effective but also requires compromises:</p> <ul><li><p><strong>Random forests</strong> are the easiest to train, because they are extremely resilient to hyperparameter choices and require little preprocessing. They are fast to train, and should not overfit if you have enough trees. But they can be a little less accurate, especially if extrapolation is required, such as predicting future time periods.</p><li><p><strong>Gradient boosting</strong> machines in theory are just as fast to train as random forests, but in practice you will have to try lots of hyperparameters. They can overfit, but they are often a little more accurate than random forests.</p><li><p><strong>Neural networks</strong> take the longest time to train and require extra preprocessing, such as normalization - this normalization needs to be used at inference time as well. They can provide great results and extrapolate well, but only if you are careful with your hyperparameters and take care to avoid overfitting.</p></ul> <p><strong>We suggest starting your analysis with a random forest</strong>. This will give you a strong baseline, and you can be confident that itâ€™s a reasonable starting point. You can then use that model for feature selection and partial dependence analysis, to get a better understanding of your data.</p> <div class=giscus></div> <script async crossorigin issue-term=pathname repo=YOUR_NAME/YOUR_REPO src=https://utteranc.es/client.js theme=github-light></script> <footer><div class=footer-content><p>100% human written content by Pipe Galera Â© 2025. Theme: <a href=https://github.com/not-matthias/apollo>Apollo</a>.</div></footer> 